{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 10: Regularization to Prevent Overfitting: L1, L2 and Dropout\n",
    "\n",
    "\n",
    "#### CSC 180  Intelligent Systems (Spring 2020)\n",
    "\n",
    "#### Dr. Haiquan Chen, California State University, Sacramento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions for Tensorflow (Little Gems)\n",
    "\n",
    "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network. \n",
    "\n",
    "* Predictors/Inputs \n",
    "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
    "    * Encode textual/categorical values with **encode_text_dummy**.\n",
    "    * Encode numeric values with **encode_numeric_zscore**.\n",
    "* Output\n",
    "    * Discard rows with missing outputs.\n",
    "    * Encode textual/categorical values with **encode_text_index**.\n",
    "    * Do not encode output numeric values.\n",
    "* Produce final feature vectors (x) and expected output (y) with **to_xy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 and L2 regularization techniques used in linear regression\n",
    "\n",
    "L1 and L2 regularization are two common regularization techniques.\n",
    "\n",
    "We are going to look at linear regression to see how L1 and L2 regularization work.  The following code sets up the auto-mpg data for this purpose.\n",
    "\n",
    "https://www.kaggle.com/uciml/autompg-dataset/home\n",
    "\n",
    "The labeling on the origin column is 1 for domestic, 2 for Europe and 3 for Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford galaxie 500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>454.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4354</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet impala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4312</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth fury iii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>4425</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>pontiac catalina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>390.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3850</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc ambassador dpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>383.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3563</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge challenger se</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>340.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>3609</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth 'cuda 340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3761</td>\n",
       "      <td>9.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet monte carlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3086</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick estate wagon (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>toyota corona mark ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth duster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>199.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2774</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc hornet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford maverick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>14.5</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>datsun pl510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1835</td>\n",
       "      <td>20.5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>volkswagen 1131 deluxe sedan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0   18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1   15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2   18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3   16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4   17.0          8         302.0       140.0    3449          10.5    70   \n",
       "5   15.0          8         429.0       198.0    4341          10.0    70   \n",
       "6   14.0          8         454.0       220.0    4354           9.0    70   \n",
       "7   14.0          8         440.0       215.0    4312           8.5    70   \n",
       "8   14.0          8         455.0       225.0    4425          10.0    70   \n",
       "9   15.0          8         390.0       190.0    3850           8.5    70   \n",
       "10  15.0          8         383.0       170.0    3563          10.0    70   \n",
       "11  14.0          8         340.0       160.0    3609           8.0    70   \n",
       "12  15.0          8         400.0       150.0    3761           9.5    70   \n",
       "13  14.0          8         455.0       225.0    3086          10.0    70   \n",
       "14  24.0          4         113.0        95.0    2372          15.0    70   \n",
       "15  22.0          6         198.0        95.0    2833          15.5    70   \n",
       "16  18.0          6         199.0        97.0    2774          15.5    70   \n",
       "17  21.0          6         200.0        85.0    2587          16.0    70   \n",
       "18  27.0          4          97.0        88.0    2130          14.5    70   \n",
       "19  26.0          4          97.0        46.0    1835          20.5    70   \n",
       "\n",
       "    origin                          name  \n",
       "0        1     chevrolet chevelle malibu  \n",
       "1        1             buick skylark 320  \n",
       "2        1            plymouth satellite  \n",
       "3        1                 amc rebel sst  \n",
       "4        1                   ford torino  \n",
       "5        1              ford galaxie 500  \n",
       "6        1              chevrolet impala  \n",
       "7        1             plymouth fury iii  \n",
       "8        1              pontiac catalina  \n",
       "9        1            amc ambassador dpl  \n",
       "10       1           dodge challenger se  \n",
       "11       1            plymouth 'cuda 340  \n",
       "12       1         chevrolet monte carlo  \n",
       "13       1       buick estate wagon (sw)  \n",
       "14       3         toyota corona mark ii  \n",
       "15       1               plymouth duster  \n",
       "16       1                    amc hornet  \n",
       "17       1                 ford maverick  \n",
       "18       3                  datsun pl510  \n",
       "19       2  volkswagen 1131 deluxe sedan  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin-1</th>\n",
       "      <th>origin-2</th>\n",
       "      <th>origin-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>454.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4354</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4312</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>4425</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>390.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3850</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>383.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3563</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>340.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>3609</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3761</td>\n",
       "      <td>9.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3086</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>199.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2774</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>14.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1835</td>\n",
       "      <td>20.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0   18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1   15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2   18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3   16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4   17.0          8         302.0       140.0    3449          10.5    70   \n",
       "5   15.0          8         429.0       198.0    4341          10.0    70   \n",
       "6   14.0          8         454.0       220.0    4354           9.0    70   \n",
       "7   14.0          8         440.0       215.0    4312           8.5    70   \n",
       "8   14.0          8         455.0       225.0    4425          10.0    70   \n",
       "9   15.0          8         390.0       190.0    3850           8.5    70   \n",
       "10  15.0          8         383.0       170.0    3563          10.0    70   \n",
       "11  14.0          8         340.0       160.0    3609           8.0    70   \n",
       "12  15.0          8         400.0       150.0    3761           9.5    70   \n",
       "13  14.0          8         455.0       225.0    3086          10.0    70   \n",
       "14  24.0          4         113.0        95.0    2372          15.0    70   \n",
       "15  22.0          6         198.0        95.0    2833          15.5    70   \n",
       "16  18.0          6         199.0        97.0    2774          15.5    70   \n",
       "17  21.0          6         200.0        85.0    2587          16.0    70   \n",
       "18  27.0          4          97.0        88.0    2130          14.5    70   \n",
       "19  26.0          4          97.0        46.0    1835          20.5    70   \n",
       "\n",
       "    origin-1  origin-2  origin-3  \n",
       "0          1         0         0  \n",
       "1          1         0         0  \n",
       "2          1         0         0  \n",
       "3          1         0         0  \n",
       "4          1         0         0  \n",
       "5          1         0         0  \n",
       "6          1         0         0  \n",
       "7          1         0         0  \n",
       "8          1         0         0  \n",
       "9          1         0         0  \n",
       "10         1         0         0  \n",
       "11         1         0         0  \n",
       "12         1         0         0  \n",
       "13         1         0         0  \n",
       "14         0         0         1  \n",
       "15         1         0         0  \n",
       "16         1         0         0  \n",
       "17         1         0         0  \n",
       "18         0         0         1  \n",
       "19         0         1         0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create feature vector\n",
    "missing_median(df, 'horsepower')\n",
    "df.drop('name', 1, inplace=True)\n",
    "\n",
    "encode_text_dummy(df, 'origin')\n",
    "df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n"
     ]
    }
   ],
   "source": [
    "# Encode to a 2D matrix for training\n",
    "x,y = to_xy(df,'mpg')\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=45) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Linear Regression\n",
    "\n",
    "To understand L1/L2 regularization, it is good to start with linear regression.  L1/L2 were first introduced for [linear regression](https://en.wikipedia.org/wiki/Linear_regression).  They can also be used for neural networks.  \n",
    "\n",
    "The following code uses linear regression to fit the auto-mpg data set.  The RMSE reported will not be as good as a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 2.937156915664673\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create linear regression\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Fit/train linear regression\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin-1', 'origin-2', 'origin-3']\n"
     ]
    }
   ],
   "source": [
    "names = list(df.columns.values)\n",
    "\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41654268,  0.02445622, -0.00778466, -0.00747326,  0.13812245,\n",
       "        0.8012743 , -1.448374  ,  0.8185648 ,  0.6298092 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.257578"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to evaluate the coefficients of a regression\n",
    "\n",
    "%matplotlib inline    \n",
    "from IPython.display import display   \n",
    "\n",
    "def report_coef(names,coef,intercept):\n",
    "    r = pd.DataFrame( { 'coef': coef, 'positive': coef>=0  }, index = names )\n",
    "    r = r.sort_values(by=['coef'])\n",
    "    display(r)\n",
    "    print(\"Intercept: {}\".format(intercept))\n",
    "    r['coef'].plot(kind='barh', color=r['positive'].map({True: 'b', False: 'r'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>origin-1</th>\n",
       "      <td>-1.448374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.416543</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.007785</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.007473</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.024456</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.138122</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-3</th>\n",
       "      <td>0.629809</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.801274</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-2</th>\n",
       "      <td>0.818565</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef  positive\n",
       "origin-1     -1.448374     False\n",
       "cylinders    -0.416543     False\n",
       "horsepower   -0.007785     False\n",
       "weight       -0.007473     False\n",
       "displacement  0.024456      True\n",
       "acceleration  0.138122      True\n",
       "origin-3      0.629809      True\n",
       "year          0.801274      True\n",
       "origin-2      0.818565      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -18.257577896118164\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "names.remove(\"mpg\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 (Lasso) Regularization\n",
    "\n",
    "L1 Regularization, also called LASSO (Least Absolute Shrinkage and Selection Operator) should be used to create sparsity in the neural network. \n",
    "\n",
    "### L1 algorithm will push many weight connections to near 0.  \n",
    "\n",
    "When a weight is near 0, the program drops it from the network.  Dropping weighted connections will create a sparse neural network.\n",
    "\n",
    "### The lower weight values will typically lead to less overfitting.\n",
    "\n",
    "\n",
    "### Minimization objective = SSE (Sum of Squared Error) + $\\alpha$ * (Sum of Absolute Value of Coefficients)\n",
    "\n",
    "When $\\alpha$ is 0, Lasso regression produces the same coefficients as a linear regression. When $\\alpha$ is very very large, all coefficients are zero.\n",
    "\n",
    "The following code demonstrates lasso regression.  Notice the effect of the coefficients compared to the previous section that used linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 3.040905714035034\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>origin-1</th>\n",
       "      <td>-1.264474</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.007458</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.002797</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.013005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.113760</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.787195</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef  positive\n",
       "origin-1     -1.264474     False\n",
       "weight       -0.007458     False\n",
       "horsepower   -0.002797     False\n",
       "cylinders    -0.000000      True\n",
       "origin-2      0.000000      True\n",
       "origin-3      0.000000      True\n",
       "displacement  0.013005      True\n",
       "acceleration  0.113760      True\n",
       "year          0.787195      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -17.271265029907227\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create linear regression\n",
    "regressor = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit/train LASSO\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df.columns.values)\n",
    "names.remove(\"mpg\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:  If your data set has a large number of input features that may not be needed, L1 regularization can help to detect and ignore unnecessary features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 (Ridge) Regularization\n",
    "\n",
    "Use Ridge/L2 regularization when you prefer low weight values.  ***The lower weight values will typically lead to less overfitting.*** \n",
    "\n",
    "\n",
    "### Minimization objective = SSE (Sum of Squared Error) + $\\alpha$ * (Sum of Square of Coefficients)\n",
    "\n",
    "When $\\alpha$ is 0, L2 regression produces the same coefficients as a linear regression. When $\\alpha$ is very very large, all coefficients are zero.\n",
    "\n",
    "### L1 will force the weights into a pattern similar to a laplace distribution; the L2 will force the weights into a pattern similar to a Gaussian distribution***, as demonstrated the following:\n",
    "\n",
    "![L1 vs L2](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_9_l1_l2.png \"L1 vs L2\")\n",
    "\n",
    "\n",
    "The following code uses L2 with linear regression (Ridge regression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 2.937572479248047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=3.88411e-10): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>origin-1</th>\n",
       "      <td>-1.444754</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.415851</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.007759</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.007473</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.024423</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.138104</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-3</th>\n",
       "      <td>0.629556</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.801221</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-2</th>\n",
       "      <td>0.817690</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef  positive\n",
       "origin-1     -1.444754     False\n",
       "cylinders    -0.415851     False\n",
       "horsepower   -0.007759     False\n",
       "weight       -0.007473     False\n",
       "displacement  0.024423      True\n",
       "acceleration  0.138104      True\n",
       "origin-3      0.629556      True\n",
       "year          0.801221      True\n",
       "origin-2      0.817690      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -18.25544548034668\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create linear regression\n",
    "regressor = Ridge(alpha=0.1)\n",
    "\n",
    "# Fit/train Ridge\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df.columns.values)\n",
    "names.remove(\"mpg\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet:   Linear regression with mixing L1 with L2.  \n",
    "    \n",
    "* $\\alpha$: Constant for penalty (regularization). \n",
    "    \n",
    "* l1_ratio : The ElasticNet mixing parameter, with 0 <= l1_ratio <= 1. For l1_ratio = 0 the penalty is an L2 penalty. For l1_ratio = 1 it is an L1 penalty.\n",
    "\n",
    "\n",
    "#### If you want the following:  a $*$ L1 + b $*$ L2,   set $\\alpha$ = a + b and l1_ratio = a / (a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 3.031985282897949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>origin-1</th>\n",
       "      <td>-0.938924</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.257568</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.007462</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.002896</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.017533</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.131320</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-3</th>\n",
       "      <td>0.369088</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-2</th>\n",
       "      <td>0.458725</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.788913</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef  positive\n",
       "origin-1     -0.938924     False\n",
       "cylinders    -0.257568     False\n",
       "weight       -0.007462     False\n",
       "horsepower   -0.002896     False\n",
       "displacement  0.017533      True\n",
       "acceleration  0.131320      True\n",
       "origin-3      0.369088      True\n",
       "origin-2      0.458725      True\n",
       "year          0.788913      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -17.4800968170166\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Create linear regression\n",
    "regressor = ElasticNet(alpha=0.1, l1_ratio=0.1)\n",
    "\n",
    "# Fit/train ElasticNet\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df.columns.values)\n",
    "names.remove(\"mpg\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1/L2 in Logistic Regression (Classification)? \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  L1/L2 in TensorFlow?\n",
    "\n",
    "L1 and L2 regularization work by adding a weight penalty to the neural network training.  \n",
    "\n",
    "### This penalty push the connection weights to small values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# TensorFlow with L1/L2 for Regression\n",
    "########################################\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "df.drop('name',1,inplace=True)\n",
    "missing_median(df, 'horsepower')\n",
    "encode_text_dummy(df, 'origin')\n",
    "x,y = to_xy(df,\"mpg\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can set three regularization params for Dense, Conv1D, Conv2D and Conv3D. \n",
    "\n",
    "keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "\n",
    "\n",
    "*** kernel_regularizer ***: Regularizer function applied to the kernel weights matrix. kernel regularizer will constantly decay the weights.\n",
    "\n",
    "*** activity_regularizer ***: Regularizer function applied to the output of the layer.  Activity regularizer will tend to make the output of the layer smaller.\n",
    "\n",
    "*** bias_regularizer ***: Regularizer function applied to the bias vector.\n",
    "\n",
    "https://keras.io/regularizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0923 18:19:34.073046 15920 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(50, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, \n",
    "                kernel_regularizer=regularizers.l1(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 298 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "298/298 - 0s - loss: 33383.5269 - val_loss: 5548.7580\n",
      "Epoch 2/100\n",
      "298/298 - 0s - loss: 5362.3602 - val_loss: 1821.3303\n",
      "Epoch 3/100\n",
      "298/298 - 0s - loss: 1541.5015 - val_loss: 1711.9823\n",
      "Epoch 4/100\n",
      "298/298 - 0s - loss: 1179.2420 - val_loss: 728.5416\n",
      "Epoch 5/100\n",
      "298/298 - 0s - loss: 656.7487 - val_loss: 448.6760\n",
      "Epoch 6/100\n",
      "298/298 - 0s - loss: 429.2057 - val_loss: 325.2816\n",
      "Epoch 7/100\n",
      "298/298 - 0s - loss: 312.0495 - val_loss: 241.1204\n",
      "Epoch 8/100\n",
      "298/298 - 0s - loss: 255.4706 - val_loss: 203.0658\n",
      "Epoch 9/100\n",
      "298/298 - 0s - loss: 225.0676 - val_loss: 177.3532\n",
      "Epoch 10/100\n",
      "298/298 - 0s - loss: 198.3537 - val_loss: 160.3631\n",
      "Epoch 11/100\n",
      "298/298 - 0s - loss: 177.0877 - val_loss: 155.0613\n",
      "Epoch 12/100\n",
      "298/298 - 0s - loss: 174.1592 - val_loss: 131.8113\n",
      "Epoch 13/100\n",
      "298/298 - 0s - loss: 153.2441 - val_loss: 116.0723\n",
      "Epoch 14/100\n",
      "298/298 - 0s - loss: 139.5486 - val_loss: 107.8158\n",
      "Epoch 15/100\n",
      "298/298 - 0s - loss: 130.9890 - val_loss: 102.6769\n",
      "Epoch 16/100\n",
      "298/298 - 0s - loss: 127.0864 - val_loss: 100.6811\n",
      "Epoch 17/100\n",
      "298/298 - 0s - loss: 120.9999 - val_loss: 95.0749\n",
      "Epoch 18/100\n",
      "298/298 - 0s - loss: 118.9244 - val_loss: 93.6698\n",
      "Epoch 19/100\n",
      "298/298 - 0s - loss: 117.9171 - val_loss: 91.4011\n",
      "Epoch 20/100\n",
      "298/298 - 0s - loss: 119.1833 - val_loss: 90.0029\n",
      "Epoch 21/100\n",
      "298/298 - 0s - loss: 121.3410 - val_loss: 92.4354\n",
      "Epoch 22/100\n",
      "298/298 - 0s - loss: 119.0321 - val_loss: 91.7975\n",
      "Epoch 23/100\n",
      "298/298 - 0s - loss: 110.0619 - val_loss: 87.0752\n",
      "Epoch 24/100\n",
      "298/298 - 0s - loss: 110.7244 - val_loss: 87.5365\n",
      "Epoch 25/100\n",
      "298/298 - 0s - loss: 110.7568 - val_loss: 88.9646\n",
      "Epoch 26/100\n",
      "298/298 - 0s - loss: 109.5084 - val_loss: 84.9203\n",
      "Epoch 27/100\n",
      "298/298 - 0s - loss: 103.8455 - val_loss: 83.7497\n",
      "Epoch 28/100\n",
      "298/298 - 0s - loss: 103.7833 - val_loss: 82.3818\n",
      "Epoch 29/100\n",
      "298/298 - 0s - loss: 102.3071 - val_loss: 84.4767\n",
      "Epoch 30/100\n",
      "298/298 - 0s - loss: 99.6304 - val_loss: 85.5485\n",
      "Epoch 31/100\n",
      "298/298 - 0s - loss: 99.5016 - val_loss: 80.5756\n",
      "Epoch 32/100\n",
      "298/298 - 0s - loss: 99.8650 - val_loss: 81.3914\n",
      "Epoch 33/100\n",
      "298/298 - 0s - loss: 98.5149 - val_loss: 80.1286\n",
      "Epoch 34/100\n",
      "298/298 - 0s - loss: 103.2051 - val_loss: 79.5559\n",
      "Epoch 35/100\n",
      "298/298 - 0s - loss: 95.9137 - val_loss: 78.9603\n",
      "Epoch 36/100\n",
      "298/298 - 0s - loss: 98.1412 - val_loss: 77.2594\n",
      "Epoch 37/100\n",
      "298/298 - 0s - loss: 94.2935 - val_loss: 77.3296\n",
      "Epoch 38/100\n",
      "298/298 - 0s - loss: 94.9826 - val_loss: 79.0126\n",
      "Epoch 39/100\n",
      "298/298 - 0s - loss: 94.1615 - val_loss: 80.2353\n",
      "Epoch 40/100\n",
      "298/298 - 0s - loss: 98.7900 - val_loss: 91.6061\n",
      "Epoch 41/100\n",
      "298/298 - 0s - loss: 93.6199 - val_loss: 76.3585\n",
      "Epoch 42/100\n",
      "298/298 - 0s - loss: 91.9163 - val_loss: 101.2141\n",
      "Epoch 43/100\n",
      "298/298 - 0s - loss: 98.4995 - val_loss: 87.4853\n",
      "Epoch 44/100\n",
      "298/298 - 0s - loss: 87.8829 - val_loss: 62.1509\n",
      "Epoch 45/100\n",
      "298/298 - 0s - loss: 73.0355 - val_loss: 63.1729\n",
      "Epoch 46/100\n",
      "298/298 - 0s - loss: 73.6374 - val_loss: 58.1400\n",
      "Epoch 47/100\n",
      "298/298 - 0s - loss: 69.9379 - val_loss: 57.8528\n",
      "Epoch 48/100\n",
      "298/298 - 0s - loss: 70.7818 - val_loss: 58.0561\n",
      "Epoch 49/100\n",
      "298/298 - 0s - loss: 69.3619 - val_loss: 75.1130\n",
      "Epoch 50/100\n",
      "298/298 - 0s - loss: 83.9551 - val_loss: 65.2160\n",
      "Epoch 51/100\n",
      "298/298 - 0s - loss: 68.2480 - val_loss: 61.5468\n",
      "Epoch 52/100\n",
      "298/298 - 0s - loss: 78.1726 - val_loss: 54.8450\n",
      "Epoch 53/100\n",
      "298/298 - 0s - loss: 72.7511 - val_loss: 59.7470\n",
      "Epoch 54/100\n",
      "298/298 - 0s - loss: 69.6643 - val_loss: 63.0221\n",
      "Epoch 55/100\n",
      "298/298 - 0s - loss: 71.7957 - val_loss: 63.8617\n",
      "Epoch 56/100\n",
      "298/298 - 0s - loss: 75.8238 - val_loss: 64.4910\n",
      "Epoch 57/100\n",
      "298/298 - 0s - loss: 62.6060 - val_loss: 59.8381\n",
      "Epoch 00057: early stopping\n",
      "Final score (RMSE): 7.076665878295898\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(1))   #  output layer\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=100)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout Layer  (A dedicated layer for regularization)\n",
    "\n",
    "#### Each dropout layer will drop neurons in its previous layer.\n",
    "\n",
    "*** To create a dropout layer, specify dropout probability.   ***  The dropout probability indicates the likelihood of a neuron dropping out for every batch during training. Typically this value is 0.1 to 0.5. \n",
    "\n",
    "*** Actually, a certain percentage of neurons will be masked during each training iteration.  All neurons return after training is complete.*** \n",
    "\n",
    "\n",
    "Animation that shows how [dropout works](https://yusugomori.com/projects/deep-learning/dropout-relu)\n",
    "\n",
    "#### A dropout layer can be added between any two hidden layers to reduce overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Code with Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin-1</th>\n",
       "      <th>origin-2</th>\n",
       "      <th>origin-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>454.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4354</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4312</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>4425</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>390.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3850</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>383.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3563</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>340.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>3609</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3761</td>\n",
       "      <td>9.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3086</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>199.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2774</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>14.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1835</td>\n",
       "      <td>20.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0   18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1   15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2   18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3   16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4   17.0          8         302.0       140.0    3449          10.5    70   \n",
       "5   15.0          8         429.0       198.0    4341          10.0    70   \n",
       "6   14.0          8         454.0       220.0    4354           9.0    70   \n",
       "7   14.0          8         440.0       215.0    4312           8.5    70   \n",
       "8   14.0          8         455.0       225.0    4425          10.0    70   \n",
       "9   15.0          8         390.0       190.0    3850           8.5    70   \n",
       "10  15.0          8         383.0       170.0    3563          10.0    70   \n",
       "11  14.0          8         340.0       160.0    3609           8.0    70   \n",
       "12  15.0          8         400.0       150.0    3761           9.5    70   \n",
       "13  14.0          8         455.0       225.0    3086          10.0    70   \n",
       "14  24.0          4         113.0        95.0    2372          15.0    70   \n",
       "15  22.0          6         198.0        95.0    2833          15.5    70   \n",
       "16  18.0          6         199.0        97.0    2774          15.5    70   \n",
       "17  21.0          6         200.0        85.0    2587          16.0    70   \n",
       "18  27.0          4          97.0        88.0    2130          14.5    70   \n",
       "19  26.0          4          97.0        46.0    1835          20.5    70   \n",
       "\n",
       "    origin-1  origin-2  origin-3  \n",
       "0          1         0         0  \n",
       "1          1         0         0  \n",
       "2          1         0         0  \n",
       "3          1         0         0  \n",
       "4          1         0         0  \n",
       "5          1         0         0  \n",
       "6          1         0         0  \n",
       "7          1         0         0  \n",
       "8          1         0         0  \n",
       "9          1         0         0  \n",
       "10         1         0         0  \n",
       "11         1         0         0  \n",
       "12         1         0         0  \n",
       "13         1         0         0  \n",
       "14         0         0         1  \n",
       "15         1         0         0  \n",
       "16         1         0         0  \n",
       "17         1         0         0  \n",
       "18         0         0         1  \n",
       "19         0         1         0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "# TensorFlow with Dropout for Regression\n",
    "############################################\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "df.drop('name',1,inplace=True)\n",
    "\n",
    "missing_median(df, 'horsepower')\n",
    "\n",
    "encode_text_dummy(df, 'origin')\n",
    "\n",
    "df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = to_xy(df,\"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 298 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "298/298 - 0s - loss: 45137.5978 - val_loss: 545.6902\n",
      "Epoch 2/1000\n",
      "298/298 - 0s - loss: 31483.9140 - val_loss: 5875.8979\n",
      "Epoch 3/1000\n",
      "298/298 - 0s - loss: 19701.5930 - val_loss: 399.8292\n",
      "Epoch 4/1000\n",
      "298/298 - 0s - loss: 15563.3631 - val_loss: 7745.5428\n",
      "Epoch 5/1000\n",
      "298/298 - 0s - loss: 13132.5204 - val_loss: 1264.1320\n",
      "Epoch 6/1000\n",
      "298/298 - 0s - loss: 10586.5725 - val_loss: 3675.7625\n",
      "Epoch 7/1000\n",
      "298/298 - 0s - loss: 9708.8782 - val_loss: 1103.6284\n",
      "Epoch 8/1000\n",
      "298/298 - 0s - loss: 7456.4856 - val_loss: 1583.2456\n",
      "Epoch 00008: early stopping\n",
      "Final score (RMSE): 39.79001998901367\n"
     ]
    }
   ],
   "source": [
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=x.shape[1]))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 50)                500       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,046\n",
      "Trainable params: 2,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection:  How 500 and 1275 were calcuated?\n",
    "\n",
    "1275 = 50*25 + 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "* [Google Colab](https://colab.research.google.com/) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow with free GPU support.  No setup needed.\n",
    "* [IBM Cognitive Class Labs](https://www.datascientistworkbench.com) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow.  No setup needed.\n",
    "* [Python Anaconda](https://www.continuum.io/downloads) - Python distribution that includes many data science packages, such as Numpy, Scipy, Scikit-Learn, Pandas, and much more.\n",
    "* [TensorFlow](https://www.tensorflow.org/) - Google's mathematics package for deep learning.\n",
    "* [Kaggle](https://www.kaggle.com/) - Competitive data science.  Good source of sample data.\n",
    "* T81-558: Applications of Deep Neural Networks. Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

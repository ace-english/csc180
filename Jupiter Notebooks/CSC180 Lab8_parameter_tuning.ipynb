{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 8: Parameter Tuning for Backpropagation \n",
    "\n",
    "\n",
    "#### CSC 180  Intelligent Systems (Fall 2019)\n",
    "\n",
    "#### Dr. Haiquan Chen, California State University, Sacramento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions for Tensorflow (Little Gems)\n",
    "\n",
    "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network. \n",
    "\n",
    "* Predictors/Inputs \n",
    "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
    "    * Encode textual/categorical values with **encode_text_dummy**.\n",
    "    * Encode numeric values with **encode_numeric_zscore**.\n",
    "* Output\n",
    "    * Discard rows with missing outputs.\n",
    "    * Encode textual/categorical values with **encode_text_index**.\n",
    "    * Do not encode output numeric values.\n",
    "* Produce final feature vectors (x) and expected output (y) with **to_xy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Learning rate\n",
    "Backpropagation is the primary means by which a neural network's weights are determined during training. Backpropagation works by calculating a weight change amount ($v_t$) for every weight($\\theta$, theata) in the neural network.  This value is subtracted from every weight by the following equation: \n",
    "\n",
    "$ \\theta_t = \\theta_{t-1} - v_t $\n",
    "\n",
    "\n",
    "### The learning rate is an important concept for backpropagation training.  Setting the learning rate can be complex:\n",
    "\n",
    "* Too low of a learning rate will usually converge to a good solution; however, the process will be very slow.\n",
    "* Too high of a learning rate will either fail outright, or converge to a higher error than a better learning rate.\n",
    "\n",
    "#### Common values for learning rate are: 0.1, 0.01, 0.001, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch size\n",
    "\n",
    "#### Number of samples per gradient update.  In keras, you may set the batch_size parameter in function fit()\n",
    "\n",
    "https://keras.io/models/model/\n",
    "\n",
    "batch_size: Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update rules (optimizers)\n",
    "\n",
    "The following image shows how each of these algorithms train (image credits: [author](http://sebastianruder.com/optimizing-gradient-descent/index.html#visualizationofalgorithms) ):\n",
    "\n",
    "![Training Techniques](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/contours_evaluation_optimizers.gif \"Training Techniques\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An optimizer is one of the two arguments required when you compile a Keras model using compile(). \n",
    "\n",
    "Specifying the Update Rule (Optimizer) in Tensorflow\n",
    "\n",
    "TensorFlow allows the update rule to be set to one of:\n",
    "\n",
    "* Adagrad\n",
    "* **Adam**\n",
    "* Ftrl\n",
    "* Momentum\n",
    "* RMSProp\n",
    "* **SGD**\n",
    "\n",
    "https://keras.io/optimizers/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either instantiate an optimizer or you can call it by its name. In the latter case, the default parameters for the optimizer will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "#adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using all Default Parameters for a Particular Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass optimizer by name: default parameters will be used\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Complete Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 318 samples, validate on 80 samples\n",
      "Epoch 1/1000\n",
      "318/318 - 1s - loss: 618.5678 - val_loss: 587.2327\n",
      "Epoch 2/1000\n",
      "318/318 - 0s - loss: 618.2572 - val_loss: 586.8145\n",
      "Epoch 3/1000\n",
      "318/318 - 0s - loss: 617.8846 - val_loss: 586.2677\n",
      "Epoch 4/1000\n",
      "318/318 - 0s - loss: 617.3848 - val_loss: 585.6389\n",
      "Epoch 5/1000\n",
      "318/318 - 0s - loss: 616.8405 - val_loss: 584.9390\n",
      "Epoch 6/1000\n",
      "318/318 - 0s - loss: 616.2495 - val_loss: 584.1628\n",
      "Epoch 7/1000\n",
      "318/318 - 0s - loss: 615.5438 - val_loss: 583.3048\n",
      "Epoch 8/1000\n",
      "318/318 - 0s - loss: 614.7590 - val_loss: 582.3987\n",
      "Epoch 9/1000\n",
      "318/318 - 0s - loss: 613.8702 - val_loss: 581.3989\n",
      "Epoch 10/1000\n",
      "318/318 - 0s - loss: 612.8481 - val_loss: 580.3062\n",
      "Epoch 11/1000\n",
      "318/318 - 0s - loss: 611.7978 - val_loss: 579.1297\n",
      "Epoch 12/1000\n",
      "318/318 - 0s - loss: 610.5891 - val_loss: 577.7399\n",
      "Epoch 13/1000\n",
      "318/318 - 0s - loss: 609.3481 - val_loss: 576.2731\n",
      "Epoch 14/1000\n",
      "318/318 - 0s - loss: 607.9943 - val_loss: 574.7656\n",
      "Epoch 15/1000\n",
      "318/318 - 0s - loss: 606.5213 - val_loss: 573.2209\n",
      "Epoch 16/1000\n",
      "318/318 - 0s - loss: 604.9632 - val_loss: 571.5409\n",
      "Epoch 17/1000\n",
      "318/318 - 0s - loss: 603.2379 - val_loss: 569.7061\n",
      "Epoch 18/1000\n",
      "318/318 - 0s - loss: 601.3680 - val_loss: 567.7682\n",
      "Epoch 19/1000\n",
      "318/318 - 0s - loss: 599.3511 - val_loss: 565.7289\n",
      "Epoch 20/1000\n",
      "318/318 - 0s - loss: 597.1904 - val_loss: 563.6099\n",
      "Epoch 21/1000\n",
      "318/318 - 0s - loss: 595.0368 - val_loss: 561.4658\n",
      "Epoch 22/1000\n",
      "318/318 - 0s - loss: 592.8678 - val_loss: 559.2740\n",
      "Epoch 23/1000\n",
      "318/318 - 0s - loss: 590.5799 - val_loss: 557.0303\n",
      "Epoch 24/1000\n",
      "318/318 - 0s - loss: 588.2642 - val_loss: 554.7509\n",
      "Epoch 25/1000\n",
      "318/318 - 0s - loss: 585.9839 - val_loss: 552.4647\n",
      "Epoch 26/1000\n",
      "318/318 - 0s - loss: 583.5866 - val_loss: 550.1454\n",
      "Epoch 27/1000\n",
      "318/318 - 0s - loss: 581.2849 - val_loss: 547.7352\n",
      "Epoch 28/1000\n",
      "318/318 - 0s - loss: 578.9286 - val_loss: 545.3141\n",
      "Epoch 29/1000\n",
      "318/318 - 0s - loss: 576.5358 - val_loss: 542.8907\n",
      "Epoch 30/1000\n",
      "318/318 - 0s - loss: 574.1118 - val_loss: 540.4850\n",
      "Epoch 31/1000\n",
      "318/318 - 0s - loss: 571.6862 - val_loss: 538.0794\n",
      "Epoch 32/1000\n",
      "318/318 - 0s - loss: 569.3133 - val_loss: 535.6664\n",
      "Epoch 33/1000\n",
      "318/318 - 0s - loss: 566.8256 - val_loss: 533.2689\n",
      "Epoch 34/1000\n",
      "318/318 - 0s - loss: 564.4286 - val_loss: 530.8580\n",
      "Epoch 35/1000\n",
      "318/318 - 0s - loss: 561.9549 - val_loss: 528.4606\n",
      "Epoch 36/1000\n",
      "318/318 - 0s - loss: 559.5463 - val_loss: 526.0587\n",
      "Epoch 37/1000\n",
      "318/318 - 0s - loss: 557.0933 - val_loss: 523.6633\n",
      "Epoch 38/1000\n",
      "318/318 - 0s - loss: 554.6991 - val_loss: 521.2701\n",
      "Epoch 39/1000\n",
      "318/318 - 0s - loss: 552.2315 - val_loss: 518.8928\n",
      "Epoch 40/1000\n",
      "318/318 - 0s - loss: 549.7905 - val_loss: 516.5229\n",
      "Epoch 41/1000\n",
      "318/318 - 0s - loss: 547.3408 - val_loss: 514.1561\n",
      "Epoch 42/1000\n",
      "318/318 - 0s - loss: 544.9127 - val_loss: 511.7721\n",
      "Epoch 43/1000\n",
      "318/318 - 0s - loss: 542.4766 - val_loss: 509.3797\n",
      "Epoch 44/1000\n",
      "318/318 - 0s - loss: 540.0386 - val_loss: 506.9818\n",
      "Epoch 45/1000\n",
      "318/318 - 0s - loss: 537.5903 - val_loss: 504.5765\n",
      "Epoch 46/1000\n",
      "318/318 - 0s - loss: 535.0511 - val_loss: 502.1729\n",
      "Epoch 47/1000\n",
      "318/318 - 0s - loss: 532.6186 - val_loss: 499.7388\n",
      "Epoch 48/1000\n",
      "318/318 - 0s - loss: 530.1304 - val_loss: 497.3056\n",
      "Epoch 49/1000\n",
      "318/318 - 0s - loss: 527.5964 - val_loss: 494.8740\n",
      "Epoch 50/1000\n",
      "318/318 - 0s - loss: 525.0917 - val_loss: 492.4252\n",
      "Epoch 51/1000\n",
      "318/318 - 0s - loss: 522.5783 - val_loss: 489.9589\n",
      "Epoch 52/1000\n",
      "318/318 - 0s - loss: 520.0488 - val_loss: 487.4760\n",
      "Epoch 53/1000\n",
      "318/318 - 0s - loss: 517.4989 - val_loss: 484.9754\n",
      "Epoch 54/1000\n",
      "318/318 - 0s - loss: 514.9359 - val_loss: 482.4612\n",
      "Epoch 55/1000\n",
      "318/318 - 0s - loss: 512.3189 - val_loss: 479.9410\n",
      "Epoch 56/1000\n",
      "318/318 - 0s - loss: 509.7857 - val_loss: 477.3906\n",
      "Epoch 57/1000\n",
      "318/318 - 0s - loss: 507.1976 - val_loss: 474.8255\n",
      "Epoch 58/1000\n",
      "318/318 - 0s - loss: 504.5231 - val_loss: 472.2556\n",
      "Epoch 59/1000\n",
      "318/318 - 0s - loss: 501.9723 - val_loss: 469.6551\n",
      "Epoch 60/1000\n",
      "318/318 - 0s - loss: 499.3198 - val_loss: 467.0527\n",
      "Epoch 61/1000\n",
      "318/318 - 0s - loss: 496.6981 - val_loss: 464.4405\n",
      "Epoch 62/1000\n",
      "318/318 - 0s - loss: 494.0199 - val_loss: 461.8354\n",
      "Epoch 63/1000\n",
      "318/318 - 0s - loss: 491.3585 - val_loss: 459.2243\n",
      "Epoch 64/1000\n",
      "318/318 - 0s - loss: 488.6461 - val_loss: 456.6058\n",
      "Epoch 65/1000\n",
      "318/318 - 0s - loss: 486.0046 - val_loss: 453.9667\n",
      "Epoch 66/1000\n",
      "318/318 - 0s - loss: 483.2430 - val_loss: 451.3228\n",
      "Epoch 67/1000\n",
      "318/318 - 0s - loss: 480.5987 - val_loss: 448.6463\n",
      "Epoch 68/1000\n",
      "318/318 - 0s - loss: 477.8446 - val_loss: 445.9680\n",
      "Epoch 69/1000\n",
      "318/318 - 0s - loss: 475.0882 - val_loss: 443.2797\n",
      "Epoch 70/1000\n",
      "318/318 - 0s - loss: 472.3083 - val_loss: 440.5834\n",
      "Epoch 71/1000\n",
      "318/318 - 0s - loss: 469.6137 - val_loss: 437.8701\n",
      "Epoch 72/1000\n",
      "318/318 - 0s - loss: 466.7925 - val_loss: 435.1707\n",
      "Epoch 73/1000\n",
      "318/318 - 0s - loss: 464.0255 - val_loss: 432.4648\n",
      "Epoch 74/1000\n",
      "318/318 - 0s - loss: 461.2729 - val_loss: 429.7455\n",
      "Epoch 75/1000\n",
      "318/318 - 0s - loss: 458.4573 - val_loss: 427.0235\n",
      "Epoch 76/1000\n",
      "318/318 - 0s - loss: 455.6754 - val_loss: 424.2825\n",
      "Epoch 77/1000\n",
      "318/318 - 0s - loss: 452.8563 - val_loss: 421.5301\n",
      "Epoch 78/1000\n",
      "318/318 - 0s - loss: 450.0423 - val_loss: 418.7663\n",
      "Epoch 79/1000\n",
      "318/318 - 0s - loss: 447.2006 - val_loss: 416.0031\n",
      "Epoch 80/1000\n",
      "318/318 - 0s - loss: 444.3579 - val_loss: 413.2309\n",
      "Epoch 81/1000\n",
      "318/318 - 0s - loss: 441.5213 - val_loss: 410.4504\n",
      "Epoch 82/1000\n",
      "318/318 - 0s - loss: 438.6154 - val_loss: 407.6803\n",
      "Epoch 83/1000\n",
      "318/318 - 0s - loss: 435.7356 - val_loss: 404.9074\n",
      "Epoch 84/1000\n",
      "318/318 - 0s - loss: 432.8700 - val_loss: 402.1302\n",
      "Epoch 85/1000\n",
      "318/318 - 0s - loss: 430.0362 - val_loss: 399.3438\n",
      "Epoch 86/1000\n",
      "318/318 - 0s - loss: 427.1307 - val_loss: 396.5586\n",
      "Epoch 87/1000\n",
      "318/318 - 0s - loss: 424.2746 - val_loss: 393.7689\n",
      "Epoch 88/1000\n",
      "318/318 - 0s - loss: 421.3407 - val_loss: 390.9810\n",
      "Epoch 89/1000\n",
      "318/318 - 0s - loss: 418.4628 - val_loss: 388.1798\n",
      "Epoch 90/1000\n",
      "318/318 - 0s - loss: 415.5525 - val_loss: 385.3841\n",
      "Epoch 91/1000\n",
      "318/318 - 0s - loss: 412.6498 - val_loss: 382.5880\n",
      "Epoch 92/1000\n",
      "318/318 - 0s - loss: 409.7496 - val_loss: 379.7942\n",
      "Epoch 93/1000\n",
      "318/318 - 0s - loss: 406.8289 - val_loss: 377.0131\n",
      "Epoch 94/1000\n",
      "318/318 - 0s - loss: 403.8932 - val_loss: 374.2359\n",
      "Epoch 95/1000\n",
      "318/318 - 0s - loss: 401.0487 - val_loss: 371.4411\n",
      "Epoch 96/1000\n",
      "318/318 - 0s - loss: 398.0736 - val_loss: 368.6635\n",
      "Epoch 97/1000\n",
      "318/318 - 0s - loss: 395.1930 - val_loss: 365.8796\n",
      "Epoch 98/1000\n",
      "318/318 - 0s - loss: 392.2804 - val_loss: 363.1047\n",
      "Epoch 99/1000\n",
      "318/318 - 0s - loss: 389.3770 - val_loss: 360.3325\n",
      "Epoch 100/1000\n",
      "318/318 - 0s - loss: 386.4799 - val_loss: 357.5571\n",
      "Epoch 101/1000\n",
      "318/318 - 0s - loss: 383.5460 - val_loss: 354.7887\n",
      "Epoch 102/1000\n",
      "318/318 - 0s - loss: 380.6430 - val_loss: 352.0168\n",
      "Epoch 103/1000\n",
      "318/318 - 0s - loss: 377.7302 - val_loss: 349.2454\n",
      "Epoch 104/1000\n",
      "318/318 - 0s - loss: 374.8555 - val_loss: 346.4680\n",
      "Epoch 105/1000\n",
      "318/318 - 0s - loss: 371.9084 - val_loss: 343.6985\n",
      "Epoch 106/1000\n",
      "318/318 - 0s - loss: 368.9909 - val_loss: 340.9319\n",
      "Epoch 107/1000\n",
      "318/318 - 0s - loss: 366.0896 - val_loss: 338.1619\n",
      "Epoch 108/1000\n",
      "318/318 - 0s - loss: 363.1626 - val_loss: 335.3971\n",
      "Epoch 109/1000\n",
      "318/318 - 0s - loss: 360.2602 - val_loss: 332.6392\n",
      "Epoch 110/1000\n",
      "318/318 - 0s - loss: 357.3490 - val_loss: 329.8910\n",
      "Epoch 111/1000\n",
      "318/318 - 0s - loss: 354.4202 - val_loss: 327.1470\n",
      "Epoch 112/1000\n",
      "318/318 - 0s - loss: 351.5471 - val_loss: 324.4014\n",
      "Epoch 113/1000\n",
      "318/318 - 0s - loss: 348.6548 - val_loss: 321.6662\n",
      "Epoch 114/1000\n",
      "318/318 - 0s - loss: 345.7685 - val_loss: 318.9505\n",
      "Epoch 115/1000\n",
      "318/318 - 0s - loss: 342.8565 - val_loss: 316.2450\n",
      "Epoch 116/1000\n",
      "318/318 - 0s - loss: 340.0027 - val_loss: 313.5300\n",
      "Epoch 117/1000\n",
      "318/318 - 0s - loss: 337.1187 - val_loss: 310.8211\n",
      "Epoch 118/1000\n",
      "318/318 - 0s - loss: 334.2429 - val_loss: 308.1126\n",
      "Epoch 119/1000\n",
      "318/318 - 0s - loss: 331.4034 - val_loss: 305.4046\n",
      "Epoch 120/1000\n",
      "318/318 - 0s - loss: 328.5132 - val_loss: 302.7104\n",
      "Epoch 121/1000\n",
      "318/318 - 0s - loss: 325.6993 - val_loss: 300.0209\n",
      "Epoch 122/1000\n",
      "318/318 - 0s - loss: 322.8059 - val_loss: 297.3659\n",
      "Epoch 123/1000\n",
      "318/318 - 0s - loss: 319.9941 - val_loss: 294.7220\n",
      "Epoch 124/1000\n",
      "318/318 - 0s - loss: 317.1379 - val_loss: 292.0945\n",
      "Epoch 125/1000\n",
      "318/318 - 0s - loss: 314.2959 - val_loss: 289.4654\n",
      "Epoch 126/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 - 0s - loss: 311.5181 - val_loss: 286.8229\n",
      "Epoch 127/1000\n",
      "318/318 - 0s - loss: 308.7377 - val_loss: 284.1810\n",
      "Epoch 128/1000\n",
      "318/318 - 0s - loss: 305.8568 - val_loss: 281.5704\n",
      "Epoch 129/1000\n",
      "318/318 - 0s - loss: 303.0652 - val_loss: 278.9645\n",
      "Epoch 130/1000\n",
      "318/318 - 0s - loss: 300.3214 - val_loss: 276.3552\n",
      "Epoch 131/1000\n",
      "318/318 - 0s - loss: 297.4767 - val_loss: 273.7745\n",
      "Epoch 132/1000\n",
      "318/318 - 0s - loss: 294.6738 - val_loss: 271.1953\n",
      "Epoch 133/1000\n",
      "318/318 - 0s - loss: 291.9512 - val_loss: 268.6108\n",
      "Epoch 134/1000\n",
      "318/318 - 0s - loss: 289.1896 - val_loss: 266.0419\n",
      "Epoch 135/1000\n",
      "318/318 - 0s - loss: 286.4014 - val_loss: 263.4884\n",
      "Epoch 136/1000\n",
      "318/318 - 0s - loss: 283.6657 - val_loss: 260.9425\n",
      "Epoch 137/1000\n",
      "318/318 - 0s - loss: 280.9329 - val_loss: 258.4130\n",
      "Epoch 138/1000\n",
      "318/318 - 0s - loss: 278.2310 - val_loss: 255.8945\n",
      "Epoch 139/1000\n",
      "318/318 - 0s - loss: 275.4700 - val_loss: 253.4001\n",
      "Epoch 140/1000\n",
      "318/318 - 0s - loss: 272.7865 - val_loss: 250.9084\n",
      "Epoch 141/1000\n",
      "318/318 - 0s - loss: 270.0947 - val_loss: 248.4232\n",
      "Epoch 142/1000\n",
      "318/318 - 0s - loss: 267.4217 - val_loss: 245.9486\n",
      "Epoch 143/1000\n",
      "318/318 - 0s - loss: 264.7837 - val_loss: 243.4866\n",
      "Epoch 144/1000\n",
      "318/318 - 0s - loss: 262.0900 - val_loss: 241.0457\n",
      "Epoch 145/1000\n",
      "318/318 - 0s - loss: 259.4503 - val_loss: 238.6096\n",
      "Epoch 146/1000\n",
      "318/318 - 0s - loss: 256.8308 - val_loss: 236.1828\n",
      "Epoch 147/1000\n",
      "318/318 - 0s - loss: 254.1834 - val_loss: 233.7690\n",
      "Epoch 148/1000\n",
      "318/318 - 0s - loss: 251.5700 - val_loss: 231.3606\n",
      "Epoch 149/1000\n",
      "318/318 - 0s - loss: 248.9755 - val_loss: 228.9658\n",
      "Epoch 150/1000\n",
      "318/318 - 0s - loss: 246.4163 - val_loss: 226.5834\n",
      "Epoch 151/1000\n",
      "318/318 - 0s - loss: 243.7697 - val_loss: 224.2272\n",
      "Epoch 152/1000\n",
      "318/318 - 0s - loss: 241.2610 - val_loss: 221.8604\n",
      "Epoch 153/1000\n",
      "318/318 - 0s - loss: 238.7193 - val_loss: 219.5000\n",
      "Epoch 154/1000\n",
      "318/318 - 0s - loss: 236.1100 - val_loss: 217.1640\n",
      "Epoch 155/1000\n",
      "318/318 - 0s - loss: 233.6160 - val_loss: 214.8354\n",
      "Epoch 156/1000\n",
      "318/318 - 0s - loss: 231.0536 - val_loss: 212.5414\n",
      "Epoch 157/1000\n",
      "318/318 - 0s - loss: 228.5002 - val_loss: 210.2583\n",
      "Epoch 158/1000\n",
      "318/318 - 0s - loss: 226.0393 - val_loss: 207.9737\n",
      "Epoch 159/1000\n",
      "318/318 - 0s - loss: 223.5174 - val_loss: 205.7048\n",
      "Epoch 160/1000\n",
      "318/318 - 0s - loss: 221.0404 - val_loss: 203.4422\n",
      "Epoch 161/1000\n",
      "318/318 - 0s - loss: 218.5305 - val_loss: 201.1902\n",
      "Epoch 162/1000\n",
      "318/318 - 0s - loss: 216.1183 - val_loss: 198.9361\n",
      "Epoch 163/1000\n",
      "318/318 - 0s - loss: 213.6503 - val_loss: 196.7008\n",
      "Epoch 164/1000\n",
      "318/318 - 0s - loss: 211.2358 - val_loss: 194.4719\n",
      "Epoch 165/1000\n",
      "318/318 - 0s - loss: 208.7993 - val_loss: 192.2586\n",
      "Epoch 166/1000\n",
      "318/318 - 0s - loss: 206.3158 - val_loss: 190.0543\n",
      "Epoch 167/1000\n",
      "318/318 - 0s - loss: 203.9989 - val_loss: 187.8246\n",
      "Epoch 168/1000\n",
      "318/318 - 0s - loss: 201.5598 - val_loss: 185.6268\n",
      "Epoch 169/1000\n",
      "318/318 - 0s - loss: 199.2231 - val_loss: 183.4326\n",
      "Epoch 170/1000\n",
      "318/318 - 0s - loss: 196.7819 - val_loss: 181.2666\n",
      "Epoch 171/1000\n",
      "318/318 - 0s - loss: 194.3987 - val_loss: 179.1137\n",
      "Epoch 172/1000\n",
      "318/318 - 0s - loss: 192.0885 - val_loss: 176.9612\n",
      "Epoch 173/1000\n",
      "318/318 - 0s - loss: 189.7212 - val_loss: 174.8249\n",
      "Epoch 174/1000\n",
      "318/318 - 0s - loss: 187.3842 - val_loss: 172.6928\n",
      "Epoch 175/1000\n",
      "318/318 - 0s - loss: 185.0433 - val_loss: 170.5698\n",
      "Epoch 176/1000\n",
      "318/318 - 0s - loss: 182.7402 - val_loss: 168.4549\n",
      "Epoch 177/1000\n",
      "318/318 - 0s - loss: 180.3910 - val_loss: 166.3524\n",
      "Epoch 178/1000\n",
      "318/318 - 0s - loss: 178.0813 - val_loss: 164.2469\n",
      "Epoch 179/1000\n",
      "318/318 - 0s - loss: 175.7457 - val_loss: 162.1384\n",
      "Epoch 180/1000\n",
      "318/318 - 0s - loss: 173.4343 - val_loss: 160.0357\n",
      "Epoch 181/1000\n",
      "318/318 - 0s - loss: 171.1221 - val_loss: 157.9353\n",
      "Epoch 182/1000\n",
      "318/318 - 0s - loss: 168.8431 - val_loss: 155.8212\n",
      "Epoch 183/1000\n",
      "318/318 - 0s - loss: 166.5312 - val_loss: 153.7178\n",
      "Epoch 184/1000\n",
      "318/318 - 0s - loss: 164.2402 - val_loss: 151.6254\n",
      "Epoch 185/1000\n",
      "318/318 - 0s - loss: 161.9877 - val_loss: 149.5516\n",
      "Epoch 186/1000\n",
      "318/318 - 0s - loss: 159.7082 - val_loss: 147.5042\n",
      "Epoch 187/1000\n",
      "318/318 - 0s - loss: 157.4120 - val_loss: 145.4804\n",
      "Epoch 188/1000\n",
      "318/318 - 0s - loss: 155.2176 - val_loss: 143.4584\n",
      "Epoch 189/1000\n",
      "318/318 - 0s - loss: 152.9729 - val_loss: 141.4653\n",
      "Epoch 190/1000\n",
      "318/318 - 0s - loss: 150.7849 - val_loss: 139.4929\n",
      "Epoch 191/1000\n",
      "318/318 - 0s - loss: 148.5724 - val_loss: 137.5329\n",
      "Epoch 192/1000\n",
      "318/318 - 0s - loss: 146.4261 - val_loss: 135.5655\n",
      "Epoch 193/1000\n",
      "318/318 - 0s - loss: 144.2365 - val_loss: 133.6209\n",
      "Epoch 194/1000\n",
      "318/318 - 0s - loss: 142.0526 - val_loss: 131.6926\n",
      "Epoch 195/1000\n",
      "318/318 - 0s - loss: 139.9331 - val_loss: 129.7678\n",
      "Epoch 196/1000\n",
      "318/318 - 0s - loss: 137.8144 - val_loss: 127.8436\n",
      "Epoch 197/1000\n",
      "318/318 - 0s - loss: 135.6590 - val_loss: 125.9411\n",
      "Epoch 198/1000\n",
      "318/318 - 0s - loss: 133.5361 - val_loss: 124.0492\n",
      "Epoch 199/1000\n",
      "318/318 - 0s - loss: 131.4258 - val_loss: 122.1521\n",
      "Epoch 200/1000\n",
      "318/318 - 0s - loss: 129.3491 - val_loss: 120.2548\n",
      "Epoch 201/1000\n",
      "318/318 - 0s - loss: 127.2730 - val_loss: 118.3717\n",
      "Epoch 202/1000\n",
      "318/318 - 0s - loss: 125.1418 - val_loss: 116.5172\n",
      "Epoch 203/1000\n",
      "318/318 - 0s - loss: 123.0970 - val_loss: 114.6711\n",
      "Epoch 204/1000\n",
      "318/318 - 0s - loss: 121.0533 - val_loss: 112.8509\n",
      "Epoch 205/1000\n",
      "318/318 - 0s - loss: 119.0290 - val_loss: 111.0497\n",
      "Epoch 206/1000\n",
      "318/318 - 0s - loss: 117.0268 - val_loss: 109.2554\n",
      "Epoch 207/1000\n",
      "318/318 - 0s - loss: 115.0624 - val_loss: 107.4622\n",
      "Epoch 208/1000\n",
      "318/318 - 0s - loss: 113.0498 - val_loss: 105.6960\n",
      "Epoch 209/1000\n",
      "318/318 - 0s - loss: 111.1089 - val_loss: 103.9481\n",
      "Epoch 210/1000\n",
      "318/318 - 0s - loss: 109.1055 - val_loss: 102.2405\n",
      "Epoch 211/1000\n",
      "318/318 - 0s - loss: 107.2440 - val_loss: 100.5339\n",
      "Epoch 212/1000\n",
      "318/318 - 0s - loss: 105.2999 - val_loss: 98.8468\n",
      "Epoch 213/1000\n",
      "318/318 - 0s - loss: 103.4503 - val_loss: 97.1675\n",
      "Epoch 214/1000\n",
      "318/318 - 0s - loss: 101.5833 - val_loss: 95.5163\n",
      "Epoch 215/1000\n",
      "318/318 - 0s - loss: 99.7838 - val_loss: 93.8833\n",
      "Epoch 216/1000\n",
      "318/318 - 0s - loss: 97.9651 - val_loss: 92.2733\n",
      "Epoch 217/1000\n",
      "318/318 - 0s - loss: 96.2059 - val_loss: 90.6868\n",
      "Epoch 218/1000\n",
      "318/318 - 0s - loss: 94.4741 - val_loss: 89.1280\n",
      "Epoch 219/1000\n",
      "318/318 - 0s - loss: 92.6986 - val_loss: 87.6085\n",
      "Epoch 220/1000\n",
      "318/318 - 0s - loss: 91.0305 - val_loss: 86.0990\n",
      "Epoch 221/1000\n",
      "318/318 - 0s - loss: 89.3491 - val_loss: 84.6148\n",
      "Epoch 222/1000\n",
      "318/318 - 0s - loss: 87.6965 - val_loss: 83.1521\n",
      "Epoch 223/1000\n",
      "318/318 - 0s - loss: 86.0968 - val_loss: 81.7046\n",
      "Epoch 224/1000\n",
      "318/318 - 0s - loss: 84.4953 - val_loss: 80.2824\n",
      "Epoch 225/1000\n",
      "318/318 - 0s - loss: 82.9078 - val_loss: 78.8977\n",
      "Epoch 226/1000\n",
      "318/318 - 0s - loss: 81.3794 - val_loss: 77.5354\n",
      "Epoch 227/1000\n",
      "318/318 - 0s - loss: 79.8458 - val_loss: 76.1968\n",
      "Epoch 228/1000\n",
      "318/318 - 0s - loss: 78.3704 - val_loss: 74.8776\n",
      "Epoch 229/1000\n",
      "318/318 - 0s - loss: 76.9170 - val_loss: 73.5877\n",
      "Epoch 230/1000\n",
      "318/318 - 0s - loss: 75.5089 - val_loss: 72.3205\n",
      "Epoch 231/1000\n",
      "318/318 - 0s - loss: 74.0882 - val_loss: 71.0873\n",
      "Epoch 232/1000\n",
      "318/318 - 0s - loss: 72.7075 - val_loss: 69.8855\n",
      "Epoch 233/1000\n",
      "318/318 - 0s - loss: 71.4126 - val_loss: 68.7043\n",
      "Epoch 234/1000\n",
      "318/318 - 0s - loss: 70.0541 - val_loss: 67.5618\n",
      "Epoch 235/1000\n",
      "318/318 - 0s - loss: 68.7890 - val_loss: 66.4347\n",
      "Epoch 236/1000\n",
      "318/318 - 0s - loss: 67.5162 - val_loss: 65.3262\n",
      "Epoch 237/1000\n",
      "318/318 - 0s - loss: 66.2919 - val_loss: 64.2361\n",
      "Epoch 238/1000\n",
      "318/318 - 0s - loss: 65.0831 - val_loss: 63.1719\n",
      "Epoch 239/1000\n",
      "318/318 - 0s - loss: 63.8925 - val_loss: 62.1374\n",
      "Epoch 240/1000\n",
      "318/318 - 0s - loss: 62.7433 - val_loss: 61.1295\n",
      "Epoch 241/1000\n",
      "318/318 - 0s - loss: 61.6048 - val_loss: 60.1499\n",
      "Epoch 242/1000\n",
      "318/318 - 0s - loss: 60.5058 - val_loss: 59.1968\n",
      "Epoch 243/1000\n",
      "318/318 - 0s - loss: 59.4354 - val_loss: 58.2692\n",
      "Epoch 244/1000\n",
      "318/318 - 0s - loss: 58.4176 - val_loss: 57.3640\n",
      "Epoch 245/1000\n",
      "318/318 - 0s - loss: 57.3610 - val_loss: 56.4934\n",
      "Epoch 246/1000\n",
      "318/318 - 0s - loss: 56.3812 - val_loss: 55.6421\n",
      "Epoch 247/1000\n",
      "318/318 - 0s - loss: 55.4450 - val_loss: 54.8059\n",
      "Epoch 248/1000\n",
      "318/318 - 0s - loss: 54.4971 - val_loss: 53.9943\n",
      "Epoch 249/1000\n",
      "318/318 - 0s - loss: 53.5544 - val_loss: 53.2125\n",
      "Epoch 250/1000\n",
      "318/318 - 0s - loss: 52.6720 - val_loss: 52.4460\n",
      "Epoch 251/1000\n",
      "318/318 - 0s - loss: 51.7969 - val_loss: 51.6980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/1000\n",
      "318/318 - 0s - loss: 50.9508 - val_loss: 50.9717\n",
      "Epoch 253/1000\n",
      "318/318 - 0s - loss: 50.1247 - val_loss: 50.2676\n",
      "Epoch 254/1000\n",
      "318/318 - 0s - loss: 49.3402 - val_loss: 49.5838\n",
      "Epoch 255/1000\n",
      "318/318 - 0s - loss: 48.5291 - val_loss: 48.9317\n",
      "Epoch 256/1000\n",
      "318/318 - 0s - loss: 47.7732 - val_loss: 48.2899\n",
      "Epoch 257/1000\n",
      "318/318 - 0s - loss: 47.0601 - val_loss: 47.6578\n",
      "Epoch 258/1000\n",
      "318/318 - 0s - loss: 46.3398 - val_loss: 47.0442\n",
      "Epoch 259/1000\n",
      "318/318 - 0s - loss: 45.6433 - val_loss: 46.4496\n",
      "Epoch 260/1000\n",
      "318/318 - 0s - loss: 44.9383 - val_loss: 45.8754\n",
      "Epoch 261/1000\n",
      "318/318 - 0s - loss: 44.3039 - val_loss: 45.3119\n",
      "Epoch 262/1000\n",
      "318/318 - 0s - loss: 43.6530 - val_loss: 44.7667\n",
      "Epoch 263/1000\n",
      "318/318 - 0s - loss: 43.0307 - val_loss: 44.2301\n",
      "Epoch 264/1000\n",
      "318/318 - 0s - loss: 42.4217 - val_loss: 43.7086\n",
      "Epoch 265/1000\n",
      "318/318 - 0s - loss: 41.8454 - val_loss: 43.2015\n",
      "Epoch 266/1000\n",
      "318/318 - 0s - loss: 41.2670 - val_loss: 42.7145\n",
      "Epoch 267/1000\n",
      "318/318 - 0s - loss: 40.7226 - val_loss: 42.2385\n",
      "Epoch 268/1000\n",
      "318/318 - 0s - loss: 40.1896 - val_loss: 41.7749\n",
      "Epoch 269/1000\n",
      "318/318 - 0s - loss: 39.6564 - val_loss: 41.3214\n",
      "Epoch 270/1000\n",
      "318/318 - 0s - loss: 39.1442 - val_loss: 40.8753\n",
      "Epoch 271/1000\n",
      "318/318 - 0s - loss: 38.6731 - val_loss: 40.4350\n",
      "Epoch 272/1000\n",
      "318/318 - 0s - loss: 38.1722 - val_loss: 40.0139\n",
      "Epoch 273/1000\n",
      "318/318 - 0s - loss: 37.6977 - val_loss: 39.6059\n",
      "Epoch 274/1000\n",
      "318/318 - 0s - loss: 37.2571 - val_loss: 39.2045\n",
      "Epoch 275/1000\n",
      "318/318 - 0s - loss: 36.8142 - val_loss: 38.8178\n",
      "Epoch 276/1000\n",
      "318/318 - 0s - loss: 36.3736 - val_loss: 38.4437\n",
      "Epoch 277/1000\n",
      "318/318 - 0s - loss: 35.9499 - val_loss: 38.0798\n",
      "Epoch 278/1000\n",
      "318/318 - 0s - loss: 35.5649 - val_loss: 37.7176\n",
      "Epoch 279/1000\n",
      "318/318 - 0s - loss: 35.1563 - val_loss: 37.3676\n",
      "Epoch 280/1000\n",
      "318/318 - 0s - loss: 34.7935 - val_loss: 37.0194\n",
      "Epoch 281/1000\n",
      "318/318 - 0s - loss: 34.4127 - val_loss: 36.6853\n",
      "Epoch 282/1000\n",
      "318/318 - 0s - loss: 34.0464 - val_loss: 36.3585\n",
      "Epoch 283/1000\n",
      "318/318 - 0s - loss: 33.6798 - val_loss: 36.0400\n",
      "Epoch 284/1000\n",
      "318/318 - 0s - loss: 33.3466 - val_loss: 35.7247\n",
      "Epoch 285/1000\n",
      "318/318 - 0s - loss: 33.0131 - val_loss: 35.4179\n",
      "Epoch 286/1000\n",
      "318/318 - 0s - loss: 32.6887 - val_loss: 35.1201\n",
      "Epoch 287/1000\n",
      "318/318 - 0s - loss: 32.3687 - val_loss: 34.8319\n",
      "Epoch 288/1000\n",
      "318/318 - 0s - loss: 32.0633 - val_loss: 34.5498\n",
      "Epoch 289/1000\n",
      "318/318 - 0s - loss: 31.7530 - val_loss: 34.2724\n",
      "Epoch 290/1000\n",
      "318/318 - 0s - loss: 31.4849 - val_loss: 33.9973\n",
      "Epoch 291/1000\n",
      "318/318 - 0s - loss: 31.1816 - val_loss: 33.7370\n",
      "Epoch 292/1000\n",
      "318/318 - 0s - loss: 30.9124 - val_loss: 33.4825\n",
      "Epoch 293/1000\n",
      "318/318 - 0s - loss: 30.6472 - val_loss: 33.2304\n",
      "Epoch 294/1000\n",
      "318/318 - 0s - loss: 30.4047 - val_loss: 32.9842\n",
      "Epoch 295/1000\n",
      "318/318 - 0s - loss: 30.1429 - val_loss: 32.7446\n",
      "Epoch 296/1000\n",
      "318/318 - 0s - loss: 29.8904 - val_loss: 32.5108\n",
      "Epoch 297/1000\n",
      "318/318 - 0s - loss: 29.6693 - val_loss: 32.2771\n",
      "Epoch 298/1000\n",
      "318/318 - 0s - loss: 29.4248 - val_loss: 32.0555\n",
      "Epoch 299/1000\n",
      "318/318 - 0s - loss: 29.2071 - val_loss: 31.8363\n",
      "Epoch 300/1000\n",
      "318/318 - 0s - loss: 28.9640 - val_loss: 31.6228\n",
      "Epoch 301/1000\n",
      "318/318 - 0s - loss: 28.7640 - val_loss: 31.4070\n",
      "Epoch 302/1000\n",
      "318/318 - 0s - loss: 28.5565 - val_loss: 31.1912\n",
      "Epoch 303/1000\n",
      "318/318 - 0s - loss: 28.3468 - val_loss: 30.9814\n",
      "Epoch 304/1000\n",
      "318/318 - 0s - loss: 28.1325 - val_loss: 30.7785\n",
      "Epoch 305/1000\n",
      "318/318 - 0s - loss: 27.9344 - val_loss: 30.5752\n",
      "Epoch 306/1000\n",
      "318/318 - 0s - loss: 27.7370 - val_loss: 30.3746\n",
      "Epoch 307/1000\n",
      "318/318 - 0s - loss: 27.5494 - val_loss: 30.1760\n",
      "Epoch 308/1000\n",
      "318/318 - 0s - loss: 27.3612 - val_loss: 29.9782\n",
      "Epoch 309/1000\n",
      "318/318 - 0s - loss: 27.1703 - val_loss: 29.7840\n",
      "Epoch 310/1000\n",
      "318/318 - 0s - loss: 26.9885 - val_loss: 29.5933\n",
      "Epoch 311/1000\n",
      "318/318 - 0s - loss: 26.8091 - val_loss: 29.4018\n",
      "Epoch 312/1000\n",
      "318/318 - 0s - loss: 26.6349 - val_loss: 29.2130\n",
      "Epoch 313/1000\n",
      "318/318 - 0s - loss: 26.4522 - val_loss: 29.0290\n",
      "Epoch 314/1000\n",
      "318/318 - 0s - loss: 26.2823 - val_loss: 28.8469\n",
      "Epoch 315/1000\n",
      "318/318 - 0s - loss: 26.1130 - val_loss: 28.6648\n",
      "Epoch 316/1000\n",
      "318/318 - 0s - loss: 25.9501 - val_loss: 28.4824\n",
      "Epoch 317/1000\n",
      "318/318 - 0s - loss: 25.7757 - val_loss: 28.3060\n",
      "Epoch 318/1000\n",
      "318/318 - 0s - loss: 25.6087 - val_loss: 28.1284\n",
      "Epoch 319/1000\n",
      "318/318 - 0s - loss: 25.4486 - val_loss: 27.9519\n",
      "Epoch 320/1000\n",
      "318/318 - 0s - loss: 25.2960 - val_loss: 27.7806\n",
      "Epoch 321/1000\n",
      "318/318 - 0s - loss: 25.1219 - val_loss: 27.6152\n",
      "Epoch 322/1000\n",
      "318/318 - 0s - loss: 24.9832 - val_loss: 27.4462\n",
      "Epoch 323/1000\n",
      "318/318 - 0s - loss: 24.8284 - val_loss: 27.2806\n",
      "Epoch 324/1000\n",
      "318/318 - 0s - loss: 24.6776 - val_loss: 27.1137\n",
      "Epoch 325/1000\n",
      "318/318 - 0s - loss: 24.5270 - val_loss: 26.9468\n",
      "Epoch 326/1000\n",
      "318/318 - 0s - loss: 24.3809 - val_loss: 26.7817\n",
      "Epoch 327/1000\n",
      "318/318 - 0s - loss: 24.2391 - val_loss: 26.6178\n",
      "Epoch 328/1000\n",
      "318/318 - 0s - loss: 24.0940 - val_loss: 26.4545\n",
      "Epoch 329/1000\n",
      "318/318 - 0s - loss: 23.9493 - val_loss: 26.2937\n",
      "Epoch 330/1000\n",
      "318/318 - 0s - loss: 23.8034 - val_loss: 26.1333\n",
      "Epoch 331/1000\n",
      "318/318 - 0s - loss: 23.6674 - val_loss: 25.9716\n",
      "Epoch 332/1000\n",
      "318/318 - 0s - loss: 23.5287 - val_loss: 25.8100\n",
      "Epoch 333/1000\n",
      "318/318 - 0s - loss: 23.3924 - val_loss: 25.6509\n",
      "Epoch 334/1000\n",
      "318/318 - 0s - loss: 23.2641 - val_loss: 25.4925\n",
      "Epoch 335/1000\n",
      "318/318 - 0s - loss: 23.1202 - val_loss: 25.3391\n",
      "Epoch 336/1000\n",
      "318/318 - 0s - loss: 22.9927 - val_loss: 25.1865\n",
      "Epoch 337/1000\n",
      "318/318 - 0s - loss: 22.8694 - val_loss: 25.0318\n",
      "Epoch 338/1000\n",
      "318/318 - 0s - loss: 22.7394 - val_loss: 24.8787\n",
      "Epoch 339/1000\n",
      "318/318 - 0s - loss: 22.6064 - val_loss: 24.7303\n",
      "Epoch 340/1000\n",
      "318/318 - 0s - loss: 22.4849 - val_loss: 24.5812\n",
      "Epoch 341/1000\n",
      "318/318 - 0s - loss: 22.3607 - val_loss: 24.4326\n",
      "Epoch 342/1000\n",
      "318/318 - 0s - loss: 22.2359 - val_loss: 24.2841\n",
      "Epoch 343/1000\n",
      "318/318 - 0s - loss: 22.1189 - val_loss: 24.1335\n",
      "Epoch 344/1000\n",
      "318/318 - 0s - loss: 21.9928 - val_loss: 23.9854\n",
      "Epoch 345/1000\n",
      "318/318 - 0s - loss: 21.8709 - val_loss: 23.8379\n",
      "Epoch 346/1000\n",
      "318/318 - 0s - loss: 21.7553 - val_loss: 23.6919\n",
      "Epoch 347/1000\n",
      "318/318 - 0s - loss: 21.6351 - val_loss: 23.5489\n",
      "Epoch 348/1000\n",
      "318/318 - 0s - loss: 21.5198 - val_loss: 23.4063\n",
      "Epoch 349/1000\n",
      "318/318 - 0s - loss: 21.3973 - val_loss: 23.2634\n",
      "Epoch 350/1000\n",
      "318/318 - 0s - loss: 21.2834 - val_loss: 23.1197\n",
      "Epoch 351/1000\n",
      "318/318 - 0s - loss: 21.1714 - val_loss: 22.9761\n",
      "Epoch 352/1000\n",
      "318/318 - 0s - loss: 21.0556 - val_loss: 22.8342\n",
      "Epoch 353/1000\n",
      "318/318 - 0s - loss: 20.9471 - val_loss: 22.6944\n",
      "Epoch 354/1000\n",
      "318/318 - 0s - loss: 20.8316 - val_loss: 22.5571\n",
      "Epoch 355/1000\n",
      "318/318 - 0s - loss: 20.7224 - val_loss: 22.4192\n",
      "Epoch 356/1000\n",
      "318/318 - 0s - loss: 20.6173 - val_loss: 22.2805\n",
      "Epoch 357/1000\n",
      "318/318 - 0s - loss: 20.5104 - val_loss: 22.1451\n",
      "Epoch 358/1000\n",
      "318/318 - 0s - loss: 20.4023 - val_loss: 22.0112\n",
      "Epoch 359/1000\n",
      "318/318 - 0s - loss: 20.2925 - val_loss: 21.8775\n",
      "Epoch 360/1000\n",
      "318/318 - 0s - loss: 20.1907 - val_loss: 21.7426\n",
      "Epoch 361/1000\n",
      "318/318 - 0s - loss: 20.0865 - val_loss: 21.6070\n",
      "Epoch 362/1000\n",
      "318/318 - 0s - loss: 19.9819 - val_loss: 21.4732\n",
      "Epoch 363/1000\n",
      "318/318 - 0s - loss: 19.8744 - val_loss: 21.3405\n",
      "Epoch 364/1000\n",
      "318/318 - 0s - loss: 19.7685 - val_loss: 21.2117\n",
      "Epoch 365/1000\n",
      "318/318 - 0s - loss: 19.6690 - val_loss: 21.0797\n",
      "Epoch 366/1000\n",
      "318/318 - 0s - loss: 19.5672 - val_loss: 20.9494\n",
      "Epoch 367/1000\n",
      "318/318 - 0s - loss: 19.4652 - val_loss: 20.8193\n",
      "Epoch 368/1000\n",
      "318/318 - 0s - loss: 19.3632 - val_loss: 20.6933\n",
      "Epoch 369/1000\n",
      "318/318 - 0s - loss: 19.2659 - val_loss: 20.5696\n",
      "Epoch 370/1000\n",
      "318/318 - 0s - loss: 19.1688 - val_loss: 20.4464\n",
      "Epoch 371/1000\n",
      "318/318 - 0s - loss: 19.0715 - val_loss: 20.3235\n",
      "Epoch 372/1000\n",
      "318/318 - 0s - loss: 18.9801 - val_loss: 20.2000\n",
      "Epoch 373/1000\n",
      "318/318 - 0s - loss: 18.8850 - val_loss: 20.0795\n",
      "Epoch 374/1000\n",
      "318/318 - 0s - loss: 18.7940 - val_loss: 19.9607\n",
      "Epoch 375/1000\n",
      "318/318 - 0s - loss: 18.7064 - val_loss: 19.8425\n",
      "Epoch 376/1000\n",
      "318/318 - 0s - loss: 18.6108 - val_loss: 19.7267\n",
      "Epoch 377/1000\n",
      "318/318 - 0s - loss: 18.5264 - val_loss: 19.6100\n",
      "Epoch 378/1000\n",
      "318/318 - 0s - loss: 18.4347 - val_loss: 19.4963\n",
      "Epoch 379/1000\n",
      "318/318 - 0s - loss: 18.3463 - val_loss: 19.3809\n",
      "Epoch 380/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 - 0s - loss: 18.2625 - val_loss: 19.2650\n",
      "Epoch 381/1000\n",
      "318/318 - 0s - loss: 18.1702 - val_loss: 19.1510\n",
      "Epoch 382/1000\n",
      "318/318 - 0s - loss: 18.0856 - val_loss: 19.0356\n",
      "Epoch 383/1000\n",
      "318/318 - 0s - loss: 17.9992 - val_loss: 18.9181\n",
      "Epoch 384/1000\n",
      "318/318 - 0s - loss: 17.9172 - val_loss: 18.8000\n",
      "Epoch 385/1000\n",
      "318/318 - 0s - loss: 17.8323 - val_loss: 18.6840\n",
      "Epoch 386/1000\n",
      "318/318 - 0s - loss: 17.7462 - val_loss: 18.5717\n",
      "Epoch 387/1000\n",
      "318/318 - 0s - loss: 17.6643 - val_loss: 18.4589\n",
      "Epoch 388/1000\n",
      "318/318 - 0s - loss: 17.5813 - val_loss: 18.3459\n",
      "Epoch 389/1000\n",
      "318/318 - 0s - loss: 17.4995 - val_loss: 18.2334\n",
      "Epoch 390/1000\n",
      "318/318 - 0s - loss: 17.4180 - val_loss: 18.1220\n",
      "Epoch 391/1000\n",
      "318/318 - 0s - loss: 17.3396 - val_loss: 18.0106\n",
      "Epoch 392/1000\n",
      "318/318 - 0s - loss: 17.2601 - val_loss: 17.9005\n",
      "Epoch 393/1000\n",
      "318/318 - 0s - loss: 17.1825 - val_loss: 17.7899\n",
      "Epoch 394/1000\n",
      "318/318 - 0s - loss: 17.1021 - val_loss: 17.6804\n",
      "Epoch 395/1000\n",
      "318/318 - 0s - loss: 17.0235 - val_loss: 17.5748\n",
      "Epoch 396/1000\n",
      "318/318 - 0s - loss: 16.9492 - val_loss: 17.4693\n",
      "Epoch 397/1000\n",
      "318/318 - 0s - loss: 16.8749 - val_loss: 17.3650\n",
      "Epoch 398/1000\n",
      "318/318 - 0s - loss: 16.7991 - val_loss: 17.2614\n",
      "Epoch 399/1000\n",
      "318/318 - 0s - loss: 16.7212 - val_loss: 17.1620\n",
      "Epoch 400/1000\n",
      "318/318 - 0s - loss: 16.6501 - val_loss: 17.0609\n",
      "Epoch 401/1000\n",
      "318/318 - 0s - loss: 16.5782 - val_loss: 16.9600\n",
      "Epoch 402/1000\n",
      "318/318 - 0s - loss: 16.5041 - val_loss: 16.8624\n",
      "Epoch 403/1000\n",
      "318/318 - 0s - loss: 16.4311 - val_loss: 16.7656\n",
      "Epoch 404/1000\n",
      "318/318 - 0s - loss: 16.3586 - val_loss: 16.6675\n",
      "Epoch 405/1000\n",
      "318/318 - 0s - loss: 16.2907 - val_loss: 16.5701\n",
      "Epoch 406/1000\n",
      "318/318 - 0s - loss: 16.2131 - val_loss: 16.4742\n",
      "Epoch 407/1000\n",
      "318/318 - 0s - loss: 16.1445 - val_loss: 16.3767\n",
      "Epoch 408/1000\n",
      "318/318 - 0s - loss: 16.0732 - val_loss: 16.2795\n",
      "Epoch 409/1000\n",
      "318/318 - 0s - loss: 16.0026 - val_loss: 16.1835\n",
      "Epoch 410/1000\n",
      "318/318 - 0s - loss: 15.9334 - val_loss: 16.0870\n",
      "Epoch 411/1000\n",
      "318/318 - 0s - loss: 15.8653 - val_loss: 15.9901\n",
      "Epoch 412/1000\n",
      "318/318 - 0s - loss: 15.7985 - val_loss: 15.8944\n",
      "Epoch 413/1000\n",
      "318/318 - 0s - loss: 15.7267 - val_loss: 15.8010\n",
      "Epoch 414/1000\n",
      "318/318 - 0s - loss: 15.6647 - val_loss: 15.7071\n",
      "Epoch 415/1000\n",
      "318/318 - 0s - loss: 15.5947 - val_loss: 15.6167\n",
      "Epoch 416/1000\n",
      "318/318 - 0s - loss: 15.5300 - val_loss: 15.5267\n",
      "Epoch 417/1000\n",
      "318/318 - 0s - loss: 15.4658 - val_loss: 15.4378\n",
      "Epoch 418/1000\n",
      "318/318 - 0s - loss: 15.4012 - val_loss: 15.3489\n",
      "Epoch 419/1000\n",
      "318/318 - 0s - loss: 15.3375 - val_loss: 15.2616\n",
      "Epoch 420/1000\n",
      "318/318 - 0s - loss: 15.2744 - val_loss: 15.1763\n",
      "Epoch 421/1000\n",
      "318/318 - 0s - loss: 15.2101 - val_loss: 15.0936\n",
      "Epoch 422/1000\n",
      "318/318 - 0s - loss: 15.1474 - val_loss: 15.0102\n",
      "Epoch 423/1000\n",
      "318/318 - 0s - loss: 15.0897 - val_loss: 14.9253\n",
      "Epoch 424/1000\n",
      "318/318 - 0s - loss: 15.0299 - val_loss: 14.8419\n",
      "Epoch 425/1000\n",
      "318/318 - 0s - loss: 14.9654 - val_loss: 14.7624\n",
      "Epoch 426/1000\n",
      "318/318 - 0s - loss: 14.9076 - val_loss: 14.6829\n",
      "Epoch 427/1000\n",
      "318/318 - 0s - loss: 14.8479 - val_loss: 14.6038\n",
      "Epoch 428/1000\n",
      "318/318 - 0s - loss: 14.7886 - val_loss: 14.5244\n",
      "Epoch 429/1000\n",
      "318/318 - 0s - loss: 14.7312 - val_loss: 14.4452\n",
      "Epoch 430/1000\n",
      "318/318 - 0s - loss: 14.6742 - val_loss: 14.3659\n",
      "Epoch 431/1000\n",
      "318/318 - 0s - loss: 14.6161 - val_loss: 14.2884\n",
      "Epoch 432/1000\n",
      "318/318 - 0s - loss: 14.5581 - val_loss: 14.2080\n",
      "Epoch 433/1000\n",
      "318/318 - 0s - loss: 14.5045 - val_loss: 14.1285\n",
      "Epoch 434/1000\n",
      "318/318 - 0s - loss: 14.4468 - val_loss: 14.0519\n",
      "Epoch 435/1000\n",
      "318/318 - 0s - loss: 14.3931 - val_loss: 13.9743\n",
      "Epoch 436/1000\n",
      "318/318 - 0s - loss: 14.3377 - val_loss: 13.8978\n",
      "Epoch 437/1000\n",
      "318/318 - 0s - loss: 14.2807 - val_loss: 13.8223\n",
      "Epoch 438/1000\n",
      "318/318 - 0s - loss: 14.2270 - val_loss: 13.7457\n",
      "Epoch 439/1000\n",
      "318/318 - 0s - loss: 14.1782 - val_loss: 13.6682\n",
      "Epoch 440/1000\n",
      "318/318 - 0s - loss: 14.1225 - val_loss: 13.5933\n",
      "Epoch 441/1000\n",
      "318/318 - 0s - loss: 14.0697 - val_loss: 13.5209\n",
      "Epoch 442/1000\n",
      "318/318 - 0s - loss: 14.0191 - val_loss: 13.4481\n",
      "Epoch 443/1000\n",
      "318/318 - 0s - loss: 13.9662 - val_loss: 13.3766\n",
      "Epoch 444/1000\n",
      "318/318 - 0s - loss: 13.9154 - val_loss: 13.3066\n",
      "Epoch 445/1000\n",
      "318/318 - 0s - loss: 13.8656 - val_loss: 13.2369\n",
      "Epoch 446/1000\n",
      "318/318 - 0s - loss: 13.8160 - val_loss: 13.1691\n",
      "Epoch 447/1000\n",
      "318/318 - 0s - loss: 13.7663 - val_loss: 13.1014\n",
      "Epoch 448/1000\n",
      "318/318 - 0s - loss: 13.7192 - val_loss: 13.0317\n",
      "Epoch 449/1000\n",
      "318/318 - 0s - loss: 13.6703 - val_loss: 12.9644\n",
      "Epoch 450/1000\n",
      "318/318 - 0s - loss: 13.6218 - val_loss: 12.8973\n",
      "Epoch 451/1000\n",
      "318/318 - 0s - loss: 13.5776 - val_loss: 12.8294\n",
      "Epoch 452/1000\n",
      "318/318 - 0s - loss: 13.5294 - val_loss: 12.7634\n",
      "Epoch 453/1000\n",
      "318/318 - 0s - loss: 13.4821 - val_loss: 12.6990\n",
      "Epoch 454/1000\n",
      "318/318 - 0s - loss: 13.4386 - val_loss: 12.6326\n",
      "Epoch 455/1000\n",
      "318/318 - 0s - loss: 13.3908 - val_loss: 12.5694\n",
      "Epoch 456/1000\n",
      "318/318 - 0s - loss: 13.3453 - val_loss: 12.5056\n",
      "Epoch 457/1000\n",
      "318/318 - 0s - loss: 13.3002 - val_loss: 12.4429\n",
      "Epoch 458/1000\n",
      "318/318 - 0s - loss: 13.2539 - val_loss: 12.3822\n",
      "Epoch 459/1000\n",
      "318/318 - 0s - loss: 13.2086 - val_loss: 12.3206\n",
      "Epoch 460/1000\n",
      "318/318 - 0s - loss: 13.1647 - val_loss: 12.2584\n",
      "Epoch 461/1000\n",
      "318/318 - 0s - loss: 13.1222 - val_loss: 12.1970\n",
      "Epoch 462/1000\n",
      "318/318 - 0s - loss: 13.0796 - val_loss: 12.1348\n",
      "Epoch 463/1000\n",
      "318/318 - 0s - loss: 13.0343 - val_loss: 12.0736\n",
      "Epoch 464/1000\n",
      "318/318 - 0s - loss: 12.9926 - val_loss: 12.0145\n",
      "Epoch 465/1000\n",
      "318/318 - 0s - loss: 12.9492 - val_loss: 11.9570\n",
      "Epoch 466/1000\n",
      "318/318 - 0s - loss: 12.9103 - val_loss: 11.9004\n",
      "Epoch 467/1000\n",
      "318/318 - 0s - loss: 12.8663 - val_loss: 11.8472\n",
      "Epoch 468/1000\n",
      "318/318 - 0s - loss: 12.8267 - val_loss: 11.7944\n",
      "Epoch 469/1000\n",
      "318/318 - 0s - loss: 12.7847 - val_loss: 11.7398\n",
      "Epoch 470/1000\n",
      "318/318 - 0s - loss: 12.7440 - val_loss: 11.6859\n",
      "Epoch 471/1000\n",
      "318/318 - 0s - loss: 12.7034 - val_loss: 11.6326\n",
      "Epoch 472/1000\n",
      "318/318 - 0s - loss: 12.6623 - val_loss: 11.5805\n",
      "Epoch 473/1000\n",
      "318/318 - 0s - loss: 12.6228 - val_loss: 11.5254\n",
      "Epoch 474/1000\n",
      "318/318 - 0s - loss: 12.5820 - val_loss: 11.4713\n",
      "Epoch 475/1000\n",
      "318/318 - 0s - loss: 12.5412 - val_loss: 11.4171\n",
      "Epoch 476/1000\n",
      "318/318 - 0s - loss: 12.4998 - val_loss: 11.3631\n",
      "Epoch 477/1000\n",
      "318/318 - 0s - loss: 12.4618 - val_loss: 11.3085\n",
      "Epoch 478/1000\n",
      "318/318 - 0s - loss: 12.4217 - val_loss: 11.2562\n",
      "Epoch 479/1000\n",
      "318/318 - 0s - loss: 12.3853 - val_loss: 11.2029\n",
      "Epoch 480/1000\n",
      "318/318 - 0s - loss: 12.3475 - val_loss: 11.1513\n",
      "Epoch 481/1000\n",
      "318/318 - 0s - loss: 12.3098 - val_loss: 11.1010\n",
      "Epoch 482/1000\n",
      "318/318 - 0s - loss: 12.2727 - val_loss: 11.0507\n",
      "Epoch 483/1000\n",
      "318/318 - 0s - loss: 12.2388 - val_loss: 10.9996\n",
      "Epoch 484/1000\n",
      "318/318 - 0s - loss: 12.2020 - val_loss: 10.9493\n",
      "Epoch 485/1000\n",
      "318/318 - 0s - loss: 12.1659 - val_loss: 10.8976\n",
      "Epoch 486/1000\n",
      "318/318 - 0s - loss: 12.1316 - val_loss: 10.8457\n",
      "Epoch 487/1000\n",
      "318/318 - 0s - loss: 12.0971 - val_loss: 10.7940\n",
      "Epoch 488/1000\n",
      "318/318 - 0s - loss: 12.0612 - val_loss: 10.7464\n",
      "Epoch 489/1000\n",
      "318/318 - 0s - loss: 12.0274 - val_loss: 10.7004\n",
      "Epoch 490/1000\n",
      "318/318 - 0s - loss: 11.9945 - val_loss: 10.6519\n",
      "Epoch 491/1000\n",
      "318/318 - 0s - loss: 11.9596 - val_loss: 10.6021\n",
      "Epoch 492/1000\n",
      "318/318 - 0s - loss: 11.9296 - val_loss: 10.5530\n",
      "Epoch 493/1000\n",
      "318/318 - 0s - loss: 11.8965 - val_loss: 10.5056\n",
      "Epoch 494/1000\n",
      "318/318 - 0s - loss: 11.8610 - val_loss: 10.4563\n",
      "Epoch 495/1000\n",
      "318/318 - 0s - loss: 11.8290 - val_loss: 10.4070\n",
      "Epoch 496/1000\n",
      "318/318 - 0s - loss: 11.7945 - val_loss: 10.3582\n",
      "Epoch 497/1000\n",
      "318/318 - 0s - loss: 11.7608 - val_loss: 10.3083\n",
      "Epoch 498/1000\n",
      "318/318 - 0s - loss: 11.7269 - val_loss: 10.2590\n",
      "Epoch 499/1000\n",
      "318/318 - 0s - loss: 11.6964 - val_loss: 10.2104\n",
      "Epoch 500/1000\n",
      "318/318 - 0s - loss: 11.6610 - val_loss: 10.1642\n",
      "Epoch 501/1000\n",
      "318/318 - 0s - loss: 11.6322 - val_loss: 10.1162\n",
      "Epoch 502/1000\n",
      "318/318 - 0s - loss: 11.5980 - val_loss: 10.0690\n",
      "Epoch 503/1000\n",
      "318/318 - 0s - loss: 11.5654 - val_loss: 10.0225\n",
      "Epoch 504/1000\n",
      "318/318 - 0s - loss: 11.5339 - val_loss: 9.9767\n",
      "Epoch 505/1000\n",
      "318/318 - 0s - loss: 11.5032 - val_loss: 9.9297\n",
      "Epoch 506/1000\n",
      "318/318 - 0s - loss: 11.4725 - val_loss: 9.8820\n",
      "Epoch 507/1000\n",
      "318/318 - 0s - loss: 11.4418 - val_loss: 9.8364\n",
      "Epoch 508/1000\n",
      "318/318 - 0s - loss: 11.4095 - val_loss: 9.7936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509/1000\n",
      "318/318 - 0s - loss: 11.3813 - val_loss: 9.7504\n",
      "Epoch 510/1000\n",
      "318/318 - 0s - loss: 11.3507 - val_loss: 9.7077\n",
      "Epoch 511/1000\n",
      "318/318 - 0s - loss: 11.3195 - val_loss: 9.6644\n",
      "Epoch 512/1000\n",
      "318/318 - 0s - loss: 11.2914 - val_loss: 9.6199\n",
      "Epoch 513/1000\n",
      "318/318 - 0s - loss: 11.2616 - val_loss: 9.5781\n",
      "Epoch 514/1000\n",
      "318/318 - 0s - loss: 11.2305 - val_loss: 9.5394\n",
      "Epoch 515/1000\n",
      "318/318 - 0s - loss: 11.2025 - val_loss: 9.5001\n",
      "Epoch 516/1000\n",
      "318/318 - 0s - loss: 11.1752 - val_loss: 9.4596\n",
      "Epoch 517/1000\n",
      "318/318 - 0s - loss: 11.1466 - val_loss: 9.4186\n",
      "Epoch 518/1000\n",
      "318/318 - 0s - loss: 11.1164 - val_loss: 9.3791\n",
      "Epoch 519/1000\n",
      "318/318 - 0s - loss: 11.0882 - val_loss: 9.3401\n",
      "Epoch 520/1000\n",
      "318/318 - 0s - loss: 11.0604 - val_loss: 9.2999\n",
      "Epoch 521/1000\n",
      "318/318 - 0s - loss: 11.0332 - val_loss: 9.2592\n",
      "Epoch 522/1000\n",
      "318/318 - 0s - loss: 11.0029 - val_loss: 9.2204\n",
      "Epoch 523/1000\n",
      "318/318 - 0s - loss: 10.9764 - val_loss: 9.1813\n",
      "Epoch 524/1000\n",
      "318/318 - 0s - loss: 10.9507 - val_loss: 9.1444\n",
      "Epoch 525/1000\n",
      "318/318 - 0s - loss: 10.9226 - val_loss: 9.1073\n",
      "Epoch 526/1000\n",
      "318/318 - 0s - loss: 10.8950 - val_loss: 9.0711\n",
      "Epoch 527/1000\n",
      "318/318 - 0s - loss: 10.8656 - val_loss: 9.0388\n",
      "Epoch 528/1000\n",
      "318/318 - 0s - loss: 10.8420 - val_loss: 9.0040\n",
      "Epoch 529/1000\n",
      "318/318 - 0s - loss: 10.8166 - val_loss: 8.9680\n",
      "Epoch 530/1000\n",
      "318/318 - 0s - loss: 10.7903 - val_loss: 8.9303\n",
      "Epoch 531/1000\n",
      "318/318 - 0s - loss: 10.7642 - val_loss: 8.8945\n",
      "Epoch 532/1000\n",
      "318/318 - 0s - loss: 10.7394 - val_loss: 8.8582\n",
      "Epoch 533/1000\n",
      "318/318 - 0s - loss: 10.7162 - val_loss: 8.8218\n",
      "Epoch 534/1000\n",
      "318/318 - 0s - loss: 10.6907 - val_loss: 8.7893\n",
      "Epoch 535/1000\n",
      "318/318 - 0s - loss: 10.6646 - val_loss: 8.7560\n",
      "Epoch 536/1000\n",
      "318/318 - 0s - loss: 10.6414 - val_loss: 8.7235\n",
      "Epoch 537/1000\n",
      "318/318 - 0s - loss: 10.6176 - val_loss: 8.6906\n",
      "Epoch 538/1000\n",
      "318/318 - 0s - loss: 10.5918 - val_loss: 8.6568\n",
      "Epoch 539/1000\n",
      "318/318 - 0s - loss: 10.5684 - val_loss: 8.6218\n",
      "Epoch 540/1000\n",
      "318/318 - 0s - loss: 10.5439 - val_loss: 8.5867\n",
      "Epoch 541/1000\n",
      "318/318 - 0s - loss: 10.5217 - val_loss: 8.5512\n",
      "Epoch 542/1000\n",
      "318/318 - 0s - loss: 10.4960 - val_loss: 8.5171\n",
      "Epoch 543/1000\n",
      "318/318 - 0s - loss: 10.4732 - val_loss: 8.4834\n",
      "Epoch 544/1000\n",
      "318/318 - 0s - loss: 10.4496 - val_loss: 8.4534\n",
      "Epoch 545/1000\n",
      "318/318 - 0s - loss: 10.4253 - val_loss: 8.4218\n",
      "Epoch 546/1000\n",
      "318/318 - 0s - loss: 10.4036 - val_loss: 8.3908\n",
      "Epoch 547/1000\n",
      "318/318 - 0s - loss: 10.3804 - val_loss: 8.3613\n",
      "Epoch 548/1000\n",
      "318/318 - 0s - loss: 10.3598 - val_loss: 8.3324\n",
      "Epoch 549/1000\n",
      "318/318 - 0s - loss: 10.3368 - val_loss: 8.3036\n",
      "Epoch 550/1000\n",
      "318/318 - 0s - loss: 10.3150 - val_loss: 8.2763\n",
      "Epoch 551/1000\n",
      "318/318 - 0s - loss: 10.2911 - val_loss: 8.2483\n",
      "Epoch 552/1000\n",
      "318/318 - 0s - loss: 10.2710 - val_loss: 8.2204\n",
      "Epoch 553/1000\n",
      "318/318 - 0s - loss: 10.2498 - val_loss: 8.1920\n",
      "Epoch 554/1000\n",
      "318/318 - 0s - loss: 10.2263 - val_loss: 8.1653\n",
      "Epoch 555/1000\n",
      "318/318 - 0s - loss: 10.2060 - val_loss: 8.1364\n",
      "Epoch 556/1000\n",
      "318/318 - 0s - loss: 10.1823 - val_loss: 8.1099\n",
      "Epoch 557/1000\n",
      "318/318 - 0s - loss: 10.1642 - val_loss: 8.0845\n",
      "Epoch 558/1000\n",
      "318/318 - 0s - loss: 10.1421 - val_loss: 8.0587\n",
      "Epoch 559/1000\n",
      "318/318 - 0s - loss: 10.1219 - val_loss: 8.0311\n",
      "Epoch 560/1000\n",
      "318/318 - 0s - loss: 10.1035 - val_loss: 8.0044\n",
      "Epoch 561/1000\n",
      "318/318 - 0s - loss: 10.0843 - val_loss: 7.9799\n",
      "Epoch 562/1000\n",
      "318/318 - 0s - loss: 10.0648 - val_loss: 7.9568\n",
      "Epoch 563/1000\n",
      "318/318 - 0s - loss: 10.0464 - val_loss: 7.9351\n",
      "Epoch 564/1000\n",
      "318/318 - 0s - loss: 10.0287 - val_loss: 7.9132\n",
      "Epoch 565/1000\n",
      "318/318 - 0s - loss: 10.0117 - val_loss: 7.8910\n",
      "Epoch 566/1000\n",
      "318/318 - 0s - loss: 9.9926 - val_loss: 7.8680\n",
      "Epoch 567/1000\n",
      "318/318 - 0s - loss: 9.9765 - val_loss: 7.8421\n",
      "Epoch 568/1000\n",
      "318/318 - 0s - loss: 9.9580 - val_loss: 7.8177\n",
      "Epoch 569/1000\n",
      "318/318 - 0s - loss: 9.9421 - val_loss: 7.7930\n",
      "Epoch 570/1000\n",
      "318/318 - 0s - loss: 9.9234 - val_loss: 7.7683\n",
      "Epoch 571/1000\n",
      "318/318 - 0s - loss: 9.9071 - val_loss: 7.7446\n",
      "Epoch 572/1000\n",
      "318/318 - 0s - loss: 9.8914 - val_loss: 7.7212\n",
      "Epoch 573/1000\n",
      "318/318 - 0s - loss: 9.8727 - val_loss: 7.6975\n",
      "Epoch 574/1000\n",
      "318/318 - 0s - loss: 9.8575 - val_loss: 7.6749\n",
      "Epoch 575/1000\n",
      "318/318 - 0s - loss: 9.8423 - val_loss: 7.6552\n",
      "Epoch 576/1000\n",
      "318/318 - 0s - loss: 9.8249 - val_loss: 7.6363\n",
      "Epoch 577/1000\n",
      "318/318 - 0s - loss: 9.8092 - val_loss: 7.6180\n",
      "Epoch 578/1000\n",
      "318/318 - 0s - loss: 9.7921 - val_loss: 7.5989\n",
      "Epoch 579/1000\n",
      "318/318 - 0s - loss: 9.7776 - val_loss: 7.5817\n",
      "Epoch 580/1000\n",
      "318/318 - 0s - loss: 9.7593 - val_loss: 7.5635\n",
      "Epoch 581/1000\n",
      "318/318 - 0s - loss: 9.7427 - val_loss: 7.5448\n",
      "Epoch 582/1000\n",
      "318/318 - 0s - loss: 9.7272 - val_loss: 7.5274\n",
      "Epoch 583/1000\n",
      "318/318 - 0s - loss: 9.7121 - val_loss: 7.5077\n",
      "Epoch 584/1000\n",
      "318/318 - 0s - loss: 9.6964 - val_loss: 7.4888\n",
      "Epoch 585/1000\n",
      "318/318 - 0s - loss: 9.6821 - val_loss: 7.4710\n",
      "Epoch 586/1000\n",
      "318/318 - 0s - loss: 9.6663 - val_loss: 7.4514\n",
      "Epoch 587/1000\n",
      "318/318 - 0s - loss: 9.6521 - val_loss: 7.4319\n",
      "Epoch 588/1000\n",
      "318/318 - 0s - loss: 9.6382 - val_loss: 7.4115\n",
      "Epoch 589/1000\n",
      "318/318 - 0s - loss: 9.6227 - val_loss: 7.3913\n",
      "Epoch 590/1000\n",
      "318/318 - 0s - loss: 9.6085 - val_loss: 7.3707\n",
      "Epoch 591/1000\n",
      "318/318 - 0s - loss: 9.5946 - val_loss: 7.3514\n",
      "Epoch 592/1000\n",
      "318/318 - 0s - loss: 9.5798 - val_loss: 7.3323\n",
      "Epoch 593/1000\n",
      "318/318 - 0s - loss: 9.5666 - val_loss: 7.3139\n",
      "Epoch 594/1000\n",
      "318/318 - 0s - loss: 9.5520 - val_loss: 7.2943\n",
      "Epoch 595/1000\n",
      "318/318 - 0s - loss: 9.5403 - val_loss: 7.2745\n",
      "Epoch 596/1000\n",
      "318/318 - 0s - loss: 9.5255 - val_loss: 7.2567\n",
      "Epoch 597/1000\n",
      "318/318 - 0s - loss: 9.5125 - val_loss: 7.2406\n",
      "Epoch 598/1000\n",
      "318/318 - 0s - loss: 9.5002 - val_loss: 7.2228\n",
      "Epoch 599/1000\n",
      "318/318 - 0s - loss: 9.4861 - val_loss: 7.2078\n",
      "Epoch 600/1000\n",
      "318/318 - 0s - loss: 9.4755 - val_loss: 7.1933\n",
      "Epoch 601/1000\n",
      "318/318 - 0s - loss: 9.4615 - val_loss: 7.1805\n",
      "Epoch 602/1000\n",
      "318/318 - 0s - loss: 9.4493 - val_loss: 7.1674\n",
      "Epoch 603/1000\n",
      "318/318 - 0s - loss: 9.4377 - val_loss: 7.1520\n",
      "Epoch 604/1000\n",
      "318/318 - 0s - loss: 9.4244 - val_loss: 7.1389\n",
      "Epoch 605/1000\n",
      "318/318 - 0s - loss: 9.4131 - val_loss: 7.1263\n",
      "Epoch 606/1000\n",
      "318/318 - 0s - loss: 9.4002 - val_loss: 7.1117\n",
      "Epoch 607/1000\n",
      "318/318 - 0s - loss: 9.3884 - val_loss: 7.0981\n",
      "Epoch 608/1000\n",
      "318/318 - 0s - loss: 9.3763 - val_loss: 7.0861\n",
      "Epoch 609/1000\n",
      "318/318 - 0s - loss: 9.3651 - val_loss: 7.0729\n",
      "Epoch 610/1000\n",
      "318/318 - 0s - loss: 9.3523 - val_loss: 7.0599\n",
      "Epoch 611/1000\n",
      "318/318 - 0s - loss: 9.3402 - val_loss: 7.0473\n",
      "Epoch 612/1000\n",
      "318/318 - 0s - loss: 9.3293 - val_loss: 7.0354\n",
      "Epoch 613/1000\n",
      "318/318 - 0s - loss: 9.3188 - val_loss: 7.0233\n",
      "Epoch 614/1000\n",
      "318/318 - 0s - loss: 9.3064 - val_loss: 7.0132\n",
      "Epoch 615/1000\n",
      "318/318 - 0s - loss: 9.2963 - val_loss: 7.0027\n",
      "Epoch 616/1000\n",
      "318/318 - 0s - loss: 9.2853 - val_loss: 6.9938\n",
      "Epoch 617/1000\n",
      "318/318 - 0s - loss: 9.2754 - val_loss: 6.9861\n",
      "Epoch 618/1000\n",
      "318/318 - 0s - loss: 9.2645 - val_loss: 6.9759\n",
      "Epoch 619/1000\n",
      "318/318 - 0s - loss: 9.2550 - val_loss: 6.9668\n",
      "Epoch 620/1000\n",
      "318/318 - 0s - loss: 9.2448 - val_loss: 6.9592\n",
      "Epoch 621/1000\n",
      "318/318 - 0s - loss: 9.2344 - val_loss: 6.9518\n",
      "Epoch 622/1000\n",
      "318/318 - 0s - loss: 9.2250 - val_loss: 6.9458\n",
      "Epoch 623/1000\n",
      "318/318 - 0s - loss: 9.2150 - val_loss: 6.9372\n",
      "Epoch 624/1000\n",
      "318/318 - 0s - loss: 9.2059 - val_loss: 6.9301\n",
      "Epoch 625/1000\n",
      "318/318 - 0s - loss: 9.1946 - val_loss: 6.9197\n",
      "Epoch 626/1000\n",
      "318/318 - 0s - loss: 9.1861 - val_loss: 6.9074\n",
      "Epoch 627/1000\n",
      "318/318 - 0s - loss: 9.1763 - val_loss: 6.8952\n",
      "Epoch 628/1000\n",
      "318/318 - 0s - loss: 9.1675 - val_loss: 6.8826\n",
      "Epoch 629/1000\n",
      "318/318 - 0s - loss: 9.1571 - val_loss: 6.8723\n",
      "Epoch 630/1000\n",
      "318/318 - 0s - loss: 9.1482 - val_loss: 6.8649\n",
      "Epoch 631/1000\n",
      "318/318 - 0s - loss: 9.1391 - val_loss: 6.8562\n",
      "Epoch 632/1000\n",
      "318/318 - 0s - loss: 9.1295 - val_loss: 6.8469\n",
      "Epoch 633/1000\n",
      "318/318 - 0s - loss: 9.1218 - val_loss: 6.8375\n",
      "Epoch 634/1000\n",
      "318/318 - 0s - loss: 9.1124 - val_loss: 6.8268\n",
      "Epoch 635/1000\n",
      "318/318 - 0s - loss: 9.1040 - val_loss: 6.8152\n",
      "Epoch 636/1000\n",
      "318/318 - 0s - loss: 9.0946 - val_loss: 6.8060\n",
      "Epoch 637/1000\n",
      "318/318 - 0s - loss: 9.0865 - val_loss: 6.7984\n",
      "Epoch 638/1000\n",
      "318/318 - 0s - loss: 9.0776 - val_loss: 6.7883\n",
      "Epoch 639/1000\n",
      "318/318 - 0s - loss: 9.0688 - val_loss: 6.7773\n",
      "Epoch 640/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 - 0s - loss: 9.0613 - val_loss: 6.7650\n",
      "Epoch 641/1000\n",
      "318/318 - 0s - loss: 9.0513 - val_loss: 6.7534\n",
      "Epoch 642/1000\n",
      "318/318 - 0s - loss: 9.0442 - val_loss: 6.7429\n",
      "Epoch 643/1000\n",
      "318/318 - 0s - loss: 9.0359 - val_loss: 6.7321\n",
      "Epoch 644/1000\n",
      "318/318 - 0s - loss: 9.0276 - val_loss: 6.7204\n",
      "Epoch 645/1000\n",
      "318/318 - 0s - loss: 9.0205 - val_loss: 6.7101\n",
      "Epoch 646/1000\n",
      "318/318 - 0s - loss: 9.0125 - val_loss: 6.6975\n",
      "Epoch 647/1000\n",
      "318/318 - 0s - loss: 9.0042 - val_loss: 6.6870\n",
      "Epoch 648/1000\n",
      "318/318 - 0s - loss: 8.9971 - val_loss: 6.6760\n",
      "Epoch 649/1000\n",
      "318/318 - 0s - loss: 8.9896 - val_loss: 6.6663\n",
      "Epoch 650/1000\n",
      "318/318 - 0s - loss: 8.9820 - val_loss: 6.6567\n",
      "Epoch 651/1000\n",
      "318/318 - 0s - loss: 8.9738 - val_loss: 6.6481\n",
      "Epoch 652/1000\n",
      "318/318 - 0s - loss: 8.9670 - val_loss: 6.6402\n",
      "Epoch 653/1000\n",
      "318/318 - 0s - loss: 8.9598 - val_loss: 6.6322\n",
      "Epoch 654/1000\n",
      "318/318 - 0s - loss: 8.9523 - val_loss: 6.6239\n",
      "Epoch 655/1000\n",
      "318/318 - 0s - loss: 8.9451 - val_loss: 6.6158\n",
      "Epoch 656/1000\n",
      "318/318 - 0s - loss: 8.9379 - val_loss: 6.6080\n",
      "Epoch 657/1000\n",
      "318/318 - 0s - loss: 8.9306 - val_loss: 6.6010\n",
      "Epoch 658/1000\n",
      "318/318 - 0s - loss: 8.9238 - val_loss: 6.5940\n",
      "Epoch 659/1000\n",
      "318/318 - 0s - loss: 8.9169 - val_loss: 6.5902\n",
      "Epoch 660/1000\n",
      "318/318 - 0s - loss: 8.9103 - val_loss: 6.5836\n",
      "Epoch 661/1000\n",
      "318/318 - 0s - loss: 8.9029 - val_loss: 6.5809\n",
      "Epoch 662/1000\n",
      "318/318 - 0s - loss: 8.8968 - val_loss: 6.5794\n",
      "Epoch 663/1000\n",
      "318/318 - 0s - loss: 8.8905 - val_loss: 6.5780\n",
      "Epoch 664/1000\n",
      "318/318 - 0s - loss: 8.8832 - val_loss: 6.5761\n",
      "Epoch 665/1000\n",
      "318/318 - 0s - loss: 8.8779 - val_loss: 6.5738\n",
      "Epoch 666/1000\n",
      "318/318 - 0s - loss: 8.8711 - val_loss: 6.5707\n",
      "Epoch 667/1000\n",
      "318/318 - 0s - loss: 8.8663 - val_loss: 6.5674\n",
      "Epoch 668/1000\n",
      "318/318 - 0s - loss: 8.8582 - val_loss: 6.5603\n",
      "Epoch 669/1000\n",
      "318/318 - 0s - loss: 8.8525 - val_loss: 6.5521\n",
      "Epoch 670/1000\n",
      "318/318 - 0s - loss: 8.8459 - val_loss: 6.5448\n",
      "Epoch 671/1000\n",
      "318/318 - 0s - loss: 8.8395 - val_loss: 6.5389\n",
      "Epoch 672/1000\n",
      "318/318 - 0s - loss: 8.8335 - val_loss: 6.5325\n",
      "Epoch 673/1000\n",
      "318/318 - 0s - loss: 8.8285 - val_loss: 6.5293\n",
      "Epoch 674/1000\n",
      "318/318 - 0s - loss: 8.8226 - val_loss: 6.5230\n",
      "Epoch 675/1000\n",
      "318/318 - 0s - loss: 8.8160 - val_loss: 6.5189\n",
      "Epoch 676/1000\n",
      "318/318 - 0s - loss: 8.8102 - val_loss: 6.5141\n",
      "Epoch 677/1000\n",
      "318/318 - 0s - loss: 8.8034 - val_loss: 6.5089\n",
      "Epoch 678/1000\n",
      "318/318 - 0s - loss: 8.7978 - val_loss: 6.5036\n",
      "Epoch 679/1000\n",
      "318/318 - 0s - loss: 8.7921 - val_loss: 6.4993\n",
      "Epoch 680/1000\n",
      "318/318 - 0s - loss: 8.7868 - val_loss: 6.4959\n",
      "Epoch 681/1000\n",
      "318/318 - 0s - loss: 8.7801 - val_loss: 6.4917\n",
      "Epoch 682/1000\n",
      "318/318 - 0s - loss: 8.7749 - val_loss: 6.4869\n",
      "Epoch 683/1000\n",
      "318/318 - 0s - loss: 8.7694 - val_loss: 6.4822\n",
      "Epoch 684/1000\n",
      "318/318 - 0s - loss: 8.7640 - val_loss: 6.4791\n",
      "Epoch 685/1000\n",
      "318/318 - 0s - loss: 8.7589 - val_loss: 6.4737\n",
      "Epoch 686/1000\n",
      "318/318 - 0s - loss: 8.7531 - val_loss: 6.4648\n",
      "Epoch 687/1000\n",
      "318/318 - 0s - loss: 8.7475 - val_loss: 6.4544\n",
      "Epoch 688/1000\n",
      "318/318 - 0s - loss: 8.7428 - val_loss: 6.4462\n",
      "Epoch 689/1000\n",
      "318/318 - 0s - loss: 8.7367 - val_loss: 6.4417\n",
      "Epoch 690/1000\n",
      "318/318 - 0s - loss: 8.7314 - val_loss: 6.4384\n",
      "Epoch 691/1000\n",
      "318/318 - 0s - loss: 8.7261 - val_loss: 6.4358\n",
      "Epoch 692/1000\n",
      "318/318 - 0s - loss: 8.7213 - val_loss: 6.4309\n",
      "Epoch 693/1000\n",
      "318/318 - 0s - loss: 8.7157 - val_loss: 6.4269\n",
      "Epoch 694/1000\n",
      "318/318 - 0s - loss: 8.7104 - val_loss: 6.4220\n",
      "Epoch 695/1000\n",
      "318/318 - 0s - loss: 8.7051 - val_loss: 6.4162\n",
      "Epoch 696/1000\n",
      "318/318 - 0s - loss: 8.7007 - val_loss: 6.4072\n",
      "Epoch 697/1000\n",
      "318/318 - 0s - loss: 8.6946 - val_loss: 6.4015\n",
      "Epoch 698/1000\n",
      "318/318 - 0s - loss: 8.6886 - val_loss: 6.3967\n",
      "Epoch 699/1000\n",
      "318/318 - 0s - loss: 8.6850 - val_loss: 6.3908\n",
      "Epoch 700/1000\n",
      "318/318 - 0s - loss: 8.6796 - val_loss: 6.3898\n",
      "Epoch 701/1000\n",
      "318/318 - 0s - loss: 8.6738 - val_loss: 6.3844\n",
      "Epoch 702/1000\n",
      "318/318 - 0s - loss: 8.6693 - val_loss: 6.3802\n",
      "Epoch 703/1000\n",
      "318/318 - 0s - loss: 8.6646 - val_loss: 6.3765\n",
      "Epoch 704/1000\n",
      "318/318 - 0s - loss: 8.6596 - val_loss: 6.3703\n",
      "Epoch 705/1000\n",
      "318/318 - 0s - loss: 8.6549 - val_loss: 6.3663\n",
      "Epoch 706/1000\n",
      "318/318 - 0s - loss: 8.6499 - val_loss: 6.3657\n",
      "Epoch 707/1000\n",
      "318/318 - 0s - loss: 8.6447 - val_loss: 6.3638\n",
      "Epoch 708/1000\n",
      "318/318 - 0s - loss: 8.6403 - val_loss: 6.3610\n",
      "Epoch 709/1000\n",
      "318/318 - 0s - loss: 8.6358 - val_loss: 6.3591\n",
      "Epoch 710/1000\n",
      "318/318 - 0s - loss: 8.6310 - val_loss: 6.3549\n",
      "Epoch 711/1000\n",
      "318/318 - 0s - loss: 8.6269 - val_loss: 6.3502\n",
      "Epoch 712/1000\n",
      "318/318 - 0s - loss: 8.6216 - val_loss: 6.3438\n",
      "Epoch 713/1000\n",
      "318/318 - 0s - loss: 8.6176 - val_loss: 6.3358\n",
      "Epoch 714/1000\n",
      "318/318 - 0s - loss: 8.6131 - val_loss: 6.3292\n",
      "Epoch 715/1000\n",
      "318/318 - 0s - loss: 8.6084 - val_loss: 6.3222\n",
      "Epoch 716/1000\n",
      "318/318 - 0s - loss: 8.6036 - val_loss: 6.3148\n",
      "Epoch 717/1000\n",
      "318/318 - 0s - loss: 8.5999 - val_loss: 6.3075\n",
      "Epoch 718/1000\n",
      "318/318 - 0s - loss: 8.5956 - val_loss: 6.3016\n",
      "Epoch 719/1000\n",
      "318/318 - 0s - loss: 8.5913 - val_loss: 6.2964\n",
      "Epoch 720/1000\n",
      "318/318 - 0s - loss: 8.5876 - val_loss: 6.2926\n",
      "Epoch 721/1000\n",
      "318/318 - 0s - loss: 8.5827 - val_loss: 6.2893\n",
      "Epoch 722/1000\n",
      "318/318 - 0s - loss: 8.5792 - val_loss: 6.2872\n",
      "Epoch 723/1000\n",
      "318/318 - 0s - loss: 8.5739 - val_loss: 6.2840\n",
      "Epoch 724/1000\n",
      "318/318 - 0s - loss: 8.5700 - val_loss: 6.2826\n",
      "Epoch 725/1000\n",
      "318/318 - 0s - loss: 8.5663 - val_loss: 6.2828\n",
      "Epoch 726/1000\n",
      "318/318 - 0s - loss: 8.5615 - val_loss: 6.2800\n",
      "Epoch 727/1000\n",
      "318/318 - 0s - loss: 8.5578 - val_loss: 6.2761\n",
      "Epoch 728/1000\n",
      "318/318 - 0s - loss: 8.5531 - val_loss: 6.2734\n",
      "Epoch 729/1000\n",
      "318/318 - 0s - loss: 8.5492 - val_loss: 6.2723\n",
      "Epoch 730/1000\n",
      "318/318 - 0s - loss: 8.5454 - val_loss: 6.2694\n",
      "Epoch 731/1000\n",
      "318/318 - 0s - loss: 8.5413 - val_loss: 6.2639\n",
      "Epoch 732/1000\n",
      "318/318 - 0s - loss: 8.5381 - val_loss: 6.2581\n",
      "Epoch 733/1000\n",
      "318/318 - 0s - loss: 8.5341 - val_loss: 6.2542\n",
      "Epoch 734/1000\n",
      "318/318 - 0s - loss: 8.5296 - val_loss: 6.2494\n",
      "Epoch 735/1000\n",
      "318/318 - 0s - loss: 8.5258 - val_loss: 6.2420\n",
      "Epoch 736/1000\n",
      "318/318 - 0s - loss: 8.5218 - val_loss: 6.2371\n",
      "Epoch 737/1000\n",
      "318/318 - 0s - loss: 8.5198 - val_loss: 6.2305\n",
      "Epoch 738/1000\n",
      "318/318 - 0s - loss: 8.5140 - val_loss: 6.2276\n",
      "Epoch 739/1000\n",
      "318/318 - 0s - loss: 8.5110 - val_loss: 6.2242\n",
      "Epoch 740/1000\n",
      "318/318 - 0s - loss: 8.5066 - val_loss: 6.2219\n",
      "Epoch 741/1000\n",
      "318/318 - 0s - loss: 8.5037 - val_loss: 6.2220\n",
      "Epoch 742/1000\n",
      "318/318 - 0s - loss: 8.4993 - val_loss: 6.2179\n",
      "Epoch 743/1000\n",
      "318/318 - 0s - loss: 8.4953 - val_loss: 6.2157\n",
      "Epoch 744/1000\n",
      "318/318 - 0s - loss: 8.4920 - val_loss: 6.2132\n",
      "Epoch 745/1000\n",
      "318/318 - 0s - loss: 8.4883 - val_loss: 6.2133\n",
      "Epoch 746/1000\n",
      "318/318 - 0s - loss: 8.4849 - val_loss: 6.2132\n",
      "Epoch 747/1000\n",
      "318/318 - 0s - loss: 8.4812 - val_loss: 6.2107\n",
      "Epoch 748/1000\n",
      "318/318 - 0s - loss: 8.4779 - val_loss: 6.2084\n",
      "Epoch 749/1000\n",
      "318/318 - 0s - loss: 8.4748 - val_loss: 6.2082\n",
      "Epoch 750/1000\n",
      "318/318 - 0s - loss: 8.4713 - val_loss: 6.2054\n",
      "Epoch 751/1000\n",
      "318/318 - 0s - loss: 8.4675 - val_loss: 6.2013\n",
      "Epoch 752/1000\n",
      "318/318 - 0s - loss: 8.4638 - val_loss: 6.1984\n",
      "Epoch 753/1000\n",
      "318/318 - 0s - loss: 8.4611 - val_loss: 6.1947\n",
      "Epoch 754/1000\n",
      "318/318 - 0s - loss: 8.4572 - val_loss: 6.1933\n",
      "Epoch 755/1000\n",
      "318/318 - 0s - loss: 8.4543 - val_loss: 6.1928\n",
      "Epoch 756/1000\n",
      "318/318 - 0s - loss: 8.4500 - val_loss: 6.1918\n",
      "Epoch 757/1000\n",
      "318/318 - 0s - loss: 8.4474 - val_loss: 6.1885\n",
      "Epoch 758/1000\n",
      "318/318 - 0s - loss: 8.4438 - val_loss: 6.1867\n",
      "Epoch 759/1000\n",
      "318/318 - 0s - loss: 8.4405 - val_loss: 6.1841\n",
      "Epoch 760/1000\n",
      "318/318 - 0s - loss: 8.4374 - val_loss: 6.1818\n",
      "Epoch 761/1000\n",
      "318/318 - 0s - loss: 8.4341 - val_loss: 6.1781\n",
      "Epoch 762/1000\n",
      "318/318 - 0s - loss: 8.4310 - val_loss: 6.1755\n",
      "Epoch 763/1000\n",
      "318/318 - 0s - loss: 8.4273 - val_loss: 6.1750\n",
      "Epoch 764/1000\n",
      "318/318 - 0s - loss: 8.4245 - val_loss: 6.1735\n",
      "Epoch 765/1000\n",
      "318/318 - 0s - loss: 8.4216 - val_loss: 6.1749\n",
      "Epoch 766/1000\n",
      "318/318 - 0s - loss: 8.4175 - val_loss: 6.1749\n",
      "Epoch 767/1000\n",
      "318/318 - 0s - loss: 8.4147 - val_loss: 6.1740\n",
      "Epoch 768/1000\n",
      "318/318 - 0s - loss: 8.4111 - val_loss: 6.1740\n",
      "Epoch 769/1000\n",
      "318/318 - 0s - loss: 8.4081 - val_loss: 6.1743\n",
      "Epoch 00769: early stopping\n",
      "Score (RMSE): 2.4846441745758057\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "path = \"./data/\"\n",
    "preprocess = True\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "# create feature vector\n",
    "missing_median(df, 'horsepower')\n",
    "encode_text_dummy(df, 'origin')\n",
    "df.drop('name',1,inplace=True)\n",
    "if preprocess:\n",
    "    encode_numeric_zscore(df, 'horsepower')\n",
    "    encode_numeric_zscore(df, 'weight')\n",
    "    encode_numeric_zscore(df, 'cylinders')\n",
    "    encode_numeric_zscore(df, 'displacement')\n",
    "    encode_numeric_zscore(df, 'acceleration')\n",
    "    encode_numeric_zscore(df, 'year')\n",
    "\n",
    "# Encode to a 2D matrix for training\n",
    "x,y = to_xy(df,'mpg')\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "#model.add(Dense(10, activation='tanh'))   \n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "#checkpointer = ModelCheckpoint(filepath=\"dnn/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "# batch_size: Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test), batch_size= 128, callbacks=[monitor,checkpointer],verbose=2,epochs=1000)\n",
    "model.load_weights('dnn/best_weights.hdf5') # load weights from best model\n",
    "\n",
    "# Predict and measure RMSE\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "\n",
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 318 samples, validate on 80 samples\n",
      "Epoch 1/1000\n",
      "318/318 - 1s - loss: 615.5566 - val_loss: 583.4039\n",
      "Epoch 2/1000\n",
      "318/318 - 1s - loss: 613.9097 - val_loss: 581.5164\n",
      "Epoch 3/1000\n",
      "318/318 - 0s - loss: 612.1221 - val_loss: 579.5286\n",
      "Epoch 4/1000\n",
      "318/318 - 0s - loss: 610.2129 - val_loss: 577.4338\n",
      "Epoch 5/1000\n",
      "318/318 - 0s - loss: 608.0160 - val_loss: 575.0228\n",
      "Epoch 6/1000\n",
      "318/318 - 0s - loss: 605.1377 - val_loss: 571.9579\n",
      "Epoch 7/1000\n",
      "318/318 - 0s - loss: 601.5498 - val_loss: 568.0755\n",
      "Epoch 8/1000\n",
      "318/318 - 0s - loss: 597.1525 - val_loss: 563.7143\n",
      "Epoch 9/1000\n",
      "318/318 - 0s - loss: 591.8561 - val_loss: 558.7035\n",
      "Epoch 10/1000\n",
      "318/318 - 0s - loss: 585.5792 - val_loss: 553.0501\n",
      "Epoch 11/1000\n",
      "318/318 - 0s - loss: 578.6921 - val_loss: 546.8141\n",
      "Epoch 12/1000\n",
      "318/318 - 0s - loss: 571.5493 - val_loss: 540.3800\n",
      "Epoch 13/1000\n",
      "318/318 - 0s - loss: 564.1987 - val_loss: 534.0105\n",
      "Epoch 14/1000\n",
      "318/318 - 0s - loss: 557.1208 - val_loss: 527.5439\n",
      "Epoch 15/1000\n",
      "318/318 - 0s - loss: 549.9641 - val_loss: 520.9554\n",
      "Epoch 16/1000\n",
      "318/318 - 0s - loss: 542.6029 - val_loss: 514.3080\n",
      "Epoch 17/1000\n",
      "318/318 - 0s - loss: 535.2583 - val_loss: 507.4769\n",
      "Epoch 18/1000\n",
      "318/318 - 0s - loss: 527.6507 - val_loss: 500.4192\n",
      "Epoch 19/1000\n",
      "318/318 - 0s - loss: 519.7719 - val_loss: 493.2044\n",
      "Epoch 20/1000\n",
      "318/318 - 0s - loss: 511.8029 - val_loss: 485.7297\n",
      "Epoch 21/1000\n",
      "318/318 - 0s - loss: 503.6411 - val_loss: 477.9376\n",
      "Epoch 22/1000\n",
      "318/318 - 0s - loss: 495.0583 - val_loss: 470.0474\n",
      "Epoch 23/1000\n",
      "318/318 - 0s - loss: 486.4061 - val_loss: 461.9618\n",
      "Epoch 24/1000\n",
      "318/318 - 0s - loss: 477.6136 - val_loss: 453.6136\n",
      "Epoch 25/1000\n",
      "318/318 - 0s - loss: 468.1893 - val_loss: 445.3123\n",
      "Epoch 26/1000\n",
      "318/318 - 0s - loss: 459.1018 - val_loss: 436.6491\n",
      "Epoch 27/1000\n",
      "318/318 - 0s - loss: 449.7508 - val_loss: 427.7272\n",
      "Epoch 28/1000\n",
      "318/318 - 0s - loss: 440.0252 - val_loss: 418.7087\n",
      "Epoch 29/1000\n",
      "318/318 - 0s - loss: 430.2123 - val_loss: 409.4467\n",
      "Epoch 30/1000\n",
      "318/318 - 0s - loss: 420.0313 - val_loss: 400.0531\n",
      "Epoch 31/1000\n",
      "318/318 - 0s - loss: 410.1262 - val_loss: 390.0649\n",
      "Epoch 32/1000\n",
      "318/318 - 0s - loss: 399.3555 - val_loss: 379.9285\n",
      "Epoch 33/1000\n",
      "318/318 - 0s - loss: 388.3717 - val_loss: 369.7678\n",
      "Epoch 34/1000\n",
      "318/318 - 0s - loss: 377.4666 - val_loss: 359.3025\n",
      "Epoch 35/1000\n",
      "318/318 - 0s - loss: 366.2245 - val_loss: 348.7556\n",
      "Epoch 36/1000\n",
      "318/318 - 0s - loss: 355.1843 - val_loss: 337.7862\n",
      "Epoch 37/1000\n",
      "318/318 - 0s - loss: 343.3525 - val_loss: 327.1281\n",
      "Epoch 38/1000\n",
      "318/318 - 0s - loss: 331.6219 - val_loss: 316.6243\n",
      "Epoch 39/1000\n",
      "318/318 - 0s - loss: 320.4475 - val_loss: 305.8495\n",
      "Epoch 40/1000\n",
      "318/318 - 0s - loss: 309.0319 - val_loss: 295.2255\n",
      "Epoch 41/1000\n",
      "318/318 - 0s - loss: 297.7927 - val_loss: 284.7153\n",
      "Epoch 42/1000\n",
      "318/318 - 0s - loss: 286.6453 - val_loss: 274.2875\n",
      "Epoch 43/1000\n",
      "318/318 - 0s - loss: 275.8653 - val_loss: 263.8459\n",
      "Epoch 44/1000\n",
      "318/318 - 0s - loss: 264.8237 - val_loss: 253.7572\n",
      "Epoch 45/1000\n",
      "318/318 - 0s - loss: 254.1353 - val_loss: 243.9226\n",
      "Epoch 46/1000\n",
      "318/318 - 0s - loss: 243.5491 - val_loss: 234.4024\n",
      "Epoch 47/1000\n",
      "318/318 - 0s - loss: 233.6796 - val_loss: 224.7923\n",
      "Epoch 48/1000\n",
      "318/318 - 0s - loss: 223.5773 - val_loss: 215.5671\n",
      "Epoch 49/1000\n",
      "318/318 - 0s - loss: 214.0024 - val_loss: 206.4449\n",
      "Epoch 50/1000\n",
      "318/318 - 0s - loss: 204.4699 - val_loss: 197.6591\n",
      "Epoch 51/1000\n",
      "318/318 - 0s - loss: 195.3672 - val_loss: 189.0771\n",
      "Epoch 52/1000\n",
      "318/318 - 0s - loss: 186.3924 - val_loss: 180.8569\n",
      "Epoch 53/1000\n",
      "318/318 - 0s - loss: 177.9832 - val_loss: 172.7694\n",
      "Epoch 54/1000\n",
      "318/318 - 0s - loss: 169.5574 - val_loss: 165.1229\n",
      "Epoch 55/1000\n",
      "318/318 - 0s - loss: 161.5109 - val_loss: 157.8007\n",
      "Epoch 56/1000\n",
      "318/318 - 0s - loss: 153.9685 - val_loss: 150.6356\n",
      "Epoch 57/1000\n",
      "318/318 - 0s - loss: 146.5475 - val_loss: 143.7912\n",
      "Epoch 58/1000\n",
      "318/318 - 0s - loss: 139.4929 - val_loss: 137.2418\n",
      "Epoch 59/1000\n",
      "318/318 - 0s - loss: 132.7666 - val_loss: 130.9395\n",
      "Epoch 60/1000\n",
      "318/318 - 0s - loss: 126.2464 - val_loss: 124.9605\n",
      "Epoch 61/1000\n",
      "318/318 - 0s - loss: 120.1294 - val_loss: 119.2275\n",
      "Epoch 62/1000\n",
      "318/318 - 0s - loss: 114.1818 - val_loss: 113.8398\n",
      "Epoch 63/1000\n",
      "318/318 - 0s - loss: 108.6902 - val_loss: 108.6473\n",
      "Epoch 64/1000\n",
      "318/318 - 0s - loss: 103.3137 - val_loss: 103.7866\n",
      "Epoch 65/1000\n",
      "318/318 - 0s - loss: 98.3175 - val_loss: 99.1687\n",
      "Epoch 66/1000\n",
      "318/318 - 0s - loss: 93.5058 - val_loss: 94.8430\n",
      "Epoch 67/1000\n",
      "318/318 - 0s - loss: 89.1232 - val_loss: 90.6798\n",
      "Epoch 68/1000\n",
      "318/318 - 0s - loss: 84.8195 - val_loss: 86.8035\n",
      "Epoch 69/1000\n",
      "318/318 - 0s - loss: 80.8524 - val_loss: 83.1355\n",
      "Epoch 70/1000\n",
      "318/318 - 0s - loss: 77.1056 - val_loss: 79.6888\n",
      "Epoch 71/1000\n",
      "318/318 - 0s - loss: 73.5369 - val_loss: 76.4916\n",
      "Epoch 72/1000\n",
      "318/318 - 0s - loss: 70.3072 - val_loss: 73.4255\n",
      "Epoch 73/1000\n",
      "318/318 - 0s - loss: 67.1837 - val_loss: 70.5831\n",
      "Epoch 74/1000\n",
      "318/318 - 0s - loss: 64.2762 - val_loss: 67.9292\n",
      "Epoch 75/1000\n",
      "318/318 - 0s - loss: 61.6100 - val_loss: 65.4101\n",
      "Epoch 76/1000\n",
      "318/318 - 0s - loss: 59.0720 - val_loss: 63.0649\n",
      "Epoch 77/1000\n",
      "318/318 - 0s - loss: 56.7040 - val_loss: 60.9001\n",
      "Epoch 78/1000\n",
      "318/318 - 0s - loss: 54.5318 - val_loss: 58.8557\n",
      "Epoch 79/1000\n",
      "318/318 - 0s - loss: 52.4581 - val_loss: 56.9827\n",
      "Epoch 80/1000\n",
      "318/318 - 0s - loss: 50.5940 - val_loss: 55.2165\n",
      "Epoch 81/1000\n",
      "318/318 - 0s - loss: 48.8353 - val_loss: 53.5669\n",
      "Epoch 82/1000\n",
      "318/318 - 0s - loss: 47.1674 - val_loss: 52.0598\n",
      "Epoch 83/1000\n",
      "318/318 - 0s - loss: 45.6734 - val_loss: 50.6410\n",
      "Epoch 84/1000\n",
      "318/318 - 0s - loss: 44.2437 - val_loss: 49.3170\n",
      "Epoch 85/1000\n",
      "318/318 - 0s - loss: 42.9216 - val_loss: 48.0850\n",
      "Epoch 86/1000\n",
      "318/318 - 0s - loss: 41.7309 - val_loss: 46.9103\n",
      "Epoch 87/1000\n",
      "318/318 - 0s - loss: 40.5788 - val_loss: 45.8289\n",
      "Epoch 88/1000\n",
      "318/318 - 0s - loss: 39.4881 - val_loss: 44.7997\n",
      "Epoch 89/1000\n",
      "318/318 - 0s - loss: 38.5204 - val_loss: 43.8071\n",
      "Epoch 90/1000\n",
      "318/318 - 0s - loss: 37.5593 - val_loss: 42.8883\n",
      "Epoch 91/1000\n",
      "318/318 - 0s - loss: 36.6765 - val_loss: 42.0183\n",
      "Epoch 92/1000\n",
      "318/318 - 0s - loss: 35.8574 - val_loss: 41.1947\n",
      "Epoch 93/1000\n",
      "318/318 - 0s - loss: 35.0927 - val_loss: 40.4084\n",
      "Epoch 94/1000\n",
      "318/318 - 0s - loss: 34.3598 - val_loss: 39.6787\n",
      "Epoch 95/1000\n",
      "318/318 - 0s - loss: 33.6681 - val_loss: 38.9736\n",
      "Epoch 96/1000\n",
      "318/318 - 0s - loss: 33.0176 - val_loss: 38.3109\n",
      "Epoch 97/1000\n",
      "318/318 - 0s - loss: 32.4220 - val_loss: 37.6560\n",
      "Epoch 98/1000\n",
      "318/318 - 0s - loss: 31.8005 - val_loss: 37.0819\n",
      "Epoch 99/1000\n",
      "318/318 - 0s - loss: 31.2842 - val_loss: 36.4714\n",
      "Epoch 100/1000\n",
      "318/318 - 0s - loss: 30.7557 - val_loss: 35.8832\n",
      "Epoch 101/1000\n",
      "318/318 - 0s - loss: 30.2430 - val_loss: 35.3297\n",
      "Epoch 102/1000\n",
      "318/318 - 0s - loss: 29.7587 - val_loss: 34.7948\n",
      "Epoch 103/1000\n",
      "318/318 - 0s - loss: 29.2909 - val_loss: 34.2648\n",
      "Epoch 104/1000\n",
      "318/318 - 0s - loss: 28.8315 - val_loss: 33.7618\n",
      "Epoch 105/1000\n",
      "318/318 - 0s - loss: 28.4139 - val_loss: 33.2596\n",
      "Epoch 106/1000\n",
      "318/318 - 0s - loss: 27.9781 - val_loss: 32.7708\n",
      "Epoch 107/1000\n",
      "318/318 - 0s - loss: 27.5862 - val_loss: 32.2751\n",
      "Epoch 108/1000\n",
      "318/318 - 0s - loss: 27.1770 - val_loss: 31.8075\n",
      "Epoch 109/1000\n",
      "318/318 - 0s - loss: 26.7813 - val_loss: 31.3396\n",
      "Epoch 110/1000\n",
      "318/318 - 0s - loss: 26.4055 - val_loss: 30.8867\n",
      "Epoch 111/1000\n",
      "318/318 - 0s - loss: 26.0492 - val_loss: 30.4230\n",
      "Epoch 112/1000\n",
      "318/318 - 0s - loss: 25.6713 - val_loss: 29.9963\n",
      "Epoch 113/1000\n",
      "318/318 - 0s - loss: 25.3193 - val_loss: 29.5606\n",
      "Epoch 114/1000\n",
      "318/318 - 0s - loss: 24.9876 - val_loss: 29.1122\n",
      "Epoch 115/1000\n",
      "318/318 - 0s - loss: 24.6255 - val_loss: 28.6932\n",
      "Epoch 116/1000\n",
      "318/318 - 0s - loss: 24.3087 - val_loss: 28.2582\n",
      "Epoch 117/1000\n",
      "318/318 - 0s - loss: 23.9629 - val_loss: 27.8427\n",
      "Epoch 118/1000\n",
      "318/318 - 0s - loss: 23.6407 - val_loss: 27.4367\n",
      "Epoch 119/1000\n",
      "318/318 - 0s - loss: 23.3275 - val_loss: 27.0159\n",
      "Epoch 120/1000\n",
      "318/318 - 0s - loss: 23.0111 - val_loss: 26.6011\n",
      "Epoch 121/1000\n",
      "318/318 - 0s - loss: 22.6946 - val_loss: 26.1975\n",
      "Epoch 122/1000\n",
      "318/318 - 0s - loss: 22.3802 - val_loss: 25.8277\n",
      "Epoch 123/1000\n",
      "318/318 - 0s - loss: 22.0892 - val_loss: 25.4244\n",
      "Epoch 124/1000\n",
      "318/318 - 0s - loss: 21.7904 - val_loss: 25.0261\n",
      "Epoch 125/1000\n",
      "318/318 - 0s - loss: 21.5067 - val_loss: 24.6346\n",
      "Epoch 126/1000\n",
      "318/318 - 0s - loss: 21.2111 - val_loss: 24.2572\n",
      "Epoch 127/1000\n",
      "318/318 - 0s - loss: 20.9246 - val_loss: 23.8694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/1000\n",
      "318/318 - 0s - loss: 20.6330 - val_loss: 23.5147\n",
      "Epoch 129/1000\n",
      "318/318 - 0s - loss: 20.3646 - val_loss: 23.1348\n",
      "Epoch 130/1000\n",
      "318/318 - 0s - loss: 20.0883 - val_loss: 22.7730\n",
      "Epoch 131/1000\n",
      "318/318 - 0s - loss: 19.8214 - val_loss: 22.4287\n",
      "Epoch 132/1000\n",
      "318/318 - 0s - loss: 19.5542 - val_loss: 22.0747\n",
      "Epoch 133/1000\n",
      "318/318 - 0s - loss: 19.3085 - val_loss: 21.7178\n",
      "Epoch 134/1000\n",
      "318/318 - 0s - loss: 19.0464 - val_loss: 21.3755\n",
      "Epoch 135/1000\n",
      "318/318 - 0s - loss: 18.8030 - val_loss: 21.0351\n",
      "Epoch 136/1000\n",
      "318/318 - 0s - loss: 18.5394 - val_loss: 20.7268\n",
      "Epoch 137/1000\n",
      "318/318 - 0s - loss: 18.3091 - val_loss: 20.3975\n",
      "Epoch 138/1000\n",
      "318/318 - 0s - loss: 18.0844 - val_loss: 20.0854\n",
      "Epoch 139/1000\n",
      "318/318 - 0s - loss: 17.8472 - val_loss: 19.7530\n",
      "Epoch 140/1000\n",
      "318/318 - 0s - loss: 17.6062 - val_loss: 19.4618\n",
      "Epoch 141/1000\n",
      "318/318 - 0s - loss: 17.3989 - val_loss: 19.1442\n",
      "Epoch 142/1000\n",
      "318/318 - 0s - loss: 17.1670 - val_loss: 18.8497\n",
      "Epoch 143/1000\n",
      "318/318 - 0s - loss: 16.9563 - val_loss: 18.5563\n",
      "Epoch 144/1000\n",
      "318/318 - 0s - loss: 16.7420 - val_loss: 18.2663\n",
      "Epoch 145/1000\n",
      "318/318 - 0s - loss: 16.5306 - val_loss: 17.9913\n",
      "Epoch 146/1000\n",
      "318/318 - 0s - loss: 16.3325 - val_loss: 17.7110\n",
      "Epoch 147/1000\n",
      "318/318 - 0s - loss: 16.1296 - val_loss: 17.4374\n",
      "Epoch 148/1000\n",
      "318/318 - 0s - loss: 15.9382 - val_loss: 17.1568\n",
      "Epoch 149/1000\n",
      "318/318 - 0s - loss: 15.7389 - val_loss: 16.8870\n",
      "Epoch 150/1000\n",
      "318/318 - 0s - loss: 15.5569 - val_loss: 16.6175\n",
      "Epoch 151/1000\n",
      "318/318 - 0s - loss: 15.3615 - val_loss: 16.3593\n",
      "Epoch 152/1000\n",
      "318/318 - 0s - loss: 15.1927 - val_loss: 16.0888\n",
      "Epoch 153/1000\n",
      "318/318 - 0s - loss: 14.9921 - val_loss: 15.8549\n",
      "Epoch 154/1000\n",
      "318/318 - 0s - loss: 14.8332 - val_loss: 15.6019\n",
      "Epoch 155/1000\n",
      "318/318 - 0s - loss: 14.6484 - val_loss: 15.3573\n",
      "Epoch 156/1000\n",
      "318/318 - 0s - loss: 14.4802 - val_loss: 15.1187\n",
      "Epoch 157/1000\n",
      "318/318 - 0s - loss: 14.3177 - val_loss: 14.8825\n",
      "Epoch 158/1000\n",
      "318/318 - 0s - loss: 14.1547 - val_loss: 14.6421\n",
      "Epoch 159/1000\n",
      "318/318 - 0s - loss: 13.9899 - val_loss: 14.4239\n",
      "Epoch 160/1000\n",
      "318/318 - 0s - loss: 13.8428 - val_loss: 14.1957\n",
      "Epoch 161/1000\n",
      "318/318 - 0s - loss: 13.6902 - val_loss: 13.9774\n",
      "Epoch 162/1000\n",
      "318/318 - 0s - loss: 13.5367 - val_loss: 13.7644\n",
      "Epoch 163/1000\n",
      "318/318 - 0s - loss: 13.3926 - val_loss: 13.5537\n",
      "Epoch 164/1000\n",
      "318/318 - 0s - loss: 13.2450 - val_loss: 13.3569\n",
      "Epoch 165/1000\n",
      "318/318 - 0s - loss: 13.1023 - val_loss: 13.1551\n",
      "Epoch 166/1000\n",
      "318/318 - 0s - loss: 12.9598 - val_loss: 12.9622\n",
      "Epoch 167/1000\n",
      "318/318 - 0s - loss: 12.8250 - val_loss: 12.7598\n",
      "Epoch 168/1000\n",
      "318/318 - 0s - loss: 12.6939 - val_loss: 12.5651\n",
      "Epoch 169/1000\n",
      "318/318 - 0s - loss: 12.5641 - val_loss: 12.3922\n",
      "Epoch 170/1000\n",
      "318/318 - 0s - loss: 12.4357 - val_loss: 12.2248\n",
      "Epoch 171/1000\n",
      "318/318 - 0s - loss: 12.3151 - val_loss: 12.0410\n",
      "Epoch 172/1000\n",
      "318/318 - 0s - loss: 12.1944 - val_loss: 11.8641\n",
      "Epoch 173/1000\n",
      "318/318 - 0s - loss: 12.0834 - val_loss: 11.6962\n",
      "Epoch 174/1000\n",
      "318/318 - 0s - loss: 11.9610 - val_loss: 11.5345\n",
      "Epoch 175/1000\n",
      "318/318 - 0s - loss: 11.8606 - val_loss: 11.3777\n",
      "Epoch 176/1000\n",
      "318/318 - 0s - loss: 11.7485 - val_loss: 11.2165\n",
      "Epoch 177/1000\n",
      "318/318 - 0s - loss: 11.6395 - val_loss: 11.0609\n",
      "Epoch 178/1000\n",
      "318/318 - 0s - loss: 11.5322 - val_loss: 10.9115\n",
      "Epoch 179/1000\n",
      "318/318 - 0s - loss: 11.4358 - val_loss: 10.7806\n",
      "Epoch 180/1000\n",
      "318/318 - 0s - loss: 11.3288 - val_loss: 10.6355\n",
      "Epoch 181/1000\n",
      "318/318 - 0s - loss: 11.2334 - val_loss: 10.4920\n",
      "Epoch 182/1000\n",
      "318/318 - 0s - loss: 11.1443 - val_loss: 10.3541\n",
      "Epoch 183/1000\n",
      "318/318 - 0s - loss: 11.0479 - val_loss: 10.2298\n",
      "Epoch 184/1000\n",
      "318/318 - 0s - loss: 10.9617 - val_loss: 10.1004\n",
      "Epoch 185/1000\n",
      "318/318 - 0s - loss: 10.8737 - val_loss: 9.9769\n",
      "Epoch 186/1000\n",
      "318/318 - 0s - loss: 10.7951 - val_loss: 9.8565\n",
      "Epoch 187/1000\n",
      "318/318 - 0s - loss: 10.7066 - val_loss: 9.7402\n",
      "Epoch 188/1000\n",
      "318/318 - 0s - loss: 10.6296 - val_loss: 9.6161\n",
      "Epoch 189/1000\n",
      "318/318 - 0s - loss: 10.5590 - val_loss: 9.4959\n",
      "Epoch 190/1000\n",
      "318/318 - 0s - loss: 10.4872 - val_loss: 9.3963\n",
      "Epoch 191/1000\n",
      "318/318 - 0s - loss: 10.4005 - val_loss: 9.2895\n",
      "Epoch 192/1000\n",
      "318/318 - 0s - loss: 10.3372 - val_loss: 9.1858\n",
      "Epoch 193/1000\n",
      "318/318 - 0s - loss: 10.2764 - val_loss: 9.0750\n",
      "Epoch 194/1000\n",
      "318/318 - 0s - loss: 10.2069 - val_loss: 8.9742\n",
      "Epoch 195/1000\n",
      "318/318 - 0s - loss: 10.1411 - val_loss: 8.8877\n",
      "Epoch 196/1000\n",
      "318/318 - 0s - loss: 10.0853 - val_loss: 8.7972\n",
      "Epoch 197/1000\n",
      "318/318 - 0s - loss: 10.0266 - val_loss: 8.7057\n",
      "Epoch 198/1000\n",
      "318/318 - 0s - loss: 9.9721 - val_loss: 8.6156\n",
      "Epoch 199/1000\n",
      "318/318 - 0s - loss: 9.9277 - val_loss: 8.5359\n",
      "Epoch 200/1000\n",
      "318/318 - 0s - loss: 9.8652 - val_loss: 8.4491\n",
      "Epoch 201/1000\n",
      "318/318 - 0s - loss: 9.8155 - val_loss: 8.3659\n",
      "Epoch 202/1000\n",
      "318/318 - 0s - loss: 9.7696 - val_loss: 8.2863\n",
      "Epoch 203/1000\n",
      "318/318 - 0s - loss: 9.7268 - val_loss: 8.2117\n",
      "Epoch 204/1000\n",
      "318/318 - 0s - loss: 9.6780 - val_loss: 8.1404\n",
      "Epoch 205/1000\n",
      "318/318 - 0s - loss: 9.6322 - val_loss: 8.0700\n",
      "Epoch 206/1000\n",
      "318/318 - 0s - loss: 9.5954 - val_loss: 7.9944\n",
      "Epoch 207/1000\n",
      "318/318 - 0s - loss: 9.5523 - val_loss: 7.9420\n",
      "Epoch 208/1000\n",
      "318/318 - 0s - loss: 9.5133 - val_loss: 7.8798\n",
      "Epoch 209/1000\n",
      "318/318 - 0s - loss: 9.4734 - val_loss: 7.8152\n",
      "Epoch 210/1000\n",
      "318/318 - 0s - loss: 9.4397 - val_loss: 7.7523\n",
      "Epoch 211/1000\n",
      "318/318 - 0s - loss: 9.4057 - val_loss: 7.6945\n",
      "Epoch 212/1000\n",
      "318/318 - 0s - loss: 9.3737 - val_loss: 7.6430\n",
      "Epoch 213/1000\n",
      "318/318 - 0s - loss: 9.3384 - val_loss: 7.5855\n",
      "Epoch 214/1000\n",
      "318/318 - 0s - loss: 9.3161 - val_loss: 7.5263\n",
      "Epoch 215/1000\n",
      "318/318 - 0s - loss: 9.2732 - val_loss: 7.4822\n",
      "Epoch 216/1000\n",
      "318/318 - 0s - loss: 9.2456 - val_loss: 7.4319\n",
      "Epoch 217/1000\n",
      "318/318 - 0s - loss: 9.2176 - val_loss: 7.3844\n",
      "Epoch 218/1000\n",
      "318/318 - 0s - loss: 9.1933 - val_loss: 7.3461\n",
      "Epoch 219/1000\n",
      "318/318 - 0s - loss: 9.1622 - val_loss: 7.3013\n",
      "Epoch 220/1000\n",
      "318/318 - 0s - loss: 9.1407 - val_loss: 7.2543\n",
      "Epoch 221/1000\n",
      "318/318 - 0s - loss: 9.1145 - val_loss: 7.2077\n",
      "Epoch 222/1000\n",
      "318/318 - 0s - loss: 9.0903 - val_loss: 7.1662\n",
      "Epoch 223/1000\n",
      "318/318 - 0s - loss: 9.0672 - val_loss: 7.1338\n",
      "Epoch 224/1000\n",
      "318/318 - 0s - loss: 9.0459 - val_loss: 7.1015\n",
      "Epoch 225/1000\n",
      "318/318 - 0s - loss: 9.0234 - val_loss: 7.0669\n",
      "Epoch 226/1000\n",
      "318/318 - 0s - loss: 9.0022 - val_loss: 7.0391\n",
      "Epoch 227/1000\n",
      "318/318 - 0s - loss: 8.9854 - val_loss: 7.0015\n",
      "Epoch 228/1000\n",
      "318/318 - 0s - loss: 8.9640 - val_loss: 6.9651\n",
      "Epoch 229/1000\n",
      "318/318 - 0s - loss: 8.9442 - val_loss: 6.9324\n",
      "Epoch 230/1000\n",
      "318/318 - 0s - loss: 8.9212 - val_loss: 6.9037\n",
      "Epoch 231/1000\n",
      "318/318 - 0s - loss: 8.9047 - val_loss: 6.8715\n",
      "Epoch 232/1000\n",
      "318/318 - 0s - loss: 8.8866 - val_loss: 6.8425\n",
      "Epoch 233/1000\n",
      "318/318 - 0s - loss: 8.8658 - val_loss: 6.8182\n",
      "Epoch 234/1000\n",
      "318/318 - 0s - loss: 8.8472 - val_loss: 6.7958\n",
      "Epoch 235/1000\n",
      "318/318 - 0s - loss: 8.8333 - val_loss: 6.7629\n",
      "Epoch 236/1000\n",
      "318/318 - 0s - loss: 8.8134 - val_loss: 6.7329\n",
      "Epoch 237/1000\n",
      "318/318 - 0s - loss: 8.7993 - val_loss: 6.7161\n",
      "Epoch 238/1000\n",
      "318/318 - 0s - loss: 8.7801 - val_loss: 6.6901\n",
      "Epoch 239/1000\n",
      "318/318 - 0s - loss: 8.7649 - val_loss: 6.6632\n",
      "Epoch 240/1000\n",
      "318/318 - 0s - loss: 8.7507 - val_loss: 6.6411\n",
      "Epoch 241/1000\n",
      "318/318 - 0s - loss: 8.7363 - val_loss: 6.6269\n",
      "Epoch 242/1000\n",
      "318/318 - 0s - loss: 8.7235 - val_loss: 6.5938\n",
      "Epoch 243/1000\n",
      "318/318 - 0s - loss: 8.7077 - val_loss: 6.5794\n",
      "Epoch 244/1000\n",
      "318/318 - 0s - loss: 8.6975 - val_loss: 6.5697\n",
      "Epoch 245/1000\n",
      "318/318 - 0s - loss: 8.6829 - val_loss: 6.5442\n",
      "Epoch 246/1000\n",
      "318/318 - 0s - loss: 8.6685 - val_loss: 6.5281\n",
      "Epoch 247/1000\n",
      "318/318 - 0s - loss: 8.6591 - val_loss: 6.5049\n",
      "Epoch 248/1000\n",
      "318/318 - 0s - loss: 8.6456 - val_loss: 6.4993\n",
      "Epoch 249/1000\n",
      "318/318 - 0s - loss: 8.6367 - val_loss: 6.4753\n",
      "Epoch 250/1000\n",
      "318/318 - 0s - loss: 8.6194 - val_loss: 6.4614\n",
      "Epoch 251/1000\n",
      "318/318 - 0s - loss: 8.6092 - val_loss: 6.4386\n",
      "Epoch 252/1000\n",
      "318/318 - 0s - loss: 8.5972 - val_loss: 6.4207\n",
      "Epoch 253/1000\n",
      "318/318 - 0s - loss: 8.5895 - val_loss: 6.4151\n",
      "Epoch 254/1000\n",
      "318/318 - 0s - loss: 8.5823 - val_loss: 6.3914\n",
      "Epoch 255/1000\n",
      "318/318 - 0s - loss: 8.5674 - val_loss: 6.3721\n",
      "Epoch 256/1000\n",
      "318/318 - 0s - loss: 8.5556 - val_loss: 6.3579\n",
      "Epoch 257/1000\n",
      "318/318 - 0s - loss: 8.5489 - val_loss: 6.3568\n",
      "Epoch 258/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/318 - 0s - loss: 8.5402 - val_loss: 6.3365\n",
      "Epoch 259/1000\n",
      "318/318 - 0s - loss: 8.5381 - val_loss: 6.3127\n",
      "Epoch 260/1000\n",
      "318/318 - 0s - loss: 8.5178 - val_loss: 6.3045\n",
      "Epoch 261/1000\n",
      "318/318 - 0s - loss: 8.5096 - val_loss: 6.2970\n",
      "Epoch 262/1000\n",
      "318/318 - 0s - loss: 8.5045 - val_loss: 6.2862\n",
      "Epoch 263/1000\n",
      "318/318 - 0s - loss: 8.4951 - val_loss: 6.2834\n",
      "Epoch 264/1000\n",
      "318/318 - 0s - loss: 8.4840 - val_loss: 6.2646\n",
      "Epoch 265/1000\n",
      "318/318 - 0s - loss: 8.4783 - val_loss: 6.2509\n",
      "Epoch 266/1000\n",
      "318/318 - 0s - loss: 8.4683 - val_loss: 6.2347\n",
      "Epoch 267/1000\n",
      "318/318 - 0s - loss: 8.4704 - val_loss: 6.2394\n",
      "Epoch 268/1000\n",
      "318/318 - 0s - loss: 8.4495 - val_loss: 6.2219\n",
      "Epoch 269/1000\n",
      "318/318 - 0s - loss: 8.4554 - val_loss: 6.1937\n",
      "Epoch 270/1000\n",
      "318/318 - 0s - loss: 8.4355 - val_loss: 6.1936\n",
      "Epoch 271/1000\n",
      "318/318 - 0s - loss: 8.4245 - val_loss: 6.1848\n",
      "Epoch 272/1000\n",
      "318/318 - 0s - loss: 8.4183 - val_loss: 6.1699\n",
      "Epoch 273/1000\n",
      "318/318 - 0s - loss: 8.4108 - val_loss: 6.1620\n",
      "Epoch 274/1000\n",
      "318/318 - 0s - loss: 8.4003 - val_loss: 6.1628\n",
      "Epoch 275/1000\n",
      "318/318 - 0s - loss: 8.3955 - val_loss: 6.1478\n",
      "Epoch 276/1000\n",
      "318/318 - 0s - loss: 8.3878 - val_loss: 6.1476\n",
      "Epoch 277/1000\n",
      "318/318 - 0s - loss: 8.3787 - val_loss: 6.1309\n",
      "Epoch 278/1000\n",
      "318/318 - 0s - loss: 8.3771 - val_loss: 6.1338\n",
      "Epoch 279/1000\n",
      "318/318 - 0s - loss: 8.3664 - val_loss: 6.1141\n",
      "Epoch 280/1000\n",
      "318/318 - 0s - loss: 8.3605 - val_loss: 6.1066\n",
      "Epoch 281/1000\n",
      "318/318 - 0s - loss: 8.3559 - val_loss: 6.1061\n",
      "Epoch 282/1000\n",
      "318/318 - 0s - loss: 8.3467 - val_loss: 6.1013\n",
      "Epoch 283/1000\n",
      "318/318 - 0s - loss: 8.3492 - val_loss: 6.0830\n",
      "Epoch 284/1000\n",
      "318/318 - 0s - loss: 8.3401 - val_loss: 6.0807\n",
      "Epoch 285/1000\n",
      "318/318 - 0s - loss: 8.3291 - val_loss: 6.0770\n",
      "Epoch 286/1000\n",
      "318/318 - 0s - loss: 8.3247 - val_loss: 6.0864\n",
      "Epoch 287/1000\n",
      "318/318 - 0s - loss: 8.3165 - val_loss: 6.0742\n",
      "Epoch 288/1000\n",
      "318/318 - 0s - loss: 8.3108 - val_loss: 6.0675\n",
      "Epoch 289/1000\n",
      "318/318 - 0s - loss: 8.3074 - val_loss: 6.0619\n",
      "Epoch 290/1000\n",
      "318/318 - 0s - loss: 8.2990 - val_loss: 6.0541\n",
      "Epoch 291/1000\n",
      "318/318 - 0s - loss: 8.2960 - val_loss: 6.0521\n",
      "Epoch 292/1000\n",
      "318/318 - 0s - loss: 8.2926 - val_loss: 6.0345\n",
      "Epoch 293/1000\n",
      "318/318 - 0s - loss: 8.2825 - val_loss: 6.0341\n",
      "Epoch 294/1000\n",
      "318/318 - 1s - loss: 8.2791 - val_loss: 6.0401\n",
      "Epoch 295/1000\n",
      "318/318 - 0s - loss: 8.2743 - val_loss: 6.0308\n",
      "Epoch 296/1000\n",
      "318/318 - 0s - loss: 8.2678 - val_loss: 6.0289\n",
      "Epoch 297/1000\n",
      "318/318 - 0s - loss: 8.2628 - val_loss: 6.0233\n",
      "Epoch 298/1000\n",
      "318/318 - 0s - loss: 8.2607 - val_loss: 6.0186\n",
      "Epoch 299/1000\n",
      "318/318 - 0s - loss: 8.2535 - val_loss: 6.0133\n",
      "Epoch 300/1000\n",
      "318/318 - 0s - loss: 8.2505 - val_loss: 6.0118\n",
      "Epoch 301/1000\n",
      "318/318 - 0s - loss: 8.2442 - val_loss: 6.0060\n",
      "Epoch 302/1000\n",
      "318/318 - 0s - loss: 8.2404 - val_loss: 6.0032\n",
      "Epoch 303/1000\n",
      "318/318 - 0s - loss: 8.2463 - val_loss: 5.9829\n",
      "Epoch 304/1000\n",
      "318/318 - 0s - loss: 8.2387 - val_loss: 5.9960\n",
      "Epoch 305/1000\n",
      "318/318 - 0s - loss: 8.2258 - val_loss: 5.9948\n",
      "Epoch 306/1000\n",
      "318/318 - 0s - loss: 8.2243 - val_loss: 5.9923\n",
      "Epoch 307/1000\n",
      "318/318 - 0s - loss: 8.2213 - val_loss: 5.9886\n",
      "Epoch 308/1000\n",
      "318/318 - 0s - loss: 8.2198 - val_loss: 5.9829\n",
      "Epoch 00308: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f527331208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "#model.add(Dense(10, activation='tanh'))   \n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "#checkpointer = ModelCheckpoint(filepath=\"dnn/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "# batch_size: Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor],verbose=2,epochs=1000)\n",
    "#model.load_weights('dnn/best_weights.hdf5') # load weights from best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (RMSE): 2.4459946155548096\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict and measure RMSE\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "\n",
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try varying optimizer paramters and batch size after class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "* [Google Colab](https://colab.research.google.com/) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow with free GPU support.  No setup needed.\n",
    "* [IBM Cognitive Class Labs](https://www.datascientistworkbench.com) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow.  No setup needed.\n",
    "* [Python Anaconda](https://www.continuum.io/downloads) - Python distribution that includes many data science packages, such as Numpy, Scipy, Scikit-Learn, Pandas, and much more.\n",
    "* [TensorFlow](https://www.tensorflow.org/) - Google's mathematics package for deep learning.\n",
    "* [Kaggle](https://www.kaggle.com/) - Competitive data science.  Good source of sample data.\n",
    "* T81-558: Applications of Deep Neural Networks. Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

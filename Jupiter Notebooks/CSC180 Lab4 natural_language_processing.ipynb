{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4: Natural Language Processing\n",
    "\n",
    "\n",
    "#### CSC 180  Intelligent Systems (Spring 2020)\n",
    "\n",
    "#### Dr. Haiquan Chen, California State University, Sacramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to vectorize natural lauguage data?\n",
    "\n",
    "Python offers a set of tools for extracting features:http://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer: transforms text into a \"sparse matrix\" where rows are text and columns are words, and values are occurrence values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 2 1 0 1]\n",
      " [1 0 0 0 1 0 1 1 0]\n",
      " [0 1 3 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.feature_extraction.text as sk_text\n",
    "\n",
    "vectorizer = sk_text.CountVectorizer(min_df=1)\n",
    "#vectorizer = sk_text.CountVectorizer(min_df=1, stop_words = 'english')\n",
    "\n",
    "#min_df: ignore terms that have a document frequency < min_df.\n",
    "\n",
    "corpus = ['This is the first document.',\n",
    "           'this is the second second document.',\n",
    "           'And the third one.',\n",
    "           'Is this the first first first document?',\n",
    "          ]\n",
    "\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(type(matrix))          # Compressed Sparse Row matrix\n",
    "print(matrix.toarray())        #  convert it to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdfVectorizer: transforms text into a \"sparse matrix\" where rows are text and columns are words, and values are the tf-dif values. \n",
    "\n",
    "More here: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[0.         0.43877674 0.54197657 0.43877674 0.         0.\n",
      "  0.35872874 0.         0.43877674]\n",
      " [0.         0.27230147 0.         0.27230147 0.         0.85322574\n",
      "  0.22262429 0.         0.27230147]\n",
      " [0.55280532 0.         0.         0.         0.55280532 0.\n",
      "  0.28847675 0.55280532 0.        ]\n",
      " [0.         0.23973261 0.88835239 0.23973261 0.         0.\n",
      "  0.19599711 0.         0.23973261]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = sk_text.TfidfVectorizer(\n",
    "                             #stop_words='english',\n",
    "                             max_features = 1000,\n",
    "                             min_df=1)\n",
    "\n",
    "\n",
    "#max_features:  build a vocabulary that only consider the top max_features features ordered by term frequency across the corpus.\n",
    "\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(type(matrix))          # Compressed Sparse Row matrix\n",
    "print(matrix.toarray())        #  convert it to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = sk_text.TfidfVectorizer(stop_words='english',\n",
    "                             #max_features = 1000,\n",
    "                             min_df=2, \n",
    "                             max_df=500\n",
    "                             )\n",
    "\n",
    "#min_df: ignore terms that have a document frequency < min_df.\n",
    "#max_df: ignore terms that have a document frequency > max_df\n",
    "\n",
    "\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "print(type(matrix))               # Compressed Sparse Row matrix\n",
    "\n",
    "tfidf_data = matrix.toarray()     #  convert it to numpy array\n",
    "\n",
    "print(tfidf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you vectorize the text, you can send the data to models\n",
    "\n",
    "An example of what we want to do:\n",
    "http://scikit-learn.org/stable/auto_examples/text/document_clustering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43877674, 0.54197657, 0.43877674, 0.35872874, 0.43877674],\n",
       "       [0.52210862, 0.        , 0.52210862, 0.42685801, 0.52210862],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.23973261, 0.88835239, 0.23973261, 0.19599711, 0.23973261]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_0 = \"Japan's prime minister, Shinzo Abe, is working towards healing the economic turmoil in his own country for his view on the future of his people.\"\n",
    "document_1 = \"Vladimir Putin is working hard to fix the economy in Russia as the Ruble has tumbled.\"\n",
    "document_2 = \"What's the future of Abenomics? We asked Shinzo Abe for his views\"\n",
    "document_3 = \"Obama has eased sanctions on Cuba while accelerating those against the Russian Economy, even as the Ruble's value falls almost daily.\"\n",
    "document_4 = \"Vladimir Putin is riding a horse while hunting deer. Vladimir Putin always seems so serious about things - even riding horses. Is he crazy?\"\n",
    "\n",
    "\n",
    "corpus = [document_0, document_1, document_2, document_3, document_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document', 'second']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = sk_text.TfidfVectorizer(stop_words='english',\n",
    "                             max_features = 100,\n",
    "                             min_df=1, \n",
    "                             #max_df=5\n",
    "                             )\n",
    "\n",
    "#min_df: ignore terms that have a document frequency < min_df.\n",
    "#max_df: ignore terms that have a document frequency > max_df\n",
    "\n",
    "\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "tfidf_data = matrix.toarray()     #  convert it to numpy array\n",
    "#print(tfidf_data)\n",
    "#print(tfidf_data.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "#print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

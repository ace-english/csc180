{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Yelp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import relevent libraries. Add useful functions from the \"useful gems\" lab.I have also included a helper function to tell me that my browser is not crashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import time, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from scipy.stats import zscore\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from collections.abc import Sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import winsound\n",
    "\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "    \n",
    "#Show progress bar in loop\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n",
    "    \n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#Let me know when you're done!\n",
    "def beep():\n",
    "    duration = 500  # milliseconds\n",
    "    freq = 1040  # Hz\n",
    "    winsound.Beep(freq, duration)\n",
    "\n",
    "loadFresh=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First determine businesses have enough reviews to be relevent for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(loadFresh):\n",
    "    #Convert raw business data into tsv\n",
    "    outfile = open(\"businesses.tsv\", 'w')\n",
    "    sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "    sfile.writerow(['business_id','stars', 'review_count'])\n",
    "    with open('yelp_dataset/business.json', encoding=\"utf-8\") as f:\n",
    "     i=0\n",
    "     for line in f:\n",
    "        row = json.loads(line)\n",
    "        if(row['review_count']>=20):\n",
    "            sfile.writerow([row['business_id'], row['stars'], (row['review_count'])])\n",
    "        i=i+1\n",
    "        update_progress(i / 192610)\n",
    "\n",
    "    update_progress(1);\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>45042</td>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11344</td>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29166</td>\n",
       "      <td>--7zmmkVg-IMGaXbuVd0SQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37751</td>\n",
       "      <td>--DaPTJW3-tB1vP-PfdTEg</td>\n",
       "      <td>3.5</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44660</td>\n",
       "      <td>zzsOLFhgUw8gnjLTVVItFA</td>\n",
       "      <td>4.5</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13453</td>\n",
       "      <td>zzwaS0xn1MVEPEf0hNLjew</td>\n",
       "      <td>3.5</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>zzwhN7x37nyjP0ZM8oiHmw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46061</td>\n",
       "      <td>zzwicjPC9g246MK2M1ZFBA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36284</td>\n",
       "      <td>zzzaIBwimxVej4tY6qFOUQ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57644 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  business_id  stars  review_count\n",
       "45042  --1UhMGODdWsrMastO9DZw    4.0            24\n",
       "11344  --6MefnULPED_I942VcFNA    3.0            44\n",
       "29166  --7zmmkVg-IMGaXbuVd0SQ    4.0            58\n",
       "49157  --9e1ONYQuAa-CB_Rrw7Tw    4.0          1613\n",
       "37751  --DaPTJW3-tB1vP-PfdTEg    3.5            49\n",
       "...                       ...    ...           ...\n",
       "44660  zzsOLFhgUw8gnjLTVVItFA    4.5           105\n",
       "13453  zzwaS0xn1MVEPEf0hNLjew    3.5            68\n",
       "356    zzwhN7x37nyjP0ZM8oiHmw    4.0            54\n",
       "46061  zzwicjPC9g246MK2M1ZFBA    3.0            70\n",
       "36284  zzzaIBwimxVej4tY6qFOUQ    3.5            37\n",
       "\n",
       "[57644 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load business table\n",
    "business_df= pd.read_csv('businesses.tsv', delimiter =\"\\t\", encoding=\"utf-8\")\n",
    "business_df=business_df.sort_values('business_id');\n",
    "business_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found 57644 with enough reviews to be useful. All stored in business_df, ordered by business ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review data\n",
    "Open the review data and convert into a TSV with only the relevent information. Runs a progress bar while loading. To save space, only writes to file if the business has 20 reviews or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(loadFresh):\n",
    "    #Convert raw review data into TSV\n",
    "    outfile = open(\"review_stars.tsv\", 'w')\n",
    "    sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "    sfile.writerow(['business_id','stars', 'text'])\n",
    "    with open('yelp_dataset/review.json', encoding=\"utf-8\") as f:\n",
    "     i=0\n",
    "     for line in f:\n",
    "        row = json.loads(line)\n",
    "        # Check if businessID if present in business table\n",
    "        if(row['business_id'] in business_df['business_id'].tolist()):\n",
    "            # some special char must be encoded in 'utf-8'\n",
    "            sfile.writerow([row['business_id'], row['stars'], (row['text']).encode('utf-8')])\n",
    "        update_progress(i / 2000000)\n",
    "        i=i+1\n",
    "\n",
    "    update_progress(1);\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Total bill for this horrible service? Over $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>5</td>\n",
       "      <td>b\"I *adore* Travis at the Hard Rock's new Kell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>5</td>\n",
       "      <td>b\"I have to say that this office really has it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Today was my second out of three sessions I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>eU_713ec6fTGNO4BegRaww</td>\n",
       "      <td>4</td>\n",
       "      <td>b'I\\'ll be the first to admit that I was not e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523429</td>\n",
       "      <td>LHXisknIbUy_XtdEQc7x9w</td>\n",
       "      <td>5</td>\n",
       "      <td>b'I read the bad reviews after I booked I almo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523430</td>\n",
       "      <td>IJlEACzNH-i_6Ovppj1KSQ</td>\n",
       "      <td>5</td>\n",
       "      <td>b\"Review for their dinner - fall menu.\\n\\nI ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523431</td>\n",
       "      <td>gRpb1HS7A8l3i4yttY3r6g</td>\n",
       "      <td>1</td>\n",
       "      <td>b\"DO NOT bother with this place!!! They could ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523432</td>\n",
       "      <td>eQAp73ks6V6VmsAbZX4RJA</td>\n",
       "      <td>5</td>\n",
       "      <td>b'My husband and I are obsessed. The service i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523433</td>\n",
       "      <td>vo8L42IzyEAIbEy51eiwQA</td>\n",
       "      <td>2</td>\n",
       "      <td>b'This place was horrible , ask for steak &amp; eg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>523434 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  stars  \\\n",
       "0       ujmEBvifdJM6h6RLv4wQIg      1   \n",
       "1       NZnhc2sEQy3RmzKTZnqtwQ      5   \n",
       "2       WTqjgwHlXbSFevF32_DJVw      5   \n",
       "3       b1b1eb3uo-w561D0ZfCEiQ      1   \n",
       "4       eU_713ec6fTGNO4BegRaww      4   \n",
       "...                        ...    ...   \n",
       "523429  LHXisknIbUy_XtdEQc7x9w      5   \n",
       "523430  IJlEACzNH-i_6Ovppj1KSQ      5   \n",
       "523431  gRpb1HS7A8l3i4yttY3r6g      1   \n",
       "523432  eQAp73ks6V6VmsAbZX4RJA      5   \n",
       "523433  vo8L42IzyEAIbEy51eiwQA      2   \n",
       "\n",
       "                                                     text  \n",
       "0       b'Total bill for this horrible service? Over $...  \n",
       "1       b\"I *adore* Travis at the Hard Rock's new Kell...  \n",
       "2       b\"I have to say that this office really has it...  \n",
       "3       b'Today was my second out of three sessions I ...  \n",
       "4       b'I\\'ll be the first to admit that I was not e...  \n",
       "...                                                   ...  \n",
       "523429  b'I read the bad reviews after I booked I almo...  \n",
       "523430  b\"Review for their dinner - fall menu.\\n\\nI ha...  \n",
       "523431  b\"DO NOT bother with this place!!! They could ...  \n",
       "523432  b'My husband and I are obsessed. The service i...  \n",
       "523433  b'This place was horrible , ask for steak & eg...  \n",
       "\n",
       "[523434 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load review data\n",
    "df= pd.read_csv('review_stars.tsv', delimiter =\"\\t\", encoding=\"utf-8\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language preprocessing\n",
    "First, aggregates all reviews under their business ID. Then we can run TFIDF on the sum of all the reviews in preparation to do language analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>80017</th>\n",
       "      <th>80018</th>\n",
       "      <th>80019</th>\n",
       "      <th>80020</th>\n",
       "      <th>80021</th>\n",
       "      <th>80022</th>\n",
       "      <th>80023</th>\n",
       "      <th>80024</th>\n",
       "      <th>80025</th>\n",
       "      <th>80026</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-092wE7j5HZOogMLAh40zA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1VaIJza42Hjev6ukacCNg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1xuC540Nycht_iWFeJ-dw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-49WY_TEa9ZEcRk_GnuLog</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5595</td>\n",
       "      <td>zyPGYeXF4XKCqNN1pjFWhg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5596</td>\n",
       "      <td>zyr5pzOs3SJIX3K-nvC2zg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5597</td>\n",
       "      <td>zz3CqZhNx2rQ_Yp6zHze-A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5598</td>\n",
       "      <td>zzOo9n22fBbKAhbSpMzggA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5599</td>\n",
       "      <td>zzwhN7x37nyjP0ZM8oiHmw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5600 rows Ã— 80028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id    0    1    2    3    4    5    6    7    8  \\\n",
       "0                     #NAME?  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1     -092wE7j5HZOogMLAh40zA  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2     -1VaIJza42Hjev6ukacCNg  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3     -1xuC540Nycht_iWFeJ-dw  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4     -49WY_TEa9ZEcRk_GnuLog  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...                      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "5595  zyPGYeXF4XKCqNN1pjFWhg  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "5596  zyr5pzOs3SJIX3K-nvC2zg  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "5597  zz3CqZhNx2rQ_Yp6zHze-A  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "5598  zzOo9n22fBbKAhbSpMzggA  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "5599  zzwhN7x37nyjP0ZM8oiHmw  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      ...  80017  80018  80019  80020  80021  80022  80023  80024  80025  \\\n",
       "0     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5595  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "5596  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "5597  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "5598  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "5599  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      80026  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "5595    0.0  \n",
       "5596    0.0  \n",
       "5597    0.0  \n",
       "5598    0.0  \n",
       "5599    0.0  \n",
       "\n",
       "[5600 rows x 80028 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#groups reviews by businessID\n",
    "df_review_group=df.groupby('business_id')['text'].sum()\n",
    "df_reviews = pd.DataFrame({'business_id':df_review_group.index, 'all_reviews':df_review_group.values})\n",
    "df_reviews\n",
    "\n",
    "#language preprocessing\n",
    "vectorizer = sk_text.TfidfVectorizer(stop_words='english',\n",
    "                             min_df=2, \n",
    "                             max_df=500)\n",
    "\n",
    "#df_reviews['all_reviews'] = vectorizer.fit_transform(df_reviews['all_reviews'])\n",
    "vector_reviews=vectorizer.fit_transform(df_reviews[\"all_reviews\"])\n",
    "\n",
    "#split off business ID\n",
    "col_id=df_reviews['business_id']\n",
    "#create dataframe from vectored reviews\n",
    "df_vector_reviews=pd.DataFrame(vector_reviews.todense())\n",
    "#concat to single dataframe\n",
    "df_tfidf_reviews=pd.concat([col_id,df_vector_reviews],axis=1)\n",
    "\n",
    "display(df_tfidf_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>80017</th>\n",
       "      <th>80018</th>\n",
       "      <th>80019</th>\n",
       "      <th>80020</th>\n",
       "      <th>80021</th>\n",
       "      <th>80022</th>\n",
       "      <th>80023</th>\n",
       "      <th>80024</th>\n",
       "      <th>80025</th>\n",
       "      <th>80026</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5595</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5596</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5597</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5598</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5599</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5600 rows Ã— 80028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars    0    1    2    3    4    5    6    7    8  ...  80017  80018  \\\n",
       "0         1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "1         5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "2         5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "3         1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "4         4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "5595      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "5596      5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "5597      4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "5598      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "5599      4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "\n",
       "      80019  80020  80021  80022  80023  80024  80025  80026  \n",
       "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "5595    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "5596    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "5597    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "5598    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "5599    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5600 rows x 80028 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join total reviews with aggregated review data\n",
    "df_join=pd.concat([df, df_tfidf_reviews], axis=1, join='inner')\n",
    "#drop unnecesary info\n",
    "df_sklearn_ready=df_join.drop(columns=['business_id', 'text'])\n",
    "df_sklearn_ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y is our list of reviews and X is your table of language data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get arrays for training\n",
    "y=df_sklearn_ready[\"stars\"].values\n",
    "x=df_sklearn_ready.drop([\"stars\"], axis=1).values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3920, 80027)\n",
      "(3920,)\n",
      "(1680, 80027)\n",
      "(1680,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is clean and it's time to feed it to the AI\n",
    "\n",
    "# Machine learning\n",
    "## TensorFlow Regression\n",
    "Since the idea is to make a bunch of models to test, to start here are some functions to repeatedly create and test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to make model\n",
    "def make_model(x,y,firstLayer=25,secondLayer=10,epochs=50, optimizer='adam', activation='relu',\n",
    "               stopEarly=1, monitor='loss', min_delta=0.001, patience=2, verbose=2):\n",
    "    model = Sequential()\n",
    "\n",
    "    #Set up layers\n",
    "    model.add(Dense(25, input_dim=x.shape[1], activation=activation)) # Hidden 1 \n",
    "    model.add(Dense(10, activation)) # Hidden 2\n",
    "    model.add(Dense(1)) # Output\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    #set up early stop parameters\n",
    "    if(stopEarly):\n",
    "        earlyStop = EarlyStopping(monitor=monitor, min_delta=min_delta, patience=patience, verbose=verbose, mode='auto')  \n",
    "        model.fit(x, y, verbose=verbose, epochs=epochs, callbacks=[earlyStop])\n",
    "    else:\n",
    "        model.fit(x, y, verbose=verbose, epochs=epochs)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with RSME Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to test a bunch of models and return the best one\n",
    "def test_models(models, x, y):\n",
    "    #used to return best model, but used too much memory\n",
    "    best_i=-1\n",
    "    i=0\n",
    "    best_rmse=5;\n",
    "    for model in models:\n",
    "        pred=model.predict(x)\n",
    "        #compare actual to predicted\n",
    "        score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
    "        print(score)\n",
    "        if(score<best_rmse):\n",
    "            best_i=i\n",
    "            best_rmse=score\n",
    "        i=i+1\n",
    "    return models[best_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create models with different control variables, several times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation\n",
    "Now we will creatie many models with different starting points, attributes, and algorithms.\n",
    "\n",
    "First we will test adam vs. sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control\n",
    "control_models=[]\n",
    "for i in range(4):\n",
    "    control_models.append(make_model(x_train,y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7355219994558784\n",
      "1.7266151064447883\n",
      "1.7307933811286005\n",
      "1.7234013586855659\n"
     ]
    }
   ],
   "source": [
    "control_final=test_models(control_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 2s - loss: 2.9511\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0611\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0561\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0434\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0361\n",
      "Epoch 6/50\n",
      "3596/3596 - 1s - loss: 2.0222\n",
      "Epoch 7/50\n",
      "3596/3596 - 1s - loss: 2.0080\n",
      "Epoch 8/50\n",
      "3596/3596 - 1s - loss: 1.9963\n",
      "Epoch 9/50\n",
      "3596/3596 - 1s - loss: 1.9754\n",
      "Epoch 10/50\n",
      "3596/3596 - 1s - loss: 1.9555\n",
      "Epoch 11/50\n",
      "3596/3596 - 1s - loss: 1.9265\n",
      "Epoch 12/50\n",
      "3596/3596 - 1s - loss: 1.9038\n",
      "Epoch 13/50\n",
      "3596/3596 - 1s - loss: 1.8698\n",
      "Epoch 14/50\n",
      "3596/3596 - 1s - loss: 1.8205\n",
      "Epoch 15/50\n",
      "3596/3596 - 1s - loss: 1.7708\n",
      "Epoch 16/50\n",
      "3596/3596 - 1s - loss: 1.7047\n",
      "Epoch 17/50\n",
      "3596/3596 - 1s - loss: 1.6298\n",
      "Epoch 18/50\n",
      "3596/3596 - 1s - loss: 1.5387\n",
      "Epoch 19/50\n",
      "3596/3596 - 1s - loss: 1.4379\n",
      "Epoch 20/50\n",
      "3596/3596 - 1s - loss: 1.3641\n",
      "Epoch 21/50\n",
      "3596/3596 - 1s - loss: 1.4678\n",
      "Epoch 22/50\n",
      "3596/3596 - 1s - loss: 1.2832\n",
      "Epoch 23/50\n",
      "3596/3596 - 1s - loss: 1.3869\n",
      "Epoch 24/50\n",
      "3596/3596 - 1s - loss: 1.3549\n",
      "Epoch 00024: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.9391\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0588\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0480\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0356\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0363\n",
      "Epoch 6/50\n",
      "3596/3596 - 1s - loss: 2.0223\n",
      "Epoch 7/50\n",
      "3596/3596 - 1s - loss: 2.0131\n",
      "Epoch 8/50\n",
      "3596/3596 - 1s - loss: 1.9937\n",
      "Epoch 9/50\n",
      "3596/3596 - 1s - loss: 1.9820\n",
      "Epoch 10/50\n",
      "3596/3596 - 1s - loss: 1.9624\n",
      "Epoch 11/50\n",
      "3596/3596 - 1s - loss: 1.9283\n",
      "Epoch 12/50\n",
      "3596/3596 - 1s - loss: 1.9063\n",
      "Epoch 13/50\n",
      "3596/3596 - 1s - loss: 1.8725\n",
      "Epoch 14/50\n",
      "3596/3596 - 1s - loss: 1.8200\n",
      "Epoch 15/50\n",
      "3596/3596 - 1s - loss: 1.7688\n",
      "Epoch 16/50\n",
      "3596/3596 - 1s - loss: 1.6947\n",
      "Epoch 17/50\n",
      "3596/3596 - 1s - loss: 1.6159\n",
      "Epoch 18/50\n",
      "3596/3596 - 1s - loss: 1.5468\n",
      "Epoch 19/50\n",
      "3596/3596 - 1s - loss: 1.4403\n",
      "Epoch 20/50\n",
      "3596/3596 - 1s - loss: 1.4338\n",
      "Epoch 21/50\n",
      "3596/3596 - 1s - loss: 1.4590\n",
      "Epoch 22/50\n",
      "3596/3596 - 1s - loss: 1.3934\n",
      "Epoch 23/50\n",
      "3596/3596 - 1s - loss: 1.4219\n",
      "Epoch 24/50\n",
      "3596/3596 - 1s - loss: 1.2302\n",
      "Epoch 25/50\n",
      "3596/3596 - 1s - loss: 1.2793\n",
      "Epoch 26/50\n",
      "3596/3596 - 1s - loss: 1.2089\n",
      "Epoch 27/50\n",
      "3596/3596 - 1s - loss: 1.2417\n",
      "Epoch 28/50\n",
      "3596/3596 - 1s - loss: 1.2061\n",
      "Epoch 29/50\n",
      "3596/3596 - 1s - loss: 1.1993\n",
      "Epoch 30/50\n",
      "3596/3596 - 1s - loss: 1.0651\n",
      "Epoch 31/50\n",
      "3596/3596 - 1s - loss: 0.9866\n",
      "Epoch 32/50\n",
      "3596/3596 - 1s - loss: 0.9038\n",
      "Epoch 33/50\n",
      "3596/3596 - 1s - loss: 0.9781\n",
      "Epoch 34/50\n",
      "3596/3596 - 1s - loss: 1.0845\n",
      "Epoch 00034: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 4.7114\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0632\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0577\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0589\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0573\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "#slower sg models\n",
    "sgd_models=[]\n",
    "for i in range(3):\n",
    "    sgd_models.append(make_model(x_train,y_train, optimizer='sgd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6333269872107088\n",
      "1.580109359799927\n",
      "1.4827214616187845\n"
     ]
    }
   ],
   "source": [
    "sgd_final=test_models(sgd_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD is much more effective, so future tests will use it.\n",
    "\n",
    "Next we will compare activation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.9485\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0634\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0633\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0608\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0648\n",
      "Epoch 6/50\n",
      "3596/3596 - 1s - loss: 2.0607\n",
      "Epoch 00006: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 2s - loss: 2.8790\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0609\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0628\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0640\n",
      "Epoch 00004: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.5581\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0653\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0638\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0637\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0650\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "#sigmoid models\n",
    "sigmoid_models=[]\n",
    "for i in range(3):\n",
    "    sigmoid_models.append(make_model(x_train,y_train, optimizer='sgd', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4774986672348622\n",
      "1.4795438365073241\n",
      "1.4823926854856608\n"
     ]
    }
   ],
   "source": [
    "sigmoid_final=test_models(sigmoid_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.5685\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0629\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0598\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0523\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0463\n",
      "Epoch 6/50\n",
      "3596/3596 - 1s - loss: 2.0377\n",
      "Epoch 7/50\n",
      "3596/3596 - 1s - loss: 2.0274\n",
      "Epoch 8/50\n",
      "3596/3596 - 1s - loss: 2.0251\n",
      "Epoch 9/50\n",
      "3596/3596 - 1s - loss: 2.0101\n",
      "Epoch 10/50\n",
      "3596/3596 - 1s - loss: 1.9957\n",
      "Epoch 11/50\n",
      "3596/3596 - 1s - loss: 1.9793\n",
      "Epoch 12/50\n",
      "3596/3596 - 1s - loss: 1.9675\n",
      "Epoch 13/50\n",
      "3596/3596 - 1s - loss: 1.9340\n",
      "Epoch 14/50\n",
      "3596/3596 - 1s - loss: 1.9029\n",
      "Epoch 15/50\n",
      "3596/3596 - 1s - loss: 1.8637\n",
      "Epoch 16/50\n",
      "3596/3596 - 1s - loss: 1.8060\n",
      "Epoch 17/50\n",
      "3596/3596 - 1s - loss: 1.7370\n",
      "Epoch 18/50\n",
      "3596/3596 - 1s - loss: 1.6497\n",
      "Epoch 19/50\n",
      "3596/3596 - 1s - loss: 1.5439\n",
      "Epoch 20/50\n",
      "3596/3596 - 1s - loss: 1.4729\n",
      "Epoch 21/50\n",
      "3596/3596 - 1s - loss: 1.4334\n",
      "Epoch 22/50\n",
      "3596/3596 - 1s - loss: 1.3671\n",
      "Epoch 23/50\n",
      "3596/3596 - 1s - loss: 1.4638\n",
      "Epoch 24/50\n",
      "3596/3596 - 1s - loss: 1.3121\n",
      "Epoch 25/50\n",
      "3596/3596 - 1s - loss: 1.2954\n",
      "Epoch 26/50\n",
      "3596/3596 - 1s - loss: 1.3327\n",
      "Epoch 27/50\n",
      "3596/3596 - 1s - loss: 1.1211\n",
      "Epoch 28/50\n",
      "3596/3596 - 1s - loss: 1.2160\n",
      "Epoch 29/50\n",
      "3596/3596 - 1s - loss: 1.1407\n",
      "Epoch 00029: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.6309\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0616\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0540\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0558\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0475\n",
      "Epoch 6/50\n",
      "3596/3596 - 1s - loss: 2.0411\n",
      "Epoch 7/50\n",
      "3596/3596 - 1s - loss: 2.0289\n",
      "Epoch 8/50\n",
      "3596/3596 - 1s - loss: 2.0250\n",
      "Epoch 9/50\n",
      "3596/3596 - 1s - loss: 2.0206\n",
      "Epoch 10/50\n",
      "3596/3596 - 1s - loss: 2.0057\n",
      "Epoch 11/50\n",
      "3596/3596 - 1s - loss: 1.9927\n",
      "Epoch 12/50\n",
      "3596/3596 - 1s - loss: 1.9789\n",
      "Epoch 13/50\n",
      "3596/3596 - 1s - loss: 1.9565\n",
      "Epoch 14/50\n",
      "3596/3596 - 1s - loss: 1.9290\n",
      "Epoch 15/50\n",
      "3596/3596 - 1s - loss: 1.8948\n",
      "Epoch 16/50\n",
      "3596/3596 - 1s - loss: 1.8484\n",
      "Epoch 17/50\n",
      "3596/3596 - 1s - loss: 1.7818\n",
      "Epoch 18/50\n",
      "3596/3596 - 1s - loss: 1.7078\n",
      "Epoch 19/50\n",
      "3596/3596 - 1s - loss: 1.6156\n",
      "Epoch 20/50\n",
      "3596/3596 - 1s - loss: 1.5359\n",
      "Epoch 21/50\n",
      "3596/3596 - 1s - loss: 1.4494\n",
      "Epoch 22/50\n",
      "3596/3596 - 1s - loss: 1.3973\n",
      "Epoch 23/50\n",
      "3596/3596 - 1s - loss: 1.4091\n",
      "Epoch 24/50\n",
      "3596/3596 - 1s - loss: 1.4389\n",
      "Epoch 00024: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.9164\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0605\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0593\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0553\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0476\n",
      "Epoch 6/50\n",
      "3596/3596 - 1s - loss: 2.0450\n",
      "Epoch 7/50\n",
      "3596/3596 - 1s - loss: 2.0397\n",
      "Epoch 8/50\n",
      "3596/3596 - 1s - loss: 2.0336\n",
      "Epoch 9/50\n",
      "3596/3596 - 1s - loss: 2.0218\n",
      "Epoch 10/50\n",
      "3596/3596 - 1s - loss: 2.0182\n",
      "Epoch 11/50\n",
      "3596/3596 - 1s - loss: 2.0075\n",
      "Epoch 12/50\n",
      "3596/3596 - 1s - loss: 1.9985\n",
      "Epoch 13/50\n",
      "3596/3596 - 1s - loss: 1.9807\n",
      "Epoch 14/50\n",
      "3596/3596 - 1s - loss: 1.9547\n",
      "Epoch 15/50\n",
      "3596/3596 - 1s - loss: 1.9345\n",
      "Epoch 16/50\n",
      "3596/3596 - 1s - loss: 1.9004\n",
      "Epoch 17/50\n",
      "3596/3596 - 1s - loss: 1.8598\n",
      "Epoch 18/50\n",
      "3596/3596 - 1s - loss: 1.8113\n",
      "Epoch 19/50\n",
      "3596/3596 - 1s - loss: 1.7363\n",
      "Epoch 20/50\n",
      "3596/3596 - 1s - loss: 1.6484\n",
      "Epoch 21/50\n",
      "3596/3596 - 1s - loss: 1.5654\n",
      "Epoch 22/50\n",
      "3596/3596 - 1s - loss: 1.4622\n",
      "Epoch 23/50\n",
      "3596/3596 - 1s - loss: 1.3467\n",
      "Epoch 24/50\n",
      "3596/3596 - 1s - loss: 1.4669\n",
      "Epoch 25/50\n",
      "3596/3596 - 1s - loss: 1.4411\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "#tanh models\n",
    "tanh_models=[]\n",
    "for i in range(3):\n",
    "    tanh_models.append(make_model(x_train,y_train, optimizer='sgd', activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0954148467986458\n",
      "1.664129425144852\n",
      "1.8854041901366214\n"
     ]
    }
   ],
   "source": [
    "tanh_final=test_models(tanh_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid is the better activation to use, so we will stick with that.\n",
    "\n",
    "Next we will play with number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3596 samples\n",
      "Epoch 1/100\n",
      "3596/3596 - 1s - loss: 2.3902\n",
      "Epoch 2/100\n",
      "3596/3596 - 1s - loss: 2.0652\n",
      "Epoch 3/100\n",
      "3596/3596 - 1s - loss: 2.0663\n",
      "Epoch 4/100\n",
      "3596/3596 - 1s - loss: 2.0650\n",
      "Epoch 00004: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/100\n",
      "3596/3596 - 1s - loss: 3.1112\n",
      "Epoch 2/100\n",
      "3596/3596 - 1s - loss: 2.0647\n",
      "Epoch 3/100\n",
      "3596/3596 - 1s - loss: 2.0647\n",
      "Epoch 4/100\n",
      "3596/3596 - 1s - loss: 2.0634\n",
      "Epoch 5/100\n",
      "3596/3596 - 1s - loss: 2.0647\n",
      "Epoch 6/100\n",
      "3596/3596 - 1s - loss: 2.0630\n",
      "Epoch 00006: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/100\n",
      "3596/3596 - 1s - loss: 3.1024\n",
      "Epoch 2/100\n",
      "3596/3596 - 1s - loss: 2.0632\n",
      "Epoch 3/100\n",
      "3596/3596 - 1s - loss: 2.0645\n",
      "Epoch 4/100\n",
      "3596/3596 - 1s - loss: 2.0652\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "#more epochs\n",
    "slow_models=[]\n",
    "for i in range(3):\n",
    "    slow_models.append(make_model(x_train,y_train, epochs=100, optimizer='sgd', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4769313373561488\n",
      "1.476936051880294\n",
      "1.4776829203897845\n"
     ]
    }
   ],
   "source": [
    "slow_final=test_models(slow_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3596 samples\n",
      "Epoch 1/200\n",
      "3596/3596 - 1s - loss: 2.3688\n",
      "Epoch 2/200\n",
      "3596/3596 - 1s - loss: 2.0601\n",
      "Epoch 3/200\n",
      "3596/3596 - 1s - loss: 2.0625\n",
      "Epoch 4/200\n",
      "3596/3596 - 1s - loss: 2.0640\n",
      "Epoch 00004: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/200\n",
      "3596/3596 - 1s - loss: 2.4965\n",
      "Epoch 2/200\n",
      "3596/3596 - 1s - loss: 2.0655\n",
      "Epoch 3/200\n",
      "3596/3596 - 1s - loss: 2.0666\n",
      "Epoch 4/200\n",
      "3596/3596 - 1s - loss: 2.0669\n",
      "Epoch 00004: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/200\n",
      "3596/3596 - 2s - loss: 2.9570\n",
      "Epoch 2/200\n",
      "3596/3596 - 1s - loss: 2.0645\n",
      "Epoch 3/200\n",
      "3596/3596 - 1s - loss: 2.0617\n",
      "Epoch 4/200\n",
      "3596/3596 - 1s - loss: 2.0632\n",
      "Epoch 5/200\n",
      "3596/3596 - 1s - loss: 2.0650\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "#way more epochs\n",
    "x_slow_models=[]\n",
    "for i in range(3):\n",
    "    x_slow_models.append(make_model(x_train,y_train, epochs=200, optimizer='sgd', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4774742454960386\n",
      "1.477118722858916\n",
      "1.4777525814222185\n"
     ]
    }
   ],
   "source": [
    "x_slow_final=test_models(x_slow_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to early stopping, number of epochs is negligible on results\n",
    "\n",
    "Next we will play with layer sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 2s - loss: 2.4875\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0634\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0659\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0661\n",
      "Epoch 00004: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.5029\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0647\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0643\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0653\n",
      "Epoch 00004: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.8868\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0649\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0644\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0655\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "#more neurons\n",
    "big_models=[]\n",
    "for i in range(3):\n",
    "    big_models.append(make_model(x_train,y_train, firstLayer=50, secondLayer=25, optimizer='sgd', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4772338324811856\n",
      "1.4769648780319902\n",
      "1.4774010414453356\n"
     ]
    }
   ],
   "source": [
    "big_final=test_models(big_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.8961\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0647\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0649\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0658\n",
      "Epoch 00004: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.7602\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0649\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0630\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0632\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0663\n",
      "Epoch 00005: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.5425\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0666\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0641\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0623\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0631\n",
      "Epoch 6/50\n",
      "3596/3596 - 1s - loss: 2.0651\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "#fewer neurons\n",
    "small_models=[]\n",
    "for i in range(3):\n",
    "    small_models.append(make_model(x_train,y_train, firstLayer=10, secondLayer=5, optimizer='sgd', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.477002018842461\n",
      "1.4769573358952646\n",
      "1.4781790713435743\n"
     ]
    }
   ],
   "source": [
    "small_final=test_models(small_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More neurons helped seems a little better. What if we used *a lot* more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.8127\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0618\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0649\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0658\n",
      "Epoch 00004: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.8799\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0647\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0652\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0633\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0643\n",
      "Epoch 6/50\n",
      "3596/3596 - 1s - loss: 2.0654\n",
      "Epoch 00006: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.5120\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0643\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0616\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0618\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0642\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "#way more neurons\n",
    "xl_models=[]\n",
    "for i in range(3):\n",
    "    xl_models.append(make_model(x_train,y_train, firstLayer=100, secondLayer=50, optimizer='sgd', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4779421139583615\n",
      "1.477326415229938\n",
      "1.4774171290776148\n"
     ]
    }
   ],
   "source": [
    "xl_final=test_models(xl_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of neurons produced a negligable difference in result.\n",
    "\n",
    "Next let us experiment with number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parfait_models=[]\n",
    "for i in range(3):\n",
    "    model = Sequential()\n",
    "\n",
    "    #Set up layers\n",
    "    model.add(Dense(25, input_dim=x.shape[1], activation='sigmoid')) # Hidden 1 \n",
    "    model.add(Dense(20, 'sigmoid')) # Hidden 2\n",
    "    model.add(Dense(10, 'sigmoid')) # Hidden 3\n",
    "    model.add(Dense(1)) # Output\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "    #set up early stop parameters\n",
    "    earlyStop = EarlyStopping(monitor='loss', min_delta=0.001, patience=2, verbose=0, mode='auto')  \n",
    "    model.fit(x_train, y_train, verbose=0, epochs=50, callbacks=[earlyStop])\n",
    "    parfait_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4825224804365338\n",
      "1.477509416215066\n",
      "1.4802060823022591\n"
     ]
    }
   ],
   "source": [
    "parfait_final=test_models(parfait_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_models=[]\n",
    "for i in range(3):\n",
    "    model = Sequential()\n",
    "\n",
    "    #Set up layers\n",
    "    model.add(Dense(50, input_dim=x.shape[1], activation='sigmoid')) # Hidden 1 \n",
    "    model.add(Dense(25, 'sigmoid')) # Hidden 2\n",
    "    model.add(Dense(15, 'sigmoid')) # Hidden 3\n",
    "    model.add(Dense(1)) # Output\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "    #set up early stop parameters\n",
    "    earlyStop = EarlyStopping(monitor='loss', min_delta=0.001, patience=2, verbose=0, mode='auto')  \n",
    "    model.fit(x, y, verbose=0, epochs=50, callbacks=[earlyStop])\n",
    "    onion_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.477013350226753\n",
      "1.4769253711515706\n",
      "1.476959496376593\n"
     ]
    }
   ],
   "source": [
    "onion_final=test_models(onion_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of layers seems negiligible with the current settings.\n",
    "\n",
    "Next let's play with the min delta and pateince variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.9678\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0668\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0619\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0634\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0618\n",
      "Epoch 6/50\n",
      "3596/3596 - 1s - loss: 2.0678\n",
      "Epoch 7/50\n",
      "3596/3596 - 1s - loss: 2.0649\n",
      "Epoch 8/50\n",
      "3596/3596 - 1s - loss: 2.0640\n",
      "Epoch 00008: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.8436\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0648\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0660\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0649\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0646\n",
      "Epoch 6/50\n",
      "3596/3596 - 1s - loss: 2.0680\n",
      "Epoch 7/50\n",
      "3596/3596 - 1s - loss: 2.0665\n",
      "Epoch 00007: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.7143\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0641\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0609\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0621\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0643\n",
      "Epoch 6/50\n",
      "3596/3596 - 1s - loss: 2.0638\n",
      "Epoch 7/50\n",
      "3596/3596 - 1s - loss: 2.0649\n",
      "Epoch 8/50\n",
      "3596/3596 - 1s - loss: 2.0642\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "#higher patience value\n",
    "patient_models=[]\n",
    "for i in range(3):\n",
    "    patient_models.append(make_model(x_train,y_train, patience=5, optimizer='sgd', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4769083996394075\n",
      "1.478265115710387\n",
      "1.4769562174790298\n"
     ]
    }
   ],
   "source": [
    "patient_final=test_models(patient_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.6634\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0633\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0651\n",
      "Epoch 00003: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.7057\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0664\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0629\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0645\n",
      "Epoch 00004: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.9922\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0604\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0637\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "#lower pateince value\n",
    "impatient_models=[]\n",
    "for i in range(3):\n",
    "    impatient_models.append(make_model(x_train,y_train,  patience=1, optimizer='sgd', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4793611795901607\n",
      "1.4769400013599658\n",
      "1.478695268734721\n"
     ]
    }
   ],
   "source": [
    "impatient_final=test_models(impatient_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.7074\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0637\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0647\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0636\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0651\n",
      "Epoch 6/50\n",
      "3596/3596 - 1s - loss: 2.0649\n",
      "Epoch 00006: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 3.7345\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0634\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0637\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0641\n",
      "Epoch 00004: early stopping\n",
      "Train on 3596 samples\n",
      "Epoch 1/50\n",
      "3596/3596 - 1s - loss: 2.6101\n",
      "Epoch 2/50\n",
      "3596/3596 - 1s - loss: 2.0670\n",
      "Epoch 3/50\n",
      "3596/3596 - 1s - loss: 2.0622\n",
      "Epoch 4/50\n",
      "3596/3596 - 1s - loss: 2.0665\n",
      "Epoch 5/50\n",
      "3596/3596 - 1s - loss: 2.0626\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "#smaller min delta value\n",
    "ten_k_models=[]\n",
    "for i in range(3):\n",
    "    ten_k_models.append(make_model(x_train,y_train, min_delta=0.0001, optimizer='sgd', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4798158071489746\n",
      "1.476906694670433\n",
      "1.4887693514533116\n"
     ]
    }
   ],
   "source": [
    "ten_k_final=test_models(ten_k_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3920 samples\n",
      "Epoch 1/50\n",
      "3920/3920 - 3s - loss: 2.7942\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-f51aeee76ba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mhun_models\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mhun_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sgd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-52-8aa94d0fcaa3>\u001b[0m in \u001b[0;36mmake_model\u001b[1;34m(x, y, firstLayer, secondLayer, epochs, optimizer, activation, stopEarly, monitor, min_delta, patience, verbose)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopEarly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mearlyStop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearlyStop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#larger min delta value\n",
    "hun_models=[]\n",
    "for i in range(3):\n",
    "    hun_models.append(make_model(x_train,y_train, min_delta=0.01, patience=5, optimizer='sgd', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_final=test_models(hun_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smaller min delta value AND more patient\n",
    "patient_10k_models=[]\n",
    "for i in range(3):\n",
    "    patient_10k_models.append(make_model(x_train,y_train, min_delta=0.0001, patience=5, optimizer='sgd', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_10k_final=test_models(patient_10k_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've picked the best configuration, let's run it from multiple starting points to get the best possible model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.479420049034254\n",
      "1.4777900426409327\n",
      "1.4769709549444714\n",
      "1.4774798763565844\n",
      "1.4772395793322126\n",
      "1.4783844682903522\n",
      "1.4779267966378182\n",
      "1.4786456403844257\n",
      "1.4778743041655324\n",
      "1.479993618986649\n"
     ]
    }
   ],
   "source": [
    "best_models=[]\n",
    "for i in range(10):\n",
    "    best_models.append(make_model(x_train,y_train, verbose=0, firstLayer=100, secondLayer=50, \n",
    "                                min_delta=0.0001, optimizer='sgd', activation='sigmoid'))\n",
    "best_model=test_models(best_models,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to make model\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Set up layers\n",
    "model.add(Dense(25, input_dim=x.shape[1], activation=activation)) # Hidden 1 \n",
    "model.add(Dense(10, activation)) # Hidden 2\n",
    "model.add(Dense(1)) # Output\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "  #set up early stop parameters\n",
    "earlyStop = EarlyStopping(monitor=monitor, min_delta=min_delta, patience=patience, verbose=verbose, mode='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3920 samples\n",
      "Epoch 1/50\n",
      "3920/3920 - 3s - loss: 8.1102\n",
      "Epoch 2/50\n",
      "3920/3920 - 3s - loss: 2.6140\n",
      "Epoch 3/50\n",
      "3920/3920 - 3s - loss: 1.9238\n",
      "Epoch 4/50\n",
      "3920/3920 - 2s - loss: 1.3657\n",
      "Epoch 5/50\n",
      "3920/3920 - 2s - loss: 0.8279\n",
      "Epoch 6/50\n",
      "3920/3920 - 3s - loss: 0.4078\n",
      "Epoch 7/50\n",
      "3920/3920 - 2s - loss: 0.1964\n",
      "Epoch 8/50\n",
      "3920/3920 - 2s - loss: 0.1035\n",
      "Epoch 9/50\n",
      "3920/3920 - 2s - loss: 0.0642\n",
      "Epoch 10/50\n",
      "3920/3920 - 2s - loss: 0.0474\n",
      "Epoch 11/50\n",
      "3920/3920 - 2s - loss: 0.0424\n",
      "Epoch 12/50\n",
      "3920/3920 - 2s - loss: 0.0419\n",
      "Epoch 13/50\n",
      "3920/3920 - 2s - loss: 0.0440\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_144_input to have shape (27047,) but got array with shape (80027,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-3561a7243aa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mchart_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m     return self._model_iteration(\n\u001b[0;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[0;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2472\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    572\u001b[0m                              \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m                              str(data_shape))\n\u001b[0m\u001b[0;32m    575\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_144_input to have shape (27047,) but got array with shape (80027,)"
     ]
    }
   ],
   "source": [
    "model=make_model(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred=model.predict(x_test)\n",
    "chart_regression(pred.flatten(),y_test,sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# save entire network to HDF5\n",
    "best_model.save(\"network.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model2 = load_model(\"network.hdf5\")\n",
    "pred = model2.predict(x_test)\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"After load score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beep()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

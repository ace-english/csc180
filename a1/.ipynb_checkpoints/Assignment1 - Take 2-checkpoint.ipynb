{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Yelp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import relevent libraries. Add useful functions from the \"useful gems\" lab.I have also included a helper function to tell me that my browser is not crashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import time, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from scipy.stats import zscore\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from collections.abc import Sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import winsound\n",
    "\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "    \n",
    "#Show progress bar in loop\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n",
    "    \n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#Let me know when you're done!\n",
    "def beep():\n",
    "    duration = 500  # milliseconds\n",
    "    freq = 1040  # Hz\n",
    "    winsound.Beep(freq, duration)\n",
    "\n",
    "loadFresh=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First determine businesses have enough reviews to be relevent for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 99.9%\n"
     ]
    }
   ],
   "source": [
    "if(loadFresh):\n",
    "    #Convert raw business data into tsv\n",
    "    outfile = open(\"businesses.tsv\", 'w')\n",
    "    sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "    sfile.writerow(['business_id','stars', 'review_count'])\n",
    "    with open('yelp_dataset/business.json', encoding=\"utf-8\") as f:\n",
    "     i=0\n",
    "     for line in f:\n",
    "        row = json.loads(line)\n",
    "        if(row['review_count']>=20):\n",
    "            sfile.writerow([row['business_id'], row['stars'], (row['review_count'])])\n",
    "        i=i+1\n",
    "        update_progress(i / 192610)\n",
    "\n",
    "    update_progress(1);\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>45042</td>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11344</td>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29166</td>\n",
       "      <td>--7zmmkVg-IMGaXbuVd0SQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49157</td>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37751</td>\n",
       "      <td>--DaPTJW3-tB1vP-PfdTEg</td>\n",
       "      <td>3.5</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44660</td>\n",
       "      <td>zzsOLFhgUw8gnjLTVVItFA</td>\n",
       "      <td>4.5</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13453</td>\n",
       "      <td>zzwaS0xn1MVEPEf0hNLjew</td>\n",
       "      <td>3.5</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>zzwhN7x37nyjP0ZM8oiHmw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46061</td>\n",
       "      <td>zzwicjPC9g246MK2M1ZFBA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36284</td>\n",
       "      <td>zzzaIBwimxVej4tY6qFOUQ</td>\n",
       "      <td>3.5</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57644 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  business_id  stars  review_count\n",
       "45042  --1UhMGODdWsrMastO9DZw    4.0            24\n",
       "11344  --6MefnULPED_I942VcFNA    3.0            44\n",
       "29166  --7zmmkVg-IMGaXbuVd0SQ    4.0            58\n",
       "49157  --9e1ONYQuAa-CB_Rrw7Tw    4.0          1613\n",
       "37751  --DaPTJW3-tB1vP-PfdTEg    3.5            49\n",
       "...                       ...    ...           ...\n",
       "44660  zzsOLFhgUw8gnjLTVVItFA    4.5           105\n",
       "13453  zzwaS0xn1MVEPEf0hNLjew    3.5            68\n",
       "356    zzwhN7x37nyjP0ZM8oiHmw    4.0            54\n",
       "46061  zzwicjPC9g246MK2M1ZFBA    3.0            70\n",
       "36284  zzzaIBwimxVej4tY6qFOUQ    3.5            37\n",
       "\n",
       "[57644 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load business table\n",
    "business_df= pd.read_csv('businesses.tsv', delimiter =\"\\t\", encoding=\"utf-8\")\n",
    "business_df=business_df.sort_values('business_id');\n",
    "business_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found 57644 with enough reviews to be useful. All stored in business_df, ordered by business ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review data\n",
    "Open the review data and convert into a TSV with only the relevent information. Runs a progress bar while loading. To save space, only writes to file if the business has 20 reviews or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [###########---------] 55.1%\n"
     ]
    }
   ],
   "source": [
    "if(loadFresh):\n",
    "    #Convert raw review data into TSV\n",
    "    outfile = open(\"review_stars.tsv\", 'w')\n",
    "    sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "    sfile.writerow(['business_id','stars', 'text'])\n",
    "    with open('yelp_dataset/review.json', encoding=\"utf-8\") as f:\n",
    "     i=0\n",
    "     for line in f:\n",
    "        row = json.loads(line)\n",
    "        # Check if businessID if present in business table\n",
    "        if(row['business_id'] in business_df['business_id'].tolist()):\n",
    "            # some special char must be encoded in 'utf-8'\n",
    "            sfile.writerow([row['business_id'], row['stars'], (row['text']).encode('utf-8')])\n",
    "        update_progress(i / 2000000)\n",
    "        i=i+1\n",
    "\n",
    "    update_progress(1);\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load review data\n",
    "df= pd.read_csv('review_stars-small.tsv', delimiter =\"\\t\", encoding=\"utf-8\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language preprocessing\n",
    "First, aggregates all reviews under their business ID. Then we can run TFIDF on the sum of all the reviews in preparation to do language analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groups reviews by businessID\n",
    "df_review_group=df.groupby('business_id')['text'].sum()\n",
    "df_reviews = pd.DataFrame({'business_id':df_review_group.index, 'all_reviews':df_review_group.values})\n",
    "df_reviews\n",
    "\n",
    "#language preprocessing\n",
    "vectorizer = sk_text.TfidfVectorizer(stop_words='english',\n",
    "                             min_df=2, \n",
    "                             max_df=500)\n",
    "\n",
    "#df_reviews['all_reviews'] = vectorizer.fit_transform(df_reviews['all_reviews'])\n",
    "vector_reviews=vectorizer.fit_transform(df_reviews[\"all_reviews\"])\n",
    "\n",
    "#split off business ID\n",
    "col_id=df_reviews['business_id']\n",
    "#create dataframe from vectored reviews\n",
    "df_vector_reviews=pd.DataFrame(vector_reviews.todense())\n",
    "#concat to single dataframe\n",
    "df_tfidf_reviews=pd.concat([col_id,df_vector_reviews],axis=1)\n",
    "\n",
    "display(df_tfidf_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join total reviews with aggregated review data\n",
    "df_join=pd.concat([df, df_tfidf_reviews], axis=1, join='inner')\n",
    "#drop unnecesary info\n",
    "df_sklearn_ready=df_join.drop(columns=['business_id', 'text'])\n",
    "df_sklearn_ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y is our list of reviews and X is your table of language data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get arrays for training\n",
    "y=df_sklearn_ready[\"stars\"].values\n",
    "x=df_sklearn_ready.drop([\"stars\"], axis=1).values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is clean and it's time to feed it to the AI\n",
    "\n",
    "# Machine learning\n",
    "## TensorFlow Regression\n",
    "Since the idea is to make a bunch of models to test, to start here are some functions to repeatedly create and test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to make model\n",
    "def make_model(x,y,firstLayer=25,secondLayer=10,epochs=50, optimizer='adam', activation='relu',\n",
    "               stopEarly=1, monitor='loss', min_delta=0.001, patience=2, verbose=2):\n",
    "    model = Sequential()\n",
    "\n",
    "    #Set up layers\n",
    "    model.add(Dense(25, input_dim=x.shape[1], activation=activation)) # Hidden 1 \n",
    "    model.add(Dense(10, activation)) # Hidden 2\n",
    "    model.add(Dense(1)) # Output\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    #set up early stop parameters\n",
    "    if(stopEarly):\n",
    "        earlyStop = EarlyStopping(monitor=monitor, min_delta=min_delta, patience=patience, verbose=verbose, mode='auto')  \n",
    "        model.fit(x, y, verbose=verbose, epochs=epochs, callbacks=[earlyStop])\n",
    "    else:\n",
    "        model.fit(x, y, verbose=verbose, epochs=epochs)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with RSME Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to test a bunch of models and return the best one\n",
    "def test_models(models, x, y):\n",
    "    #used to return best model, but used too much memory\n",
    "    best_i=-1\n",
    "    i=0\n",
    "    best_rmse=5;\n",
    "    for model in models:\n",
    "        pred=model.predict(x)\n",
    "        #compare actual to predicted\n",
    "        score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
    "        print(score)\n",
    "        if(score<best_rmse):\n",
    "            best_i=i\n",
    "            best_rmse=score\n",
    "        i=i+1\n",
    "    return models[best_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create models with different control variables, several times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation\n",
    "Now we will creatie many models with different starting points, attributes, and algorithms.\n",
    "\n",
    "First we will test adam vs. sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fd169890a6ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#model.add(Dense(10, activation='tanh'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "#model.add(Dense(10, activation='tanh'))   \n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=\"dnn/best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "# batch_size: Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test), batch_size= 128, callbacks=[monitor,checkpointer],verbose=2,epochs=1000)\n",
    "model.load_weights('dnn/best_weights.hdf5') # load weights from best model\n",
    "\n",
    "# Predict and measure RMSE\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "\n",
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),y_test)\n",
    "\n",
    "pred=model.predict(x_test)\n",
    "chart_regression(pred.flatten(),y_test,sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# save entire network to HDF5\n",
    "best_model.save(\"network.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model2 = load_model(\"network.hdf5\")\n",
    "pred = model2.predict(x_test)\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"After load score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beep()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
